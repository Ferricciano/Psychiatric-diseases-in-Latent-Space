{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f90305e9-56bb-4fa7-bc02-0f9b086f0fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "import seaborn as sns\n",
    "import myFunctions as fct\n",
    "import matplotlib as mpl\n",
    "import scipy.io as sio\n",
    "from autoEncoderDense import AutoEncoderDense\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras import backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6278e553-01d6-4879-b167-3673673dfc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 80, 152)\n"
     ]
    }
   ],
   "source": [
    "adhd= np.load('ucla_adhd_dbs80_filtered.npy')\n",
    "bipolar= np.load('ucla_bipolar_dbs80_filtered.npy')\n",
    "schizophrenia= np.load('ucla_schizophrenia_dbs80_filtered.npy')\n",
    "controls= np.load('ucla_controls_dbs80_filtered.npy')\n",
    "                \n",
    "\n",
    "matrix_list = []\n",
    "\n",
    "for i in range (40):\n",
    "    matrix_list.append(controls[i])\n",
    "\n",
    "\n",
    "for i in range (40):\n",
    "    matrix_list.append(bipolar[i])\n",
    "    \n",
    "n = adhd.shape[0]\n",
    "for i in range (n):\n",
    "    matrix_list.append(adhd[i]) \n",
    "\n",
    "\n",
    "for i in range (40):\n",
    "    matrix_list.append(schizophrenia[i])            \n",
    "matrix_array = np.stack(matrix_list, axis=0)\n",
    "\n",
    "\n",
    "num_matrices = matrix_array.shape[0]\n",
    "shuffled_indices = np.random.permutation(num_matrices)\n",
    "all_data = np.zeros_like(matrix_array)\n",
    "for i, index in enumerate(shuffled_indices):\n",
    "    all_data[i] = matrix_array[index]\n",
    "\n",
    "print(all_data.shape)\n",
    "\n",
    "assert matrix_array[0][0][0] != all_data[0][0][0]\n",
    "\n",
    "all_data_normalized = all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e79f285-3c8f-48cf-a52e-3ac62c9fbb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataframe_image as dfi\n",
    "df = pd.DataFrame(all_data_normalized[1])\n",
    "dfi.export(df, 'df80_styled.png', max_cols = 5, max_rows = 8, dpi = 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2cd6435c-59eb-4588-a6b1-965cb0ca6196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192, 80, 152, 1)\n",
      "dataset shape (29184, 80, 1, 1)\n",
      "Train idx = [    0     1     2 ... 29181 29182 29183] test idx = [    3     9    15 ... 29161 29165 29167]\n",
      "training set size=(23347, 80, 1, 1)\n",
      "test set size=(5837, 80, 1, 1)\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 19)                30419     \n",
      "=================================================================\n",
      "Total params: 37,299\n",
      "Trainable params: 36,979\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 19)]              0         \n",
      "_________________________________________________________________\n",
      "dec_dense_4_reshape (Dense)  (None, 1600)              32000     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_2 (Dense)      (None, 80, 1, 20)         420       \n",
      "_________________________________________________________________\n",
      "decoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "decoder_relu_2 (ReLU)        (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_1 (Dense)      (None, 80, 1, 60)         1260      \n",
      "_________________________________________________________________\n",
      "decoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "decoder_relu_1 (ReLU)        (None, 80, 1, 60)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_0 (Dense)      (None, 80, 1, 80)         4880      \n",
      "_________________________________________________________________\n",
      "decoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "decoder_relu_0 (ReLU)        (None, 80, 1, 80)         0         \n",
      "_________________________________________________________________\n",
      "decoder_last_layer (Dense)   (None, 80, 1, 1)          81        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 80, 1, 1)          0         \n",
      "=================================================================\n",
      "Total params: 39,281\n",
      "Trainable params: 38,961\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 19)                37299     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          39281     \n",
      "=================================================================\n",
      "Total params: 76,580\n",
      "Trainable params: 75,940\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "730/730 [==============================] - 18s 24ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - accuracy: 0.0065 - val_loss: 2.5178e-04 - val_mean_squared_error: 2.5178e-04 - val_accuracy: 0.0069\n",
      "Epoch 2/25\n",
      "730/730 [==============================] - 17s 24ms/step - loss: 1.9725e-04 - mean_squared_error: 1.9725e-04 - accuracy: 0.0065 - val_loss: 1.4002e-04 - val_mean_squared_error: 1.4002e-04 - val_accuracy: 0.0069\n",
      "Epoch 3/25\n",
      "730/730 [==============================] - 17s 24ms/step - loss: 1.2563e-04 - mean_squared_error: 1.2563e-04 - accuracy: 0.0065 - val_loss: 1.0846e-04 - val_mean_squared_error: 1.0846e-04 - val_accuracy: 0.0069\n",
      "Epoch 4/25\n",
      "730/730 [==============================] - 18s 24ms/step - loss: 1.0113e-04 - mean_squared_error: 1.0113e-04 - accuracy: 0.0065 - val_loss: 9.3690e-05 - val_mean_squared_error: 9.3690e-05 - val_accuracy: 0.0069\n",
      "Epoch 5/25\n",
      "730/730 [==============================] - 19s 25ms/step - loss: 8.8890e-05 - mean_squared_error: 8.8890e-05 - accuracy: 0.0065 - val_loss: 8.4275e-05 - val_mean_squared_error: 8.4275e-05 - val_accuracy: 0.0069\n",
      "Epoch 6/25\n",
      "730/730 [==============================] - 20s 27ms/step - loss: 8.2165e-05 - mean_squared_error: 8.2165e-05 - accuracy: 0.0065 - val_loss: 7.7788e-05 - val_mean_squared_error: 7.7788e-05 - val_accuracy: 0.0069\n",
      "Epoch 7/25\n",
      "730/730 [==============================] - 20s 27ms/step - loss: 7.5987e-05 - mean_squared_error: 7.5987e-05 - accuracy: 0.0065 - val_loss: 7.2969e-05 - val_mean_squared_error: 7.2969e-05 - val_accuracy: 0.0069\n",
      "Epoch 8/25\n",
      "730/730 [==============================] - 18s 24ms/step - loss: 7.3021e-05 - mean_squared_error: 7.3021e-05 - accuracy: 0.0065 - val_loss: 7.1701e-05 - val_mean_squared_error: 7.1701e-05 - val_accuracy: 0.0069\n",
      "Epoch 9/25\n",
      "730/730 [==============================] - 18s 25ms/step - loss: 7.1282e-05 - mean_squared_error: 7.1282e-05 - accuracy: 0.0065 - val_loss: 6.9484e-05 - val_mean_squared_error: 6.9484e-05 - val_accuracy: 0.0069\n",
      "Epoch 10/25\n",
      "730/730 [==============================] - 18s 24ms/step - loss: 7.0375e-05 - mean_squared_error: 7.0375e-05 - accuracy: 0.0065 - val_loss: 6.9229e-05 - val_mean_squared_error: 6.9229e-05 - val_accuracy: 0.0069\n",
      "Epoch 11/25\n",
      "730/730 [==============================] - 18s 24ms/step - loss: 6.9472e-05 - mean_squared_error: 6.9472e-05 - accuracy: 0.0065 - val_loss: 6.8397e-05 - val_mean_squared_error: 6.8397e-05 - val_accuracy: 0.0069\n",
      "Epoch 12/25\n",
      "730/730 [==============================] - 18s 25ms/step - loss: 6.8826e-05 - mean_squared_error: 6.8826e-05 - accuracy: 0.0065 - val_loss: 6.8553e-05 - val_mean_squared_error: 6.8553e-05 - val_accuracy: 0.0069\n",
      "Epoch 13/25\n",
      "730/730 [==============================] - 17s 24ms/step - loss: 6.8594e-05 - mean_squared_error: 6.8594e-05 - accuracy: 0.0065 - val_loss: 6.8025e-05 - val_mean_squared_error: 6.8025e-05 - val_accuracy: 0.0069\n",
      "Epoch 14/25\n",
      "730/730 [==============================] - 18s 24ms/step - loss: 6.8408e-05 - mean_squared_error: 6.8408e-05 - accuracy: 0.0065 - val_loss: 6.8084e-05 - val_mean_squared_error: 6.8084e-05 - val_accuracy: 0.0069\n",
      "Epoch 15/25\n",
      "730/730 [==============================] - 18s 24ms/step - loss: 6.8042e-05 - mean_squared_error: 6.8042e-05 - accuracy: 0.0065 - val_loss: 6.7649e-05 - val_mean_squared_error: 6.7649e-05 - val_accuracy: 0.0069\n",
      "Epoch 16/25\n",
      "730/730 [==============================] - 18s 25ms/step - loss: 6.7630e-05 - mean_squared_error: 6.7630e-05 - accuracy: 0.0065 - val_loss: 6.8935e-05 - val_mean_squared_error: 6.8934e-05 - val_accuracy: 0.0069\n",
      "Epoch 17/25\n",
      "730/730 [==============================] - 18s 24ms/step - loss: 6.7511e-05 - mean_squared_error: 6.7511e-05 - accuracy: 0.0065 - val_loss: 6.7488e-05 - val_mean_squared_error: 6.7488e-05 - val_accuracy: 0.0069\n",
      "Epoch 18/25\n",
      "730/730 [==============================] - 18s 24ms/step - loss: 6.7488e-05 - mean_squared_error: 6.7488e-05 - accuracy: 0.0065 - val_loss: 6.7508e-05 - val_mean_squared_error: 6.7508e-05 - val_accuracy: 0.0069\n",
      "Epoch 19/25\n",
      "730/730 [==============================] - 17s 24ms/step - loss: 6.7166e-05 - mean_squared_error: 6.7166e-05 - accuracy: 0.0065 - val_loss: 6.7844e-05 - val_mean_squared_error: 6.7844e-05 - val_accuracy: 0.0069\n",
      "Epoch 20/25\n",
      "730/730 [==============================] - 18s 24ms/step - loss: 6.7083e-05 - mean_squared_error: 6.7083e-05 - accuracy: 0.0065 - val_loss: 6.6910e-05 - val_mean_squared_error: 6.6910e-05 - val_accuracy: 0.0069\n",
      "Epoch 21/25\n",
      "730/730 [==============================] - 18s 25ms/step - loss: 6.6926e-05 - mean_squared_error: 6.6926e-05 - accuracy: 0.0065 - val_loss: 6.6795e-05 - val_mean_squared_error: 6.6795e-05 - val_accuracy: 0.0069\n",
      "Epoch 22/25\n",
      "730/730 [==============================] - 17s 24ms/step - loss: 6.6815e-05 - mean_squared_error: 6.6815e-05 - accuracy: 0.0065 - val_loss: 6.6704e-05 - val_mean_squared_error: 6.6704e-05 - val_accuracy: 0.0069\n",
      "Epoch 23/25\n",
      "730/730 [==============================] - 17s 24ms/step - loss: 6.6596e-05 - mean_squared_error: 6.6597e-05 - accuracy: 0.0065 - val_loss: 7.0996e-05 - val_mean_squared_error: 7.0996e-05 - val_accuracy: 0.0069\n",
      "Epoch 24/25\n",
      "730/730 [==============================] - 18s 24ms/step - loss: 6.6405e-05 - mean_squared_error: 6.6405e-05 - accuracy: 0.0065 - val_loss: 6.6802e-05 - val_mean_squared_error: 6.6802e-05 - val_accuracy: 0.0069\n",
      "Epoch 25/25\n",
      "730/730 [==============================] - 18s 24ms/step - loss: 6.6492e-05 - mean_squared_error: 6.6492e-05 - accuracy: 0.0065 - val_loss: 6.6589e-05 - val_mean_squared_error: 6.6589e-05 - val_accuracy: 0.0069\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 19)                37299     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          39281     \n",
      "=================================================================\n",
      "Total params: 76,580\n",
      "Trainable params: 75,940\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 19)                30419     \n",
      "=================================================================\n",
      "Total params: 37,299\n",
      "Trainable params: 36,979\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 6.9339e-05 - mean_squared_error: 6.9339e-05 - accuracy: 0.0069\n",
      "MSE results: 6.933927215868607e-05\n",
      "accuracy results: 0.006852835416793823\n",
      "metrics names ['loss', 'mean_squared_error', 'accuracy']\n",
      "fold iteration # 2  lat dim 19\n",
      "MSE (valid) [6.933927215868607e-05], lat dim 19\n",
      "Train idx = [    0     2     3 ... 29181 29182 29183] test idx = [    1     4     8 ... 29155 29169 29172]\n",
      "training set size=(23347, 80, 1, 1)\n",
      "test set size=(5837, 80, 1, 1)\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 19)                30419     \n",
      "=================================================================\n",
      "Total params: 37,299\n",
      "Trainable params: 36,979\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 19)]              0         \n",
      "_________________________________________________________________\n",
      "dec_dense_4_reshape (Dense)  (None, 1600)              32000     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_2 (Dense)      (None, 80, 1, 20)         420       \n",
      "_________________________________________________________________\n",
      "decoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "decoder_relu_2 (ReLU)        (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_1 (Dense)      (None, 80, 1, 60)         1260      \n",
      "_________________________________________________________________\n",
      "decoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "decoder_relu_1 (ReLU)        (None, 80, 1, 60)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_0 (Dense)      (None, 80, 1, 80)         4880      \n",
      "_________________________________________________________________\n",
      "decoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "decoder_relu_0 (ReLU)        (None, 80, 1, 80)         0         \n",
      "_________________________________________________________________\n",
      "decoder_last_layer (Dense)   (None, 80, 1, 1)          81        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 80, 1, 1)          0         \n",
      "=================================================================\n",
      "Total params: 39,281\n",
      "Trainable params: 38,961\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 19)                37299     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          39281     \n",
      "=================================================================\n",
      "Total params: 76,580\n",
      "Trainable params: 75,940\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "730/730 [==============================] - 18s 25ms/step - loss: 0.0077 - mean_squared_error: 0.0077 - accuracy: 0.0067 - val_loss: 2.2796e-04 - val_mean_squared_error: 2.2796e-04 - val_accuracy: 0.0060\n",
      "Epoch 2/25\n",
      "730/730 [==============================] - 18s 25ms/step - loss: 1.8463e-04 - mean_squared_error: 1.8463e-04 - accuracy: 0.0067 - val_loss: 1.2615e-04 - val_mean_squared_error: 1.2615e-04 - val_accuracy: 0.0060\n",
      "Epoch 3/25\n",
      "730/730 [==============================] - 18s 25ms/step - loss: 1.1479e-04 - mean_squared_error: 1.1479e-04 - accuracy: 0.0067 - val_loss: 9.6675e-05 - val_mean_squared_error: 9.6675e-05 - val_accuracy: 0.0060\n",
      "Epoch 4/25\n",
      "730/730 [==============================] - 19s 26ms/step - loss: 9.2527e-05 - mean_squared_error: 9.2527e-05 - accuracy: 0.0067 - val_loss: 8.4008e-05 - val_mean_squared_error: 8.4008e-05 - val_accuracy: 0.0060\n",
      "Epoch 5/25\n",
      "730/730 [==============================] - 18s 25ms/step - loss: 8.2753e-05 - mean_squared_error: 8.2753e-05 - accuracy: 0.0067 - val_loss: 7.9593e-05 - val_mean_squared_error: 7.9593e-05 - val_accuracy: 0.0060\n",
      "Epoch 6/25\n",
      "730/730 [==============================] - 18s 25ms/step - loss: 7.7469e-05 - mean_squared_error: 7.7469e-05 - accuracy: 0.0067 - val_loss: 7.3679e-05 - val_mean_squared_error: 7.3679e-05 - val_accuracy: 0.0060\n",
      "Epoch 7/25\n",
      "730/730 [==============================] - 18s 25ms/step - loss: 7.4364e-05 - mean_squared_error: 7.4364e-05 - accuracy: 0.0067 - val_loss: 7.1069e-05 - val_mean_squared_error: 7.1069e-05 - val_accuracy: 0.0060\n",
      "Epoch 8/25\n",
      "730/730 [==============================] - 19s 26ms/step - loss: 7.2202e-05 - mean_squared_error: 7.2202e-05 - accuracy: 0.0067 - val_loss: 6.9415e-05 - val_mean_squared_error: 6.9415e-05 - val_accuracy: 0.0060\n",
      "Epoch 9/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 7.0685e-05 - mean_squared_error: 7.0685e-05 - accuracy: 0.0067 - val_loss: 6.8766e-05 - val_mean_squared_error: 6.8766e-05 - val_accuracy: 0.0060\n",
      "Epoch 10/25\n",
      "730/730 [==============================] - 19s 26ms/step - loss: 6.9780e-05 - mean_squared_error: 6.9780e-05 - accuracy: 0.0067 - val_loss: 6.8128e-05 - val_mean_squared_error: 6.8128e-05 - val_accuracy: 0.0060\n",
      "Epoch 11/25\n",
      "730/730 [==============================] - 18s 24ms/step - loss: 6.9534e-05 - mean_squared_error: 6.9534e-05 - accuracy: 0.0067 - val_loss: 6.8997e-05 - val_mean_squared_error: 6.8997e-05 - val_accuracy: 0.0060\n",
      "Epoch 12/25\n",
      "730/730 [==============================] - 18s 25ms/step - loss: 6.8949e-05 - mean_squared_error: 6.8949e-05 - accuracy: 0.0067 - val_loss: 6.9348e-05 - val_mean_squared_error: 6.9348e-05 - val_accuracy: 0.0060\n",
      "Epoch 13/25\n",
      "730/730 [==============================] - 18s 24ms/step - loss: 6.8689e-05 - mean_squared_error: 6.8689e-05 - accuracy: 0.0067 - val_loss: 6.6943e-05 - val_mean_squared_error: 6.6943e-05 - val_accuracy: 0.0060\n",
      "Epoch 14/25\n",
      "730/730 [==============================] - 18s 25ms/step - loss: 6.8340e-05 - mean_squared_error: 6.8339e-05 - accuracy: 0.0067 - val_loss: 6.6453e-05 - val_mean_squared_error: 6.6453e-05 - val_accuracy: 0.0060\n",
      "Epoch 15/25\n",
      "730/730 [==============================] - 18s 24ms/step - loss: 6.8320e-05 - mean_squared_error: 6.8320e-05 - accuracy: 0.0067 - val_loss: 6.6779e-05 - val_mean_squared_error: 6.6779e-05 - val_accuracy: 0.0060\n",
      "Epoch 16/25\n",
      "730/730 [==============================] - 18s 25ms/step - loss: 6.8017e-05 - mean_squared_error: 6.8017e-05 - accuracy: 0.0067 - val_loss: 6.6777e-05 - val_mean_squared_error: 6.6777e-05 - val_accuracy: 0.0060\n",
      "Epoch 17/25\n",
      "730/730 [==============================] - 19s 25ms/step - loss: 6.8127e-05 - mean_squared_error: 6.8127e-05 - accuracy: 0.0067 - val_loss: 6.6610e-05 - val_mean_squared_error: 6.6610e-05 - val_accuracy: 0.0060\n",
      "Epoch 18/25\n",
      "730/730 [==============================] - 18s 24ms/step - loss: 6.7732e-05 - mean_squared_error: 6.7732e-05 - accuracy: 0.0067 - val_loss: 6.6508e-05 - val_mean_squared_error: 6.6508e-05 - val_accuracy: 0.0060\n",
      "Epoch 19/25\n",
      "730/730 [==============================] - 19s 26ms/step - loss: 6.7693e-05 - mean_squared_error: 6.7693e-05 - accuracy: 0.0067 - val_loss: 6.6234e-05 - val_mean_squared_error: 6.6234e-05 - val_accuracy: 0.0060\n",
      "Epoch 20/25\n",
      "730/730 [==============================] - 18s 25ms/step - loss: 6.7509e-05 - mean_squared_error: 6.7509e-05 - accuracy: 0.0067 - val_loss: 6.6034e-05 - val_mean_squared_error: 6.6034e-05 - val_accuracy: 0.0060\n",
      "Epoch 21/25\n",
      "730/730 [==============================] - 18s 25ms/step - loss: 6.7615e-05 - mean_squared_error: 6.7615e-05 - accuracy: 0.0067 - val_loss: 6.7717e-05 - val_mean_squared_error: 6.7717e-05 - val_accuracy: 0.0060\n",
      "Epoch 22/25\n",
      "730/730 [==============================] - 18s 25ms/step - loss: 6.7196e-05 - mean_squared_error: 6.7196e-05 - accuracy: 0.0067 - val_loss: 6.5861e-05 - val_mean_squared_error: 6.5861e-05 - val_accuracy: 0.0060\n",
      "Epoch 23/25\n",
      "730/730 [==============================] - 18s 25ms/step - loss: 6.7481e-05 - mean_squared_error: 6.7480e-05 - accuracy: 0.0067 - val_loss: 6.6834e-05 - val_mean_squared_error: 6.6834e-05 - val_accuracy: 0.0060\n",
      "Epoch 24/25\n",
      "730/730 [==============================] - 19s 26ms/step - loss: 6.7190e-05 - mean_squared_error: 6.7190e-05 - accuracy: 0.0067 - val_loss: 6.6739e-05 - val_mean_squared_error: 6.6739e-05 - val_accuracy: 0.0060\n",
      "Epoch 25/25\n",
      "730/730 [==============================] - 20s 27ms/step - loss: 6.7246e-05 - mean_squared_error: 6.7246e-05 - accuracy: 0.0067 - val_loss: 6.5731e-05 - val_mean_squared_error: 6.5731e-05 - val_accuracy: 0.0060\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 19)                37299     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          39281     \n",
      "=================================================================\n",
      "Total params: 76,580\n",
      "Trainable params: 75,940\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 19)                30419     \n",
      "=================================================================\n",
      "Total params: 37,299\n",
      "Trainable params: 36,979\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 6.8505e-05 - mean_squared_error: 6.8505e-05 - accuracy: 0.0060\n",
      "MSE results: 6.850479257991537e-05\n",
      "accuracy results: 0.005996230989694595\n",
      "metrics names ['loss', 'mean_squared_error', 'accuracy']\n",
      "fold iteration # 3  lat dim 19\n",
      "MSE (valid) [6.933927215868607e-05, 6.850479257991537e-05], lat dim 19\n",
      "Train idx = [    1     2     3 ... 29181 29182 29183] test idx = [    0     6    11 ... 29177 29178 29179]\n",
      "training set size=(23347, 80, 1, 1)\n",
      "test set size=(5837, 80, 1, 1)\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 19)                30419     \n",
      "=================================================================\n",
      "Total params: 37,299\n",
      "Trainable params: 36,979\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 19)]              0         \n",
      "_________________________________________________________________\n",
      "dec_dense_4_reshape (Dense)  (None, 1600)              32000     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_2 (Dense)      (None, 80, 1, 20)         420       \n",
      "_________________________________________________________________\n",
      "decoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "decoder_relu_2 (ReLU)        (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_1 (Dense)      (None, 80, 1, 60)         1260      \n",
      "_________________________________________________________________\n",
      "decoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "decoder_relu_1 (ReLU)        (None, 80, 1, 60)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_0 (Dense)      (None, 80, 1, 80)         4880      \n",
      "_________________________________________________________________\n",
      "decoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "decoder_relu_0 (ReLU)        (None, 80, 1, 80)         0         \n",
      "_________________________________________________________________\n",
      "decoder_last_layer (Dense)   (None, 80, 1, 1)          81        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 80, 1, 1)          0         \n",
      "=================================================================\n",
      "Total params: 39,281\n",
      "Trainable params: 38,961\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 19)                37299     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          39281     \n",
      "=================================================================\n",
      "Total params: 76,580\n",
      "Trainable params: 75,940\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "730/730 [==============================] - 18s 25ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - accuracy: 0.0063 - val_loss: 2.3056e-04 - val_mean_squared_error: 2.3056e-04 - val_accuracy: 0.0079\n",
      "Epoch 2/25\n",
      "730/730 [==============================] - 18s 24ms/step - loss: 1.7472e-04 - mean_squared_error: 1.7473e-04 - accuracy: 0.0063 - val_loss: 1.3032e-04 - val_mean_squared_error: 1.3032e-04 - val_accuracy: 0.0079\n",
      "Epoch 3/25\n",
      "730/730 [==============================] - 18s 25ms/step - loss: 1.1205e-04 - mean_squared_error: 1.1205e-04 - accuracy: 0.0063 - val_loss: 9.8649e-05 - val_mean_squared_error: 9.8649e-05 - val_accuracy: 0.0079\n",
      "Epoch 4/25\n",
      "730/730 [==============================] - 17s 24ms/step - loss: 9.0413e-05 - mean_squared_error: 9.0413e-05 - accuracy: 0.0063 - val_loss: 8.9362e-05 - val_mean_squared_error: 8.9362e-05 - val_accuracy: 0.0079\n",
      "Epoch 5/25\n",
      "730/730 [==============================] - 17s 24ms/step - loss: 8.0294e-05 - mean_squared_error: 8.0294e-05 - accuracy: 0.0063 - val_loss: 8.1050e-05 - val_mean_squared_error: 8.1050e-05 - val_accuracy: 0.0079\n",
      "Epoch 6/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.5737e-05 - mean_squared_error: 7.5737e-05 - accuracy: 0.0063 - val_loss: 7.6123e-05 - val_mean_squared_error: 7.6123e-05 - val_accuracy: 0.0079\n",
      "Epoch 7/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 7.2944e-05 - mean_squared_error: 7.2944e-05 - accuracy: 0.0063 - val_loss: 7.6507e-05 - val_mean_squared_error: 7.6507e-05 - val_accuracy: 0.0079\n",
      "Epoch 8/25\n",
      "730/730 [==============================] - 17s 24ms/step - loss: 7.1234e-05 - mean_squared_error: 7.1234e-05 - accuracy: 0.0063 - val_loss: 7.2442e-05 - val_mean_squared_error: 7.2442e-05 - val_accuracy: 0.0079\n",
      "Epoch 9/25\n",
      "730/730 [==============================] - 18s 25ms/step - loss: 6.9627e-05 - mean_squared_error: 6.9627e-05 - accuracy: 0.0063 - val_loss: 7.1648e-05 - val_mean_squared_error: 7.1648e-05 - val_accuracy: 0.0079\n",
      "Epoch 10/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.8757e-05 - mean_squared_error: 6.8757e-05 - accuracy: 0.0063 - val_loss: 7.1214e-05 - val_mean_squared_error: 7.1214e-05 - val_accuracy: 0.0079\n",
      "Epoch 11/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.8341e-05 - mean_squared_error: 6.8341e-05 - accuracy: 0.0063 - val_loss: 7.2896e-05 - val_mean_squared_error: 7.2896e-05 - val_accuracy: 0.0079\n",
      "Epoch 12/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.7972e-05 - mean_squared_error: 6.7972e-05 - accuracy: 0.0063 - val_loss: 7.1840e-05 - val_mean_squared_error: 7.1840e-05 - val_accuracy: 0.0079\n",
      "Epoch 13/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.8025e-05 - mean_squared_error: 6.8025e-05 - accuracy: 0.0063 - val_loss: 7.0730e-05 - val_mean_squared_error: 7.0730e-05 - val_accuracy: 0.0079\n",
      "Epoch 14/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.7387e-05 - mean_squared_error: 6.7387e-05 - accuracy: 0.0063 - val_loss: 7.0585e-05 - val_mean_squared_error: 7.0585e-05 - val_accuracy: 0.0079\n",
      "Epoch 15/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.7367e-05 - mean_squared_error: 6.7367e-05 - accuracy: 0.0063 - val_loss: 7.0754e-05 - val_mean_squared_error: 7.0754e-05 - val_accuracy: 0.0079\n",
      "Epoch 16/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.7315e-05 - mean_squared_error: 6.7315e-05 - accuracy: 0.0063 - val_loss: 6.9794e-05 - val_mean_squared_error: 6.9794e-05 - val_accuracy: 0.0079\n",
      "Epoch 17/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6865e-05 - mean_squared_error: 6.6865e-05 - accuracy: 0.0063 - val_loss: 6.9965e-05 - val_mean_squared_error: 6.9965e-05 - val_accuracy: 0.0079\n",
      "Epoch 18/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6903e-05 - mean_squared_error: 6.6904e-05 - accuracy: 0.0063 - val_loss: 7.0940e-05 - val_mean_squared_error: 7.0940e-05 - val_accuracy: 0.0079\n",
      "Epoch 19/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.7075e-05 - mean_squared_error: 6.7075e-05 - accuracy: 0.0063 - val_loss: 7.0000e-05 - val_mean_squared_error: 7.0000e-05 - val_accuracy: 0.0079\n",
      "Epoch 20/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6601e-05 - mean_squared_error: 6.6601e-05 - accuracy: 0.0063 - val_loss: 7.0381e-05 - val_mean_squared_error: 7.0381e-05 - val_accuracy: 0.0079\n",
      "Epoch 21/25\n",
      "730/730 [==============================] - 16s 23ms/step - loss: 6.6655e-05 - mean_squared_error: 6.6655e-05 - accuracy: 0.0063 - val_loss: 7.0949e-05 - val_mean_squared_error: 7.0949e-05 - val_accuracy: 0.0079\n",
      "Epoch 22/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6387e-05 - mean_squared_error: 6.6387e-05 - accuracy: 0.0063 - val_loss: 7.0596e-05 - val_mean_squared_error: 7.0596e-05 - val_accuracy: 0.0079\n",
      "Epoch 23/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6323e-05 - mean_squared_error: 6.6323e-05 - accuracy: 0.0063 - val_loss: 6.9398e-05 - val_mean_squared_error: 6.9398e-05 - val_accuracy: 0.0079\n",
      "Epoch 24/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6156e-05 - mean_squared_error: 6.6156e-05 - accuracy: 0.0063 - val_loss: 6.9622e-05 - val_mean_squared_error: 6.9622e-05 - val_accuracy: 0.0079\n",
      "Epoch 25/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.6211e-05 - mean_squared_error: 6.6211e-05 - accuracy: 0.0063 - val_loss: 7.0683e-05 - val_mean_squared_error: 7.0683e-05 - val_accuracy: 0.0079\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 19)                37299     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          39281     \n",
      "=================================================================\n",
      "Total params: 76,580\n",
      "Trainable params: 75,940\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 19)                30419     \n",
      "=================================================================\n",
      "Total params: 37,299\n",
      "Trainable params: 36,979\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 7.9029e-05 - mean_squared_error: 7.9029e-05 - accuracy: 0.0079\n",
      "MSE results: 7.90293124737218e-05\n",
      "accuracy results: 0.007880760356783867\n",
      "metrics names ['loss', 'mean_squared_error', 'accuracy']\n",
      "fold iteration # 4  lat dim 19\n",
      "MSE (valid) [6.933927215868607e-05, 6.850479257991537e-05, 7.90293124737218e-05], lat dim 19\n",
      "Train idx = [    0     1     3 ... 29181 29182 29183] test idx = [    2     7    12 ... 29168 29170 29174]\n",
      "training set size=(23347, 80, 1, 1)\n",
      "test set size=(5837, 80, 1, 1)\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 19)                30419     \n",
      "=================================================================\n",
      "Total params: 37,299\n",
      "Trainable params: 36,979\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 19)]              0         \n",
      "_________________________________________________________________\n",
      "dec_dense_4_reshape (Dense)  (None, 1600)              32000     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_2 (Dense)      (None, 80, 1, 20)         420       \n",
      "_________________________________________________________________\n",
      "decoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "decoder_relu_2 (ReLU)        (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_1 (Dense)      (None, 80, 1, 60)         1260      \n",
      "_________________________________________________________________\n",
      "decoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "decoder_relu_1 (ReLU)        (None, 80, 1, 60)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_0 (Dense)      (None, 80, 1, 80)         4880      \n",
      "_________________________________________________________________\n",
      "decoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "decoder_relu_0 (ReLU)        (None, 80, 1, 80)         0         \n",
      "_________________________________________________________________\n",
      "decoder_last_layer (Dense)   (None, 80, 1, 1)          81        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 80, 1, 1)          0         \n",
      "=================================================================\n",
      "Total params: 39,281\n",
      "Trainable params: 38,961\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 19)                37299     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          39281     \n",
      "=================================================================\n",
      "Total params: 76,580\n",
      "Trainable params: 75,940\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "730/730 [==============================] - 17s 24ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - accuracy: 0.0066 - val_loss: 2.7275e-04 - val_mean_squared_error: 2.7275e-04 - val_accuracy: 0.0065\n",
      "Epoch 2/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 2.0037e-04 - mean_squared_error: 2.0037e-04 - accuracy: 0.0066 - val_loss: 1.3788e-04 - val_mean_squared_error: 1.3788e-04 - val_accuracy: 0.0065\n",
      "Epoch 3/25\n",
      "730/730 [==============================] - 18s 25ms/step - loss: 1.2564e-04 - mean_squared_error: 1.2564e-04 - accuracy: 0.0066 - val_loss: 1.0365e-04 - val_mean_squared_error: 1.0365e-04 - val_accuracy: 0.0065\n",
      "Epoch 4/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 1.0326e-04 - mean_squared_error: 1.0326e-04 - accuracy: 0.0066 - val_loss: 8.4170e-05 - val_mean_squared_error: 8.4170e-05 - val_accuracy: 0.0065\n",
      "Epoch 5/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 8.8631e-05 - mean_squared_error: 8.8631e-05 - accuracy: 0.0066 - val_loss: 7.6488e-05 - val_mean_squared_error: 7.6488e-05 - val_accuracy: 0.0065\n",
      "Epoch 6/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 8.1891e-05 - mean_squared_error: 8.1891e-05 - accuracy: 0.0066 - val_loss: 7.5499e-05 - val_mean_squared_error: 7.5499e-05 - val_accuracy: 0.0065\n",
      "Epoch 7/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.7024e-05 - mean_squared_error: 7.7024e-05 - accuracy: 0.0066 - val_loss: 6.8705e-05 - val_mean_squared_error: 6.8705e-05 - val_accuracy: 0.0065\n",
      "Epoch 8/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.4677e-05 - mean_squared_error: 7.4677e-05 - accuracy: 0.0066 - val_loss: 6.5610e-05 - val_mean_squared_error: 6.5610e-05 - val_accuracy: 0.0065\n",
      "Epoch 9/25\n",
      "730/730 [==============================] - 16s 23ms/step - loss: 7.2734e-05 - mean_squared_error: 7.2734e-05 - accuracy: 0.0066 - val_loss: 6.5587e-05 - val_mean_squared_error: 6.5587e-05 - val_accuracy: 0.0065\n",
      "Epoch 10/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.2090e-05 - mean_squared_error: 7.2090e-05 - accuracy: 0.0066 - val_loss: 6.4358e-05 - val_mean_squared_error: 6.4358e-05 - val_accuracy: 0.0065\n",
      "Epoch 11/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 7.0486e-05 - mean_squared_error: 7.0486e-05 - accuracy: 0.0066 - val_loss: 6.3326e-05 - val_mean_squared_error: 6.3326e-05 - val_accuracy: 0.0065\n",
      "Epoch 12/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.0555e-05 - mean_squared_error: 7.0555e-05 - accuracy: 0.0066 - val_loss: 6.2861e-05 - val_mean_squared_error: 6.2861e-05 - val_accuracy: 0.0065\n",
      "Epoch 13/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.9580e-05 - mean_squared_error: 6.9580e-05 - accuracy: 0.0066 - val_loss: 6.2700e-05 - val_mean_squared_error: 6.2700e-05 - val_accuracy: 0.0065\n",
      "Epoch 14/25\n",
      "730/730 [==============================] - 16s 23ms/step - loss: 6.9352e-05 - mean_squared_error: 6.9352e-05 - accuracy: 0.0066 - val_loss: 6.2566e-05 - val_mean_squared_error: 6.2566e-05 - val_accuracy: 0.0065\n",
      "Epoch 15/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.9750e-05 - mean_squared_error: 6.9750e-05 - accuracy: 0.0066 - val_loss: 6.2360e-05 - val_mean_squared_error: 6.2360e-05 - val_accuracy: 0.0065\n",
      "Epoch 16/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.9090e-05 - mean_squared_error: 6.9090e-05 - accuracy: 0.0066 - val_loss: 6.2767e-05 - val_mean_squared_error: 6.2767e-05 - val_accuracy: 0.0065\n",
      "Epoch 17/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.8970e-05 - mean_squared_error: 6.8970e-05 - accuracy: 0.0066 - val_loss: 6.2070e-05 - val_mean_squared_error: 6.2070e-05 - val_accuracy: 0.0065\n",
      "Epoch 18/25\n",
      "730/730 [==============================] - 17s 24ms/step - loss: 6.8700e-05 - mean_squared_error: 6.8700e-05 - accuracy: 0.0066 - val_loss: 6.4370e-05 - val_mean_squared_error: 6.4370e-05 - val_accuracy: 0.0065\n",
      "Epoch 19/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.8962e-05 - mean_squared_error: 6.8962e-05 - accuracy: 0.0066 - val_loss: 6.1922e-05 - val_mean_squared_error: 6.1922e-05 - val_accuracy: 0.0065\n",
      "Epoch 20/25\n",
      "730/730 [==============================] - 17s 24ms/step - loss: 6.8358e-05 - mean_squared_error: 6.8358e-05 - accuracy: 0.0066 - val_loss: 6.1798e-05 - val_mean_squared_error: 6.1798e-05 - val_accuracy: 0.0065\n",
      "Epoch 21/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.8478e-05 - mean_squared_error: 6.8478e-05 - accuracy: 0.0066 - val_loss: 6.1984e-05 - val_mean_squared_error: 6.1984e-05 - val_accuracy: 0.0065\n",
      "Epoch 22/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.8385e-05 - mean_squared_error: 6.8385e-05 - accuracy: 0.0066 - val_loss: 6.1968e-05 - val_mean_squared_error: 6.1968e-05 - val_accuracy: 0.0065\n",
      "Epoch 23/25\n",
      "730/730 [==============================] - 18s 25ms/step - loss: 6.8201e-05 - mean_squared_error: 6.8201e-05 - accuracy: 0.0066 - val_loss: 6.1727e-05 - val_mean_squared_error: 6.1727e-05 - val_accuracy: 0.0065\n",
      "Epoch 24/25\n",
      "730/730 [==============================] - 18s 25ms/step - loss: 6.8272e-05 - mean_squared_error: 6.8272e-05 - accuracy: 0.0066 - val_loss: 6.2337e-05 - val_mean_squared_error: 6.2337e-05 - val_accuracy: 0.0065\n",
      "Epoch 25/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.7995e-05 - mean_squared_error: 6.7995e-05 - accuracy: 0.0066 - val_loss: 6.1616e-05 - val_mean_squared_error: 6.1616e-05 - val_accuracy: 0.0065\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 19)                37299     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          39281     \n",
      "=================================================================\n",
      "Total params: 76,580\n",
      "Trainable params: 75,940\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 19)                30419     \n",
      "=================================================================\n",
      "Total params: 37,299\n",
      "Trainable params: 36,979\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 6.3819e-05 - mean_squared_error: 6.3819e-05 - accuracy: 0.0065\n",
      "MSE results: 6.381917773978785e-05\n",
      "accuracy results: 0.006510193459689617\n",
      "metrics names ['loss', 'mean_squared_error', 'accuracy']\n",
      "fold iteration # 5  lat dim 19\n",
      "MSE (valid) [6.933927215868607e-05, 6.850479257991537e-05, 7.90293124737218e-05, 6.381917773978785e-05], lat dim 19\n",
      "Train idx = [    0     1     2 ... 29177 29178 29179] test idx = [    5    13    22 ... 29181 29182 29183]\n",
      "training set size=(23348, 80, 1, 1)\n",
      "test set size=(5836, 80, 1, 1)\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 19)                30419     \n",
      "=================================================================\n",
      "Total params: 37,299\n",
      "Trainable params: 36,979\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 19)]              0         \n",
      "_________________________________________________________________\n",
      "dec_dense_4_reshape (Dense)  (None, 1600)              32000     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_2 (Dense)      (None, 80, 1, 20)         420       \n",
      "_________________________________________________________________\n",
      "decoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "decoder_relu_2 (ReLU)        (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_1 (Dense)      (None, 80, 1, 60)         1260      \n",
      "_________________________________________________________________\n",
      "decoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "decoder_relu_1 (ReLU)        (None, 80, 1, 60)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_0 (Dense)      (None, 80, 1, 80)         4880      \n",
      "_________________________________________________________________\n",
      "decoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "decoder_relu_0 (ReLU)        (None, 80, 1, 80)         0         \n",
      "_________________________________________________________________\n",
      "decoder_last_layer (Dense)   (None, 80, 1, 1)          81        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 80, 1, 1)          0         \n",
      "=================================================================\n",
      "Total params: 39,281\n",
      "Trainable params: 38,961\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 19)                37299     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          39281     \n",
      "=================================================================\n",
      "Total params: 76,580\n",
      "Trainable params: 75,940\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "730/730 [==============================] - 18s 24ms/step - loss: 0.0088 - mean_squared_error: 0.0088 - accuracy: 0.0068 - val_loss: 3.0000e-04 - val_mean_squared_error: 3.0000e-04 - val_accuracy: 0.0057\n",
      "Epoch 2/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 2.0837e-04 - mean_squared_error: 2.0837e-04 - accuracy: 0.0068 - val_loss: 1.3960e-04 - val_mean_squared_error: 1.3960e-04 - val_accuracy: 0.0057\n",
      "Epoch 3/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 1.2843e-04 - mean_squared_error: 1.2843e-04 - accuracy: 0.0068 - val_loss: 1.0679e-04 - val_mean_squared_error: 1.0679e-04 - val_accuracy: 0.0057\n",
      "Epoch 4/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 1.0279e-04 - mean_squared_error: 1.0279e-04 - accuracy: 0.0068 - val_loss: 9.1770e-05 - val_mean_squared_error: 9.1770e-05 - val_accuracy: 0.0057\n",
      "Epoch 5/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 8.9911e-05 - mean_squared_error: 8.9911e-05 - accuracy: 0.0068 - val_loss: 9.3229e-05 - val_mean_squared_error: 9.3229e-05 - val_accuracy: 0.0057\n",
      "Epoch 6/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 8.2017e-05 - mean_squared_error: 8.2017e-05 - accuracy: 0.0068 - val_loss: 7.9044e-05 - val_mean_squared_error: 7.9044e-05 - val_accuracy: 0.0057\n",
      "Epoch 7/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.7571e-05 - mean_squared_error: 7.7571e-05 - accuracy: 0.0068 - val_loss: 7.3501e-05 - val_mean_squared_error: 7.3501e-05 - val_accuracy: 0.0057\n",
      "Epoch 8/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.3725e-05 - mean_squared_error: 7.3725e-05 - accuracy: 0.0068 - val_loss: 7.0593e-05 - val_mean_squared_error: 7.0593e-05 - val_accuracy: 0.0057\n",
      "Epoch 9/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.1841e-05 - mean_squared_error: 7.1841e-05 - accuracy: 0.0068 - val_loss: 6.9636e-05 - val_mean_squared_error: 6.9636e-05 - val_accuracy: 0.0057\n",
      "Epoch 10/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.0703e-05 - mean_squared_error: 7.0703e-05 - accuracy: 0.0068 - val_loss: 6.9971e-05 - val_mean_squared_error: 6.9971e-05 - val_accuracy: 0.0057\n",
      "Epoch 11/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.9700e-05 - mean_squared_error: 6.9700e-05 - accuracy: 0.0068 - val_loss: 7.0407e-05 - val_mean_squared_error: 7.0407e-05 - val_accuracy: 0.0057\n",
      "Epoch 12/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.9227e-05 - mean_squared_error: 6.9227e-05 - accuracy: 0.0068 - val_loss: 6.7943e-05 - val_mean_squared_error: 6.7943e-05 - val_accuracy: 0.0057\n",
      "Epoch 13/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.8648e-05 - mean_squared_error: 6.8648e-05 - accuracy: 0.0068 - val_loss: 6.7673e-05 - val_mean_squared_error: 6.7673e-05 - val_accuracy: 0.0057\n",
      "Epoch 14/25\n",
      "730/730 [==============================] - 17s 24ms/step - loss: 6.8291e-05 - mean_squared_error: 6.8291e-05 - accuracy: 0.0068 - val_loss: 6.7953e-05 - val_mean_squared_error: 6.7953e-05 - val_accuracy: 0.0057\n",
      "Epoch 15/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.8155e-05 - mean_squared_error: 6.8155e-05 - accuracy: 0.0068 - val_loss: 6.8449e-05 - val_mean_squared_error: 6.8449e-05 - val_accuracy: 0.0057\n",
      "Epoch 16/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.7672e-05 - mean_squared_error: 6.7672e-05 - accuracy: 0.0068 - val_loss: 6.7013e-05 - val_mean_squared_error: 6.7013e-05 - val_accuracy: 0.0057\n",
      "Epoch 17/25\n",
      "730/730 [==============================] - 16s 23ms/step - loss: 6.7990e-05 - mean_squared_error: 6.7990e-05 - accuracy: 0.0068 - val_loss: 6.7511e-05 - val_mean_squared_error: 6.7511e-05 - val_accuracy: 0.0057\n",
      "Epoch 18/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.7546e-05 - mean_squared_error: 6.7546e-05 - accuracy: 0.0068 - val_loss: 6.6912e-05 - val_mean_squared_error: 6.6912e-05 - val_accuracy: 0.0057\n",
      "Epoch 19/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.7343e-05 - mean_squared_error: 6.7343e-05 - accuracy: 0.0068 - val_loss: 6.7408e-05 - val_mean_squared_error: 6.7408e-05 - val_accuracy: 0.0057\n",
      "Epoch 20/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.7040e-05 - mean_squared_error: 6.7040e-05 - accuracy: 0.0068 - val_loss: 6.7386e-05 - val_mean_squared_error: 6.7387e-05 - val_accuracy: 0.0057\n",
      "Epoch 21/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.7006e-05 - mean_squared_error: 6.7006e-05 - accuracy: 0.0068 - val_loss: 6.6722e-05 - val_mean_squared_error: 6.6722e-05 - val_accuracy: 0.0057\n",
      "Epoch 22/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6869e-05 - mean_squared_error: 6.6869e-05 - accuracy: 0.0068 - val_loss: 6.6688e-05 - val_mean_squared_error: 6.6688e-05 - val_accuracy: 0.0057\n",
      "Epoch 23/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6700e-05 - mean_squared_error: 6.6700e-05 - accuracy: 0.0068 - val_loss: 6.7766e-05 - val_mean_squared_error: 6.7766e-05 - val_accuracy: 0.0057\n",
      "Epoch 24/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.6604e-05 - mean_squared_error: 6.6604e-05 - accuracy: 0.0068 - val_loss: 6.7190e-05 - val_mean_squared_error: 6.7190e-05 - val_accuracy: 0.0057\n",
      "Epoch 25/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.6456e-05 - mean_squared_error: 6.6456e-05 - accuracy: 0.0068 - val_loss: 6.6632e-05 - val_mean_squared_error: 6.6632e-05 - val_accuracy: 0.0057\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 19)                37299     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          39281     \n",
      "=================================================================\n",
      "Total params: 76,580\n",
      "Trainable params: 75,940\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 19)                30419     \n",
      "=================================================================\n",
      "Total params: 37,299\n",
      "Trainable params: 36,979\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 6.8972e-05 - mean_squared_error: 6.8972e-05 - accuracy: 0.0057\n",
      "MSE results: 6.89723456162028e-05\n",
      "accuracy results: 0.005654558073729277\n",
      "metrics names ['loss', 'mean_squared_error', 'accuracy']\n",
      "fold iteration # 6  lat dim 19\n",
      "MSE (valid) [6.933927215868607e-05, 6.850479257991537e-05, 7.90293124737218e-05, 6.381917773978785e-05, 6.89723456162028e-05], lat dim 19\n",
      "Train idx = [    1     2     3 ... 29178 29180 29183] test idx = [    0    20    30 ... 29179 29181 29182]\n",
      "training set size=(23347, 80, 1, 1)\n",
      "test set size=(5837, 80, 1, 1)\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 20)                32020     \n",
      "=================================================================\n",
      "Total params: 38,900\n",
      "Trainable params: 38,580\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 20)]              0         \n",
      "_________________________________________________________________\n",
      "dec_dense_4_reshape (Dense)  (None, 1600)              33600     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_2 (Dense)      (None, 80, 1, 20)         420       \n",
      "_________________________________________________________________\n",
      "decoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "decoder_relu_2 (ReLU)        (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_1 (Dense)      (None, 80, 1, 60)         1260      \n",
      "_________________________________________________________________\n",
      "decoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "decoder_relu_1 (ReLU)        (None, 80, 1, 60)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_0 (Dense)      (None, 80, 1, 80)         4880      \n",
      "_________________________________________________________________\n",
      "decoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "decoder_relu_0 (ReLU)        (None, 80, 1, 80)         0         \n",
      "_________________________________________________________________\n",
      "decoder_last_layer (Dense)   (None, 80, 1, 1)          81        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 80, 1, 1)          0         \n",
      "=================================================================\n",
      "Total params: 40,881\n",
      "Trainable params: 40,561\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 20)                38900     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          40881     \n",
      "=================================================================\n",
      "Total params: 79,781\n",
      "Trainable params: 79,141\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "730/730 [==============================] - 17s 24ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - accuracy: 0.0069 - val_loss: 2.3445e-04 - val_mean_squared_error: 2.3445e-04 - val_accuracy: 0.0055\n",
      "Epoch 2/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 1.7804e-04 - mean_squared_error: 1.7804e-04 - accuracy: 0.0069 - val_loss: 1.2552e-04 - val_mean_squared_error: 1.2552e-04 - val_accuracy: 0.0055\n",
      "Epoch 3/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 1.1231e-04 - mean_squared_error: 1.1231e-04 - accuracy: 0.0069 - val_loss: 9.5512e-05 - val_mean_squared_error: 9.5512e-05 - val_accuracy: 0.0055\n",
      "Epoch 4/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 9.1753e-05 - mean_squared_error: 9.1753e-05 - accuracy: 0.0069 - val_loss: 8.3743e-05 - val_mean_squared_error: 8.3743e-05 - val_accuracy: 0.0055\n",
      "Epoch 5/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 8.1871e-05 - mean_squared_error: 8.1871e-05 - accuracy: 0.0069 - val_loss: 7.5727e-05 - val_mean_squared_error: 7.5727e-05 - val_accuracy: 0.0055\n",
      "Epoch 6/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.6373e-05 - mean_squared_error: 7.6373e-05 - accuracy: 0.0069 - val_loss: 7.2019e-05 - val_mean_squared_error: 7.2019e-05 - val_accuracy: 0.0055\n",
      "Epoch 7/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.3519e-05 - mean_squared_error: 7.3519e-05 - accuracy: 0.0069 - val_loss: 7.1958e-05 - val_mean_squared_error: 7.1958e-05 - val_accuracy: 0.0055\n",
      "Epoch 8/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.3123e-05 - mean_squared_error: 7.3123e-05 - accuracy: 0.0069 - val_loss: 6.8507e-05 - val_mean_squared_error: 6.8507e-05 - val_accuracy: 0.0055\n",
      "Epoch 9/25\n",
      "730/730 [==============================] - 16s 23ms/step - loss: 7.0618e-05 - mean_squared_error: 7.0618e-05 - accuracy: 0.0069 - val_loss: 6.7922e-05 - val_mean_squared_error: 6.7922e-05 - val_accuracy: 0.0055\n",
      "Epoch 10/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.9969e-05 - mean_squared_error: 6.9969e-05 - accuracy: 0.0069 - val_loss: 6.6878e-05 - val_mean_squared_error: 6.6878e-05 - val_accuracy: 0.0055\n",
      "Epoch 11/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.9095e-05 - mean_squared_error: 6.9095e-05 - accuracy: 0.0069 - val_loss: 6.6745e-05 - val_mean_squared_error: 6.6745e-05 - val_accuracy: 0.0055\n",
      "Epoch 12/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.9378e-05 - mean_squared_error: 6.9378e-05 - accuracy: 0.0069 - val_loss: 6.6651e-05 - val_mean_squared_error: 6.6651e-05 - val_accuracy: 0.0055\n",
      "Epoch 13/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.8487e-05 - mean_squared_error: 6.8487e-05 - accuracy: 0.0069 - val_loss: 6.6259e-05 - val_mean_squared_error: 6.6259e-05 - val_accuracy: 0.0055\n",
      "Epoch 14/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.9011e-05 - mean_squared_error: 6.9010e-05 - accuracy: 0.0069 - val_loss: 6.7072e-05 - val_mean_squared_error: 6.7072e-05 - val_accuracy: 0.0055\n",
      "Epoch 15/25\n",
      "730/730 [==============================] - 18s 24ms/step - loss: 6.8173e-05 - mean_squared_error: 6.8173e-05 - accuracy: 0.0069 - val_loss: 6.5641e-05 - val_mean_squared_error: 6.5641e-05 - val_accuracy: 0.0055\n",
      "Epoch 16/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.7965e-05 - mean_squared_error: 6.7965e-05 - accuracy: 0.0069 - val_loss: 6.5529e-05 - val_mean_squared_error: 6.5529e-05 - val_accuracy: 0.0055\n",
      "Epoch 17/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.7588e-05 - mean_squared_error: 6.7588e-05 - accuracy: 0.0069 - val_loss: 6.6224e-05 - val_mean_squared_error: 6.6224e-05 - val_accuracy: 0.0055\n",
      "Epoch 18/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.7547e-05 - mean_squared_error: 6.7547e-05 - accuracy: 0.0069 - val_loss: 6.5466e-05 - val_mean_squared_error: 6.5466e-05 - val_accuracy: 0.0055\n",
      "Epoch 19/25\n",
      "730/730 [==============================] - 16s 23ms/step - loss: 6.7353e-05 - mean_squared_error: 6.7353e-05 - accuracy: 0.0069 - val_loss: 6.5751e-05 - val_mean_squared_error: 6.5751e-05 - val_accuracy: 0.0055\n",
      "Epoch 20/25\n",
      "730/730 [==============================] - 16s 23ms/step - loss: 6.7273e-05 - mean_squared_error: 6.7272e-05 - accuracy: 0.0069 - val_loss: 6.5493e-05 - val_mean_squared_error: 6.5493e-05 - val_accuracy: 0.0055\n",
      "Epoch 21/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.7182e-05 - mean_squared_error: 6.7182e-05 - accuracy: 0.0069 - val_loss: 6.5767e-05 - val_mean_squared_error: 6.5767e-05 - val_accuracy: 0.0055\n",
      "Epoch 22/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.7259e-05 - mean_squared_error: 6.7259e-05 - accuracy: 0.0069 - val_loss: 6.6135e-05 - val_mean_squared_error: 6.6135e-05 - val_accuracy: 0.0055\n",
      "Epoch 23/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6997e-05 - mean_squared_error: 6.6997e-05 - accuracy: 0.0069 - val_loss: 6.5297e-05 - val_mean_squared_error: 6.5297e-05 - val_accuracy: 0.0055\n",
      "Epoch 24/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6878e-05 - mean_squared_error: 6.6878e-05 - accuracy: 0.0069 - val_loss: 6.5640e-05 - val_mean_squared_error: 6.5640e-05 - val_accuracy: 0.0055\n",
      "Epoch 25/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6589e-05 - mean_squared_error: 6.6589e-05 - accuracy: 0.0069 - val_loss: 6.5085e-05 - val_mean_squared_error: 6.5085e-05 - val_accuracy: 0.0055\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 20)                38900     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          40881     \n",
      "=================================================================\n",
      "Total params: 79,781\n",
      "Trainable params: 79,141\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 20)                32020     \n",
      "=================================================================\n",
      "Total params: 38,900\n",
      "Trainable params: 38,580\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "  1/183 [..............................] - ETA: 0s - loss: 5.5510e-07 - mean_squared_error: 5.5510e-07 - accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0130s). Check your callbacks.\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 6.7440e-05 - mean_squared_error: 6.7440e-05 - accuracy: 0.0055\n",
      "MSE results: 6.743978156009689e-05\n",
      "accuracy results: 0.0054822685196995735\n",
      "metrics names ['loss', 'mean_squared_error', 'accuracy']\n",
      "fold iteration # 2  lat dim 20\n",
      "MSE (valid) [6.743978156009689e-05], lat dim 20\n",
      "Train idx = [    0     1     3 ... 29180 29181 29182] test idx = [    2    10    11 ... 29169 29175 29183]\n",
      "training set size=(23347, 80, 1, 1)\n",
      "test set size=(5837, 80, 1, 1)\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 20)                32020     \n",
      "=================================================================\n",
      "Total params: 38,900\n",
      "Trainable params: 38,580\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 20)]              0         \n",
      "_________________________________________________________________\n",
      "dec_dense_4_reshape (Dense)  (None, 1600)              33600     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_2 (Dense)      (None, 80, 1, 20)         420       \n",
      "_________________________________________________________________\n",
      "decoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "decoder_relu_2 (ReLU)        (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_1 (Dense)      (None, 80, 1, 60)         1260      \n",
      "_________________________________________________________________\n",
      "decoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "decoder_relu_1 (ReLU)        (None, 80, 1, 60)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_0 (Dense)      (None, 80, 1, 80)         4880      \n",
      "_________________________________________________________________\n",
      "decoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "decoder_relu_0 (ReLU)        (None, 80, 1, 80)         0         \n",
      "_________________________________________________________________\n",
      "decoder_last_layer (Dense)   (None, 80, 1, 1)          81        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 80, 1, 1)          0         \n",
      "=================================================================\n",
      "Total params: 40,881\n",
      "Trainable params: 40,561\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 20)                38900     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          40881     \n",
      "=================================================================\n",
      "Total params: 79,781\n",
      "Trainable params: 79,141\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "730/730 [==============================] - 18s 24ms/step - loss: 0.0086 - mean_squared_error: 0.0086 - accuracy: 0.0062 - val_loss: 2.8745e-04 - val_mean_squared_error: 2.8745e-04 - val_accuracy: 0.0081\n",
      "Epoch 2/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 2.0012e-04 - mean_squared_error: 2.0012e-04 - accuracy: 0.0062 - val_loss: 1.4503e-04 - val_mean_squared_error: 1.4503e-04 - val_accuracy: 0.0081\n",
      "Epoch 3/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 1.2642e-04 - mean_squared_error: 1.2642e-04 - accuracy: 0.0062 - val_loss: 1.0864e-04 - val_mean_squared_error: 1.0864e-04 - val_accuracy: 0.0081\n",
      "Epoch 4/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 1.0294e-04 - mean_squared_error: 1.0294e-04 - accuracy: 0.0062 - val_loss: 9.2737e-05 - val_mean_squared_error: 9.2738e-05 - val_accuracy: 0.0081\n",
      "Epoch 5/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 9.0222e-05 - mean_squared_error: 9.0222e-05 - accuracy: 0.0062 - val_loss: 8.2683e-05 - val_mean_squared_error: 8.2683e-05 - val_accuracy: 0.0081\n",
      "Epoch 6/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 8.2300e-05 - mean_squared_error: 8.2300e-05 - accuracy: 0.0062 - val_loss: 7.9508e-05 - val_mean_squared_error: 7.9508e-05 - val_accuracy: 0.0081\n",
      "Epoch 7/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.7105e-05 - mean_squared_error: 7.7105e-05 - accuracy: 0.0062 - val_loss: 7.5489e-05 - val_mean_squared_error: 7.5489e-05 - val_accuracy: 0.0081\n",
      "Epoch 8/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 7.4389e-05 - mean_squared_error: 7.4389e-05 - accuracy: 0.0062 - val_loss: 7.0190e-05 - val_mean_squared_error: 7.0190e-05 - val_accuracy: 0.0081\n",
      "Epoch 9/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.1702e-05 - mean_squared_error: 7.1702e-05 - accuracy: 0.0062 - val_loss: 6.9196e-05 - val_mean_squared_error: 6.9196e-05 - val_accuracy: 0.0081\n",
      "Epoch 10/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.0491e-05 - mean_squared_error: 7.0491e-05 - accuracy: 0.0062 - val_loss: 6.7647e-05 - val_mean_squared_error: 6.7647e-05 - val_accuracy: 0.0081\n",
      "Epoch 11/25\n",
      "730/730 [==============================] - 16s 23ms/step - loss: 6.9813e-05 - mean_squared_error: 6.9813e-05 - accuracy: 0.0062 - val_loss: 6.7085e-05 - val_mean_squared_error: 6.7085e-05 - val_accuracy: 0.0081\n",
      "Epoch 12/25\n",
      "730/730 [==============================] - 16s 23ms/step - loss: 6.9099e-05 - mean_squared_error: 6.9099e-05 - accuracy: 0.0062 - val_loss: 6.6503e-05 - val_mean_squared_error: 6.6503e-05 - val_accuracy: 0.0081\n",
      "Epoch 13/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 6.8488e-05 - mean_squared_error: 6.8488e-05 - accuracy: 0.0062 - val_loss: 6.6292e-05 - val_mean_squared_error: 6.6292e-05 - val_accuracy: 0.0081\n",
      "Epoch 14/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 6.8332e-05 - mean_squared_error: 6.8332e-05 - accuracy: 0.0062 - val_loss: 6.6268e-05 - val_mean_squared_error: 6.6268e-05 - val_accuracy: 0.0081\n",
      "Epoch 15/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.7590e-05 - mean_squared_error: 6.7590e-05 - accuracy: 0.0062 - val_loss: 6.6702e-05 - val_mean_squared_error: 6.6702e-05 - val_accuracy: 0.0081\n",
      "Epoch 16/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.7450e-05 - mean_squared_error: 6.7450e-05 - accuracy: 0.0062 - val_loss: 6.6087e-05 - val_mean_squared_error: 6.6087e-05 - val_accuracy: 0.0081\n",
      "Epoch 17/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.7557e-05 - mean_squared_error: 6.7557e-05 - accuracy: 0.0062 - val_loss: 6.7455e-05 - val_mean_squared_error: 6.7455e-05 - val_accuracy: 0.0081\n",
      "Epoch 18/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.7011e-05 - mean_squared_error: 6.7011e-05 - accuracy: 0.0062 - val_loss: 6.6463e-05 - val_mean_squared_error: 6.6463e-05 - val_accuracy: 0.0081\n",
      "Epoch 19/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6969e-05 - mean_squared_error: 6.6969e-05 - accuracy: 0.0062 - val_loss: 6.5680e-05 - val_mean_squared_error: 6.5680e-05 - val_accuracy: 0.0081\n",
      "Epoch 20/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.7127e-05 - mean_squared_error: 6.7127e-05 - accuracy: 0.0062 - val_loss: 6.5808e-05 - val_mean_squared_error: 6.5808e-05 - val_accuracy: 0.0081\n",
      "Epoch 21/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 6.6789e-05 - mean_squared_error: 6.6789e-05 - accuracy: 0.0062 - val_loss: 6.5635e-05 - val_mean_squared_error: 6.5635e-05 - val_accuracy: 0.0081\n",
      "Epoch 22/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 6.6787e-05 - mean_squared_error: 6.6787e-05 - accuracy: 0.0062 - val_loss: 6.5287e-05 - val_mean_squared_error: 6.5287e-05 - val_accuracy: 0.0081\n",
      "Epoch 23/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6492e-05 - mean_squared_error: 6.6492e-05 - accuracy: 0.0062 - val_loss: 6.5321e-05 - val_mean_squared_error: 6.5321e-05 - val_accuracy: 0.0081\n",
      "Epoch 24/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6359e-05 - mean_squared_error: 6.6359e-05 - accuracy: 0.0062 - val_loss: 6.5567e-05 - val_mean_squared_error: 6.5567e-05 - val_accuracy: 0.0081\n",
      "Epoch 25/25\n",
      "730/730 [==============================] - 18s 25ms/step - loss: 6.6378e-05 - mean_squared_error: 6.6378e-05 - accuracy: 0.0062 - val_loss: 6.6325e-05 - val_mean_squared_error: 6.6325e-05 - val_accuracy: 0.0081\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 20)                38900     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          40881     \n",
      "=================================================================\n",
      "Total params: 79,781\n",
      "Trainable params: 79,141\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 20)                32020     \n",
      "=================================================================\n",
      "Total params: 38,900\n",
      "Trainable params: 38,580\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 7.1049e-05 - mean_squared_error: 7.1049e-05 - accuracy: 0.0081\n",
      "MSE results: 7.104862743290141e-05\n",
      "accuracy results: 0.008052081800997257\n",
      "metrics names ['loss', 'mean_squared_error', 'accuracy']\n",
      "fold iteration # 3  lat dim 20\n",
      "MSE (valid) [6.743978156009689e-05, 7.104862743290141e-05], lat dim 20\n",
      "Train idx = [    0     2     4 ... 29181 29182 29183] test idx = [    1     3     5 ... 29164 29167 29180]\n",
      "training set size=(23347, 80, 1, 1)\n",
      "test set size=(5837, 80, 1, 1)\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 20)                32020     \n",
      "=================================================================\n",
      "Total params: 38,900\n",
      "Trainable params: 38,580\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 20)]              0         \n",
      "_________________________________________________________________\n",
      "dec_dense_4_reshape (Dense)  (None, 1600)              33600     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_2 (Dense)      (None, 80, 1, 20)         420       \n",
      "_________________________________________________________________\n",
      "decoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "decoder_relu_2 (ReLU)        (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_1 (Dense)      (None, 80, 1, 60)         1260      \n",
      "_________________________________________________________________\n",
      "decoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "decoder_relu_1 (ReLU)        (None, 80, 1, 60)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_0 (Dense)      (None, 80, 1, 80)         4880      \n",
      "_________________________________________________________________\n",
      "decoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "decoder_relu_0 (ReLU)        (None, 80, 1, 80)         0         \n",
      "_________________________________________________________________\n",
      "decoder_last_layer (Dense)   (None, 80, 1, 1)          81        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 80, 1, 1)          0         \n",
      "=================================================================\n",
      "Total params: 40,881\n",
      "Trainable params: 40,561\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 20)                38900     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          40881     \n",
      "=================================================================\n",
      "Total params: 79,781\n",
      "Trainable params: 79,141\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 0.0087 - mean_squared_error: 0.0087 - accuracy: 0.0067 - val_loss: 2.9637e-04 - val_mean_squared_error: 2.9637e-04 - val_accuracy: 0.0060\n",
      "Epoch 2/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 2.0287e-04 - mean_squared_error: 2.0287e-04 - accuracy: 0.0067 - val_loss: 1.4605e-04 - val_mean_squared_error: 1.4605e-04 - val_accuracy: 0.0060\n",
      "Epoch 3/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 1.2756e-04 - mean_squared_error: 1.2756e-04 - accuracy: 0.0067 - val_loss: 1.1473e-04 - val_mean_squared_error: 1.1473e-04 - val_accuracy: 0.0060\n",
      "Epoch 4/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 1.0149e-04 - mean_squared_error: 1.0149e-04 - accuracy: 0.0067 - val_loss: 1.0531e-04 - val_mean_squared_error: 1.0531e-04 - val_accuracy: 0.0060\n",
      "Epoch 5/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 8.9981e-05 - mean_squared_error: 8.9981e-05 - accuracy: 0.0067 - val_loss: 8.8948e-05 - val_mean_squared_error: 8.8948e-05 - val_accuracy: 0.0060\n",
      "Epoch 6/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 8.0652e-05 - mean_squared_error: 8.0652e-05 - accuracy: 0.0067 - val_loss: 9.4151e-05 - val_mean_squared_error: 9.4151e-05 - val_accuracy: 0.0060\n",
      "Epoch 7/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 7.6111e-05 - mean_squared_error: 7.6111e-05 - accuracy: 0.0067 - val_loss: 7.7378e-05 - val_mean_squared_error: 7.7378e-05 - val_accuracy: 0.0060\n",
      "Epoch 8/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 7.4012e-05 - mean_squared_error: 7.4012e-05 - accuracy: 0.0067 - val_loss: 7.6885e-05 - val_mean_squared_error: 7.6885e-05 - val_accuracy: 0.0060\n",
      "Epoch 9/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 7.0568e-05 - mean_squared_error: 7.0568e-05 - accuracy: 0.0067 - val_loss: 7.2789e-05 - val_mean_squared_error: 7.2789e-05 - val_accuracy: 0.0060\n",
      "Epoch 10/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 6.9521e-05 - mean_squared_error: 6.9521e-05 - accuracy: 0.0067 - val_loss: 7.1843e-05 - val_mean_squared_error: 7.1843e-05 - val_accuracy: 0.0060\n",
      "Epoch 11/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 6.8668e-05 - mean_squared_error: 6.8668e-05 - accuracy: 0.0067 - val_loss: 7.1205e-05 - val_mean_squared_error: 7.1205e-05 - val_accuracy: 0.0060\n",
      "Epoch 12/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.8020e-05 - mean_squared_error: 6.8020e-05 - accuracy: 0.0067 - val_loss: 7.2336e-05 - val_mean_squared_error: 7.2336e-05 - val_accuracy: 0.0060\n",
      "Epoch 13/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.7365e-05 - mean_squared_error: 6.7365e-05 - accuracy: 0.0067 - val_loss: 7.1265e-05 - val_mean_squared_error: 7.1265e-05 - val_accuracy: 0.0060\n",
      "Epoch 14/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.7212e-05 - mean_squared_error: 6.7213e-05 - accuracy: 0.0067 - val_loss: 7.1232e-05 - val_mean_squared_error: 7.1232e-05 - val_accuracy: 0.0060\n",
      "Epoch 15/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 6.7058e-05 - mean_squared_error: 6.7058e-05 - accuracy: 0.0067 - val_loss: 7.0214e-05 - val_mean_squared_error: 7.0214e-05 - val_accuracy: 0.0060\n",
      "Epoch 16/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6504e-05 - mean_squared_error: 6.6504e-05 - accuracy: 0.0067 - val_loss: 7.0456e-05 - val_mean_squared_error: 7.0456e-05 - val_accuracy: 0.0060\n",
      "Epoch 17/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.6224e-05 - mean_squared_error: 6.6224e-05 - accuracy: 0.0067 - val_loss: 7.0150e-05 - val_mean_squared_error: 7.0150e-05 - val_accuracy: 0.0060\n",
      "Epoch 18/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.6166e-05 - mean_squared_error: 6.6166e-05 - accuracy: 0.0067 - val_loss: 6.9944e-05 - val_mean_squared_error: 6.9944e-05 - val_accuracy: 0.0060\n",
      "Epoch 19/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.5970e-05 - mean_squared_error: 6.5970e-05 - accuracy: 0.0067 - val_loss: 6.9933e-05 - val_mean_squared_error: 6.9933e-05 - val_accuracy: 0.0060\n",
      "Epoch 20/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 6.6006e-05 - mean_squared_error: 6.6006e-05 - accuracy: 0.0067 - val_loss: 7.0014e-05 - val_mean_squared_error: 7.0014e-05 - val_accuracy: 0.0060\n",
      "Epoch 21/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6055e-05 - mean_squared_error: 6.6054e-05 - accuracy: 0.0067 - val_loss: 6.9593e-05 - val_mean_squared_error: 6.9593e-05 - val_accuracy: 0.0060\n",
      "Epoch 22/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.5473e-05 - mean_squared_error: 6.5473e-05 - accuracy: 0.0067 - val_loss: 6.9869e-05 - val_mean_squared_error: 6.9869e-05 - val_accuracy: 0.0060\n",
      "Epoch 23/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.5526e-05 - mean_squared_error: 6.5526e-05 - accuracy: 0.0067 - val_loss: 7.0213e-05 - val_mean_squared_error: 7.0213e-05 - val_accuracy: 0.0060\n",
      "Epoch 24/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.5711e-05 - mean_squared_error: 6.5711e-05 - accuracy: 0.0067 - val_loss: 6.9923e-05 - val_mean_squared_error: 6.9923e-05 - val_accuracy: 0.0060\n",
      "Epoch 25/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.5355e-05 - mean_squared_error: 6.5355e-05 - accuracy: 0.0067 - val_loss: 6.9748e-05 - val_mean_squared_error: 6.9748e-05 - val_accuracy: 0.0060\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 20)                38900     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          40881     \n",
      "=================================================================\n",
      "Total params: 79,781\n",
      "Trainable params: 79,141\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 20)                32020     \n",
      "=================================================================\n",
      "Total params: 38,900\n",
      "Trainable params: 38,580\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 7.2568e-05 - mean_squared_error: 7.2568e-05 - accuracy: 0.0060\n",
      "MSE results: 7.25676873116754e-05\n",
      "accuracy results: 0.005996230989694595\n",
      "metrics names ['loss', 'mean_squared_error', 'accuracy']\n",
      "fold iteration # 4  lat dim 20\n",
      "MSE (valid) [6.743978156009689e-05, 7.104862743290141e-05, 7.25676873116754e-05], lat dim 20\n",
      "Train idx = [    0     1     2 ... 29181 29182 29183] test idx = [    4     7    13 ... 29174 29176 29178]\n",
      "training set size=(23347, 80, 1, 1)\n",
      "test set size=(5837, 80, 1, 1)\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 20)                32020     \n",
      "=================================================================\n",
      "Total params: 38,900\n",
      "Trainable params: 38,580\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 20)]              0         \n",
      "_________________________________________________________________\n",
      "dec_dense_4_reshape (Dense)  (None, 1600)              33600     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_2 (Dense)      (None, 80, 1, 20)         420       \n",
      "_________________________________________________________________\n",
      "decoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "decoder_relu_2 (ReLU)        (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_1 (Dense)      (None, 80, 1, 60)         1260      \n",
      "_________________________________________________________________\n",
      "decoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "decoder_relu_1 (ReLU)        (None, 80, 1, 60)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_0 (Dense)      (None, 80, 1, 80)         4880      \n",
      "_________________________________________________________________\n",
      "decoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "decoder_relu_0 (ReLU)        (None, 80, 1, 80)         0         \n",
      "_________________________________________________________________\n",
      "decoder_last_layer (Dense)   (None, 80, 1, 1)          81        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 80, 1, 1)          0         \n",
      "=================================================================\n",
      "Total params: 40,881\n",
      "Trainable params: 40,561\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 20)                38900     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          40881     \n",
      "=================================================================\n",
      "Total params: 79,781\n",
      "Trainable params: 79,141\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "730/730 [==============================] - 18s 25ms/step - loss: 0.0111 - mean_squared_error: 0.0111 - accuracy: 0.0066 - val_loss: 2.9875e-04 - val_mean_squared_error: 2.9875e-04 - val_accuracy: 0.0065\n",
      "Epoch 2/25\n",
      "730/730 [==============================] - 17s 24ms/step - loss: 2.1330e-04 - mean_squared_error: 2.1330e-04 - accuracy: 0.0066 - val_loss: 1.4550e-04 - val_mean_squared_error: 1.4550e-04 - val_accuracy: 0.0065\n",
      "Epoch 3/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 1.3083e-04 - mean_squared_error: 1.3083e-04 - accuracy: 0.0066 - val_loss: 1.1205e-04 - val_mean_squared_error: 1.1205e-04 - val_accuracy: 0.0065\n",
      "Epoch 4/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 1.0522e-04 - mean_squared_error: 1.0522e-04 - accuracy: 0.0066 - val_loss: 9.3104e-05 - val_mean_squared_error: 9.3104e-05 - val_accuracy: 0.0065\n",
      "Epoch 5/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 9.2645e-05 - mean_squared_error: 9.2645e-05 - accuracy: 0.0066 - val_loss: 7.9858e-05 - val_mean_squared_error: 7.9858e-05 - val_accuracy: 0.0065\n",
      "Epoch 6/25\n",
      "730/730 [==============================] - 17s 24ms/step - loss: 8.4712e-05 - mean_squared_error: 8.4712e-05 - accuracy: 0.0066 - val_loss: 7.3945e-05 - val_mean_squared_error: 7.3945e-05 - val_accuracy: 0.0065\n",
      "Epoch 7/25\n",
      "730/730 [==============================] - 17s 24ms/step - loss: 7.9090e-05 - mean_squared_error: 7.9090e-05 - accuracy: 0.0066 - val_loss: 6.9738e-05 - val_mean_squared_error: 6.9738e-05 - val_accuracy: 0.0065\n",
      "Epoch 8/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 7.5742e-05 - mean_squared_error: 7.5742e-05 - accuracy: 0.0066 - val_loss: 6.7454e-05 - val_mean_squared_error: 6.7454e-05 - val_accuracy: 0.0065\n",
      "Epoch 9/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 7.3614e-05 - mean_squared_error: 7.3614e-05 - accuracy: 0.0066 - val_loss: 6.5780e-05 - val_mean_squared_error: 6.5780e-05 - val_accuracy: 0.0065\n",
      "Epoch 10/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 7.1890e-05 - mean_squared_error: 7.1890e-05 - accuracy: 0.0066 - val_loss: 6.5335e-05 - val_mean_squared_error: 6.5335e-05 - val_accuracy: 0.0065\n",
      "Epoch 11/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 7.1517e-05 - mean_squared_error: 7.1517e-05 - accuracy: 0.0066 - val_loss: 6.4024e-05 - val_mean_squared_error: 6.4024e-05 - val_accuracy: 0.0065\n",
      "Epoch 12/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 7.0206e-05 - mean_squared_error: 7.0206e-05 - accuracy: 0.0066 - val_loss: 6.3522e-05 - val_mean_squared_error: 6.3522e-05 - val_accuracy: 0.0065\n",
      "Epoch 13/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.9873e-05 - mean_squared_error: 6.9873e-05 - accuracy: 0.0066 - val_loss: 6.3257e-05 - val_mean_squared_error: 6.3257e-05 - val_accuracy: 0.0065\n",
      "Epoch 14/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.9115e-05 - mean_squared_error: 6.9115e-05 - accuracy: 0.0066 - val_loss: 6.3864e-05 - val_mean_squared_error: 6.3864e-05 - val_accuracy: 0.0065\n",
      "Epoch 15/25\n",
      "730/730 [==============================] - 17s 24ms/step - loss: 6.9206e-05 - mean_squared_error: 6.9206e-05 - accuracy: 0.0066 - val_loss: 6.4948e-05 - val_mean_squared_error: 6.4948e-05 - val_accuracy: 0.0065\n",
      "Epoch 16/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.8803e-05 - mean_squared_error: 6.8803e-05 - accuracy: 0.0066 - val_loss: 6.2471e-05 - val_mean_squared_error: 6.2471e-05 - val_accuracy: 0.0065\n",
      "Epoch 17/25\n",
      "730/730 [==============================] - 17s 24ms/step - loss: 6.8523e-05 - mean_squared_error: 6.8523e-05 - accuracy: 0.0066 - val_loss: 6.2414e-05 - val_mean_squared_error: 6.2414e-05 - val_accuracy: 0.0065\n",
      "Epoch 18/25\n",
      "730/730 [==============================] - 17s 24ms/step - loss: 6.8242e-05 - mean_squared_error: 6.8242e-05 - accuracy: 0.0066 - val_loss: 6.2742e-05 - val_mean_squared_error: 6.2742e-05 - val_accuracy: 0.0065\n",
      "Epoch 19/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.7968e-05 - mean_squared_error: 6.7968e-05 - accuracy: 0.0066 - val_loss: 6.2220e-05 - val_mean_squared_error: 6.2220e-05 - val_accuracy: 0.0065\n",
      "Epoch 20/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.7851e-05 - mean_squared_error: 6.7851e-05 - accuracy: 0.0066 - val_loss: 6.2088e-05 - val_mean_squared_error: 6.2088e-05 - val_accuracy: 0.0065\n",
      "Epoch 21/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.7821e-05 - mean_squared_error: 6.7821e-05 - accuracy: 0.0066 - val_loss: 6.2116e-05 - val_mean_squared_error: 6.2116e-05 - val_accuracy: 0.0065\n",
      "Epoch 22/25\n",
      "730/730 [==============================] - 16s 23ms/step - loss: 6.7509e-05 - mean_squared_error: 6.7509e-05 - accuracy: 0.0066 - val_loss: 6.2044e-05 - val_mean_squared_error: 6.2044e-05 - val_accuracy: 0.0065\n",
      "Epoch 23/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.7577e-05 - mean_squared_error: 6.7577e-05 - accuracy: 0.0066 - val_loss: 6.4130e-05 - val_mean_squared_error: 6.4130e-05 - val_accuracy: 0.0065\n",
      "Epoch 24/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.7525e-05 - mean_squared_error: 6.7525e-05 - accuracy: 0.0066 - val_loss: 6.2278e-05 - val_mean_squared_error: 6.2278e-05 - val_accuracy: 0.0065\n",
      "Epoch 25/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.7310e-05 - mean_squared_error: 6.7310e-05 - accuracy: 0.0066 - val_loss: 6.2089e-05 - val_mean_squared_error: 6.2089e-05 - val_accuracy: 0.0065\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 20)                38900     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          40881     \n",
      "=================================================================\n",
      "Total params: 79,781\n",
      "Trainable params: 79,141\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 20)                32020     \n",
      "=================================================================\n",
      "Total params: 38,900\n",
      "Trainable params: 38,580\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 6.5378e-05 - mean_squared_error: 6.5378e-05 - accuracy: 0.0065\n",
      "MSE results: 6.537818990182132e-05\n",
      "accuracy results: 0.006510193459689617\n",
      "metrics names ['loss', 'mean_squared_error', 'accuracy']\n",
      "fold iteration # 5  lat dim 20\n",
      "MSE (valid) [6.743978156009689e-05, 7.104862743290141e-05, 7.25676873116754e-05, 6.537818990182132e-05], lat dim 20\n",
      "Train idx = [    0     1     2 ... 29181 29182 29183] test idx = [    6     8     9 ... 29168 29170 29177]\n",
      "training set size=(23348, 80, 1, 1)\n",
      "test set size=(5836, 80, 1, 1)\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 20)                32020     \n",
      "=================================================================\n",
      "Total params: 38,900\n",
      "Trainable params: 38,580\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 20)]              0         \n",
      "_________________________________________________________________\n",
      "dec_dense_4_reshape (Dense)  (None, 1600)              33600     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_2 (Dense)      (None, 80, 1, 20)         420       \n",
      "_________________________________________________________________\n",
      "decoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "decoder_relu_2 (ReLU)        (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_1 (Dense)      (None, 80, 1, 60)         1260      \n",
      "_________________________________________________________________\n",
      "decoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "decoder_relu_1 (ReLU)        (None, 80, 1, 60)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_0 (Dense)      (None, 80, 1, 80)         4880      \n",
      "_________________________________________________________________\n",
      "decoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "decoder_relu_0 (ReLU)        (None, 80, 1, 80)         0         \n",
      "_________________________________________________________________\n",
      "decoder_last_layer (Dense)   (None, 80, 1, 1)          81        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 80, 1, 1)          0         \n",
      "=================================================================\n",
      "Total params: 40,881\n",
      "Trainable params: 40,561\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 20)                38900     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          40881     \n",
      "=================================================================\n",
      "Total params: 79,781\n",
      "Trainable params: 79,141\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "730/730 [==============================] - 18s 25ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - accuracy: 0.0065 - val_loss: 2.2724e-04 - val_mean_squared_error: 2.2724e-04 - val_accuracy: 0.0069\n",
      "Epoch 2/25\n",
      "730/730 [==============================] - 18s 24ms/step - loss: 1.7554e-04 - mean_squared_error: 1.7554e-04 - accuracy: 0.0065 - val_loss: 1.2623e-04 - val_mean_squared_error: 1.2623e-04 - val_accuracy: 0.0069\n",
      "Epoch 3/25\n",
      "730/730 [==============================] - 18s 24ms/step - loss: 1.1112e-04 - mean_squared_error: 1.1112e-04 - accuracy: 0.0065 - val_loss: 9.6500e-05 - val_mean_squared_error: 9.6500e-05 - val_accuracy: 0.0069\n",
      "Epoch 4/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 8.9554e-05 - mean_squared_error: 8.9554e-05 - accuracy: 0.0065 - val_loss: 8.2741e-05 - val_mean_squared_error: 8.2741e-05 - val_accuracy: 0.0069\n",
      "Epoch 5/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 8.0153e-05 - mean_squared_error: 8.0153e-05 - accuracy: 0.0065 - val_loss: 7.6810e-05 - val_mean_squared_error: 7.6810e-05 - val_accuracy: 0.0069\n",
      "Epoch 6/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 7.5366e-05 - mean_squared_error: 7.5366e-05 - accuracy: 0.0065 - val_loss: 7.3054e-05 - val_mean_squared_error: 7.3054e-05 - val_accuracy: 0.0069\n",
      "Epoch 7/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.2659e-05 - mean_squared_error: 7.2659e-05 - accuracy: 0.0065 - val_loss: 7.1246e-05 - val_mean_squared_error: 7.1246e-05 - val_accuracy: 0.0069\n",
      "Epoch 8/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.1189e-05 - mean_squared_error: 7.1189e-05 - accuracy: 0.0065 - val_loss: 7.3946e-05 - val_mean_squared_error: 7.3946e-05 - val_accuracy: 0.0069\n",
      "Epoch 9/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.9888e-05 - mean_squared_error: 6.9888e-05 - accuracy: 0.0065 - val_loss: 7.3614e-05 - val_mean_squared_error: 7.3614e-05 - val_accuracy: 0.0069\n",
      "Epoch 10/25\n",
      "730/730 [==============================] - 16s 23ms/step - loss: 6.9320e-05 - mean_squared_error: 6.9320e-05 - accuracy: 0.0065 - val_loss: 6.8251e-05 - val_mean_squared_error: 6.8251e-05 - val_accuracy: 0.0069\n",
      "Epoch 11/25\n",
      "730/730 [==============================] - 16s 23ms/step - loss: 6.8553e-05 - mean_squared_error: 6.8553e-05 - accuracy: 0.0065 - val_loss: 7.0183e-05 - val_mean_squared_error: 7.0183e-05 - val_accuracy: 0.0069\n",
      "Epoch 12/25\n",
      "730/730 [==============================] - 16s 23ms/step - loss: 6.8242e-05 - mean_squared_error: 6.8242e-05 - accuracy: 0.0065 - val_loss: 6.7681e-05 - val_mean_squared_error: 6.7681e-05 - val_accuracy: 0.0069\n",
      "Epoch 13/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.8282e-05 - mean_squared_error: 6.8282e-05 - accuracy: 0.0065 - val_loss: 6.7845e-05 - val_mean_squared_error: 6.7845e-05 - val_accuracy: 0.0069\n",
      "Epoch 14/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.7814e-05 - mean_squared_error: 6.7814e-05 - accuracy: 0.0065 - val_loss: 6.7481e-05 - val_mean_squared_error: 6.7481e-05 - val_accuracy: 0.0069\n",
      "Epoch 15/25\n",
      "730/730 [==============================] - 16s 23ms/step - loss: 6.7690e-05 - mean_squared_error: 6.7690e-05 - accuracy: 0.0065 - val_loss: 8.0798e-05 - val_mean_squared_error: 8.0798e-05 - val_accuracy: 0.0069\n",
      "Epoch 16/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.7531e-05 - mean_squared_error: 6.7531e-05 - accuracy: 0.0065 - val_loss: 6.8788e-05 - val_mean_squared_error: 6.8789e-05 - val_accuracy: 0.0069\n",
      "Epoch 17/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.7147e-05 - mean_squared_error: 6.7147e-05 - accuracy: 0.0065 - val_loss: 6.7291e-05 - val_mean_squared_error: 6.7290e-05 - val_accuracy: 0.0069\n",
      "Epoch 18/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.7241e-05 - mean_squared_error: 6.7241e-05 - accuracy: 0.0065 - val_loss: 6.6986e-05 - val_mean_squared_error: 6.6986e-05 - val_accuracy: 0.0069\n",
      "Epoch 19/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.7173e-05 - mean_squared_error: 6.7173e-05 - accuracy: 0.0065 - val_loss: 6.7492e-05 - val_mean_squared_error: 6.7492e-05 - val_accuracy: 0.0069\n",
      "Epoch 20/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.7061e-05 - mean_squared_error: 6.7061e-05 - accuracy: 0.0065 - val_loss: 6.6636e-05 - val_mean_squared_error: 6.6636e-05 - val_accuracy: 0.0069\n",
      "Epoch 21/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.6788e-05 - mean_squared_error: 6.6788e-05 - accuracy: 0.0065 - val_loss: 6.6656e-05 - val_mean_squared_error: 6.6656e-05 - val_accuracy: 0.0069\n",
      "Epoch 22/25\n",
      "730/730 [==============================] - 19s 26ms/step - loss: 6.6839e-05 - mean_squared_error: 6.6839e-05 - accuracy: 0.0065 - val_loss: 6.6643e-05 - val_mean_squared_error: 6.6643e-05 - val_accuracy: 0.0069\n",
      "Epoch 23/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6639e-05 - mean_squared_error: 6.6639e-05 - accuracy: 0.0065 - val_loss: 6.8516e-05 - val_mean_squared_error: 6.8516e-05 - val_accuracy: 0.0069\n",
      "Epoch 24/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6494e-05 - mean_squared_error: 6.6494e-05 - accuracy: 0.0065 - val_loss: 6.6877e-05 - val_mean_squared_error: 6.6877e-05 - val_accuracy: 0.0069\n",
      "Epoch 25/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6476e-05 - mean_squared_error: 6.6476e-05 - accuracy: 0.0065 - val_loss: 6.6616e-05 - val_mean_squared_error: 6.6616e-05 - val_accuracy: 0.0069\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 20)                38900     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          40881     \n",
      "=================================================================\n",
      "Total params: 79,781\n",
      "Trainable params: 79,141\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 20)                32020     \n",
      "=================================================================\n",
      "Total params: 38,900\n",
      "Trainable params: 38,580\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 6.9285e-05 - mean_squared_error: 6.9286e-05 - accuracy: 0.0069\n",
      "MSE results: 6.928551010787487e-05\n",
      "accuracy results: 0.006854009814560413\n",
      "metrics names ['loss', 'mean_squared_error', 'accuracy']\n",
      "fold iteration # 6  lat dim 20\n",
      "MSE (valid) [6.743978156009689e-05, 7.104862743290141e-05, 7.25676873116754e-05, 6.537818990182132e-05, 6.928551010787487e-05], lat dim 20\n",
      "Train idx = [    0     1     2 ... 29180 29181 29183] test idx = [    3    15    21 ... 29168 29173 29182]\n",
      "training set size=(23347, 80, 1, 1)\n",
      "test set size=(5837, 80, 1, 1)\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 21)                33621     \n",
      "=================================================================\n",
      "Total params: 40,501\n",
      "Trainable params: 40,181\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 21)]              0         \n",
      "_________________________________________________________________\n",
      "dec_dense_4_reshape (Dense)  (None, 1600)              35200     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_2 (Dense)      (None, 80, 1, 20)         420       \n",
      "_________________________________________________________________\n",
      "decoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "decoder_relu_2 (ReLU)        (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_1 (Dense)      (None, 80, 1, 60)         1260      \n",
      "_________________________________________________________________\n",
      "decoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "decoder_relu_1 (ReLU)        (None, 80, 1, 60)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_0 (Dense)      (None, 80, 1, 80)         4880      \n",
      "_________________________________________________________________\n",
      "decoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "decoder_relu_0 (ReLU)        (None, 80, 1, 80)         0         \n",
      "_________________________________________________________________\n",
      "decoder_last_layer (Dense)   (None, 80, 1, 1)          81        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 80, 1, 1)          0         \n",
      "=================================================================\n",
      "Total params: 42,481\n",
      "Trainable params: 42,161\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 21)                40501     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          42481     \n",
      "=================================================================\n",
      "Total params: 82,982\n",
      "Trainable params: 82,342\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - accuracy: 0.0062 - val_loss: 2.8157e-04 - val_mean_squared_error: 2.8157e-04 - val_accuracy: 0.0079\n",
      "Epoch 2/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 2.0133e-04 - mean_squared_error: 2.0133e-04 - accuracy: 0.0063 - val_loss: 1.3684e-04 - val_mean_squared_error: 1.3684e-04 - val_accuracy: 0.0079\n",
      "Epoch 3/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 1.2449e-04 - mean_squared_error: 1.2449e-04 - accuracy: 0.0063 - val_loss: 1.0132e-04 - val_mean_squared_error: 1.0132e-04 - val_accuracy: 0.0079\n",
      "Epoch 4/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 9.9786e-05 - mean_squared_error: 9.9786e-05 - accuracy: 0.0063 - val_loss: 8.7405e-05 - val_mean_squared_error: 8.7405e-05 - val_accuracy: 0.0079\n",
      "Epoch 5/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 8.8199e-05 - mean_squared_error: 8.8199e-05 - accuracy: 0.0063 - val_loss: 7.9784e-05 - val_mean_squared_error: 7.9784e-05 - val_accuracy: 0.0079\n",
      "Epoch 6/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 8.0818e-05 - mean_squared_error: 8.0818e-05 - accuracy: 0.0063 - val_loss: 7.2599e-05 - val_mean_squared_error: 7.2599e-05 - val_accuracy: 0.0079\n",
      "Epoch 7/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 7.6173e-05 - mean_squared_error: 7.6173e-05 - accuracy: 0.0063 - val_loss: 6.9140e-05 - val_mean_squared_error: 6.9140e-05 - val_accuracy: 0.0079\n",
      "Epoch 8/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 7.4215e-05 - mean_squared_error: 7.4215e-05 - accuracy: 0.0063 - val_loss: 6.7590e-05 - val_mean_squared_error: 6.7590e-05 - val_accuracy: 0.0079\n",
      "Epoch 9/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.1941e-05 - mean_squared_error: 7.1941e-05 - accuracy: 0.0063 - val_loss: 6.5030e-05 - val_mean_squared_error: 6.5030e-05 - val_accuracy: 0.0079\n",
      "Epoch 10/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.0539e-05 - mean_squared_error: 7.0539e-05 - accuracy: 0.0063 - val_loss: 6.4380e-05 - val_mean_squared_error: 6.4380e-05 - val_accuracy: 0.0079\n",
      "Epoch 11/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.0356e-05 - mean_squared_error: 7.0356e-05 - accuracy: 0.0063 - val_loss: 6.3916e-05 - val_mean_squared_error: 6.3916e-05 - val_accuracy: 0.0079\n",
      "Epoch 12/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 6.9542e-05 - mean_squared_error: 6.9542e-05 - accuracy: 0.0063 - val_loss: 6.3416e-05 - val_mean_squared_error: 6.3416e-05 - val_accuracy: 0.0079\n",
      "Epoch 13/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 6.9028e-05 - mean_squared_error: 6.9028e-05 - accuracy: 0.0063 - val_loss: 6.3199e-05 - val_mean_squared_error: 6.3199e-05 - val_accuracy: 0.0079\n",
      "Epoch 14/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.8399e-05 - mean_squared_error: 6.8399e-05 - accuracy: 0.0063 - val_loss: 6.3219e-05 - val_mean_squared_error: 6.3219e-05 - val_accuracy: 0.0079\n",
      "Epoch 15/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.8675e-05 - mean_squared_error: 6.8675e-05 - accuracy: 0.0063 - val_loss: 6.3265e-05 - val_mean_squared_error: 6.3265e-05 - val_accuracy: 0.0079\n",
      "Epoch 16/25\n",
      "730/730 [==============================] - 19s 26ms/step - loss: 6.8026e-05 - mean_squared_error: 6.8026e-05 - accuracy: 0.0063 - val_loss: 6.4432e-05 - val_mean_squared_error: 6.4432e-05 - val_accuracy: 0.0079\n",
      "Epoch 17/25\n",
      "730/730 [==============================] - 17s 24ms/step - loss: 6.8207e-05 - mean_squared_error: 6.8207e-05 - accuracy: 0.0063 - val_loss: 6.4710e-05 - val_mean_squared_error: 6.4710e-05 - val_accuracy: 0.0079\n",
      "Epoch 18/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 6.7854e-05 - mean_squared_error: 6.7854e-05 - accuracy: 0.0063 - val_loss: 6.2717e-05 - val_mean_squared_error: 6.2717e-05 - val_accuracy: 0.0079\n",
      "Epoch 19/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.7483e-05 - mean_squared_error: 6.7483e-05 - accuracy: 0.0063 - val_loss: 6.2832e-05 - val_mean_squared_error: 6.2832e-05 - val_accuracy: 0.0079\n",
      "Epoch 20/25\n",
      "730/730 [==============================] - 18s 24ms/step - loss: 6.7294e-05 - mean_squared_error: 6.7294e-05 - accuracy: 0.0063 - val_loss: 6.2510e-05 - val_mean_squared_error: 6.2510e-05 - val_accuracy: 0.0079\n",
      "Epoch 21/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 6.7190e-05 - mean_squared_error: 6.7190e-05 - accuracy: 0.0063 - val_loss: 6.2278e-05 - val_mean_squared_error: 6.2278e-05 - val_accuracy: 0.0079\n",
      "Epoch 22/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 6.7276e-05 - mean_squared_error: 6.7276e-05 - accuracy: 0.0063 - val_loss: 6.4306e-05 - val_mean_squared_error: 6.4306e-05 - val_accuracy: 0.0079\n",
      "Epoch 23/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 6.7191e-05 - mean_squared_error: 6.7191e-05 - accuracy: 0.0063 - val_loss: 6.2235e-05 - val_mean_squared_error: 6.2235e-05 - val_accuracy: 0.0079\n",
      "Epoch 24/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.7022e-05 - mean_squared_error: 6.7022e-05 - accuracy: 0.0063 - val_loss: 6.2509e-05 - val_mean_squared_error: 6.2509e-05 - val_accuracy: 0.0079\n",
      "Epoch 25/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 6.7003e-05 - mean_squared_error: 6.7003e-05 - accuracy: 0.0063 - val_loss: 6.2587e-05 - val_mean_squared_error: 6.2587e-05 - val_accuracy: 0.0079\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 21)                40501     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          42481     \n",
      "=================================================================\n",
      "Total params: 82,982\n",
      "Trainable params: 82,342\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 21)                33621     \n",
      "=================================================================\n",
      "Total params: 40,501\n",
      "Trainable params: 40,181\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 6.6021e-05 - mean_squared_error: 6.6021e-05 - accuracy: 0.0079\n",
      "MSE results: 6.602079520234838e-05\n",
      "accuracy results: 0.007880760356783867\n",
      "metrics names ['loss', 'mean_squared_error', 'accuracy']\n",
      "fold iteration # 2  lat dim 21\n",
      "MSE (valid) [6.602079520234838e-05], lat dim 21\n",
      "Train idx = [    0     1     2 ... 29181 29182 29183] test idx = [    6     7     8 ... 29176 29178 29179]\n",
      "training set size=(23347, 80, 1, 1)\n",
      "test set size=(5837, 80, 1, 1)\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 21)                33621     \n",
      "=================================================================\n",
      "Total params: 40,501\n",
      "Trainable params: 40,181\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 21)]              0         \n",
      "_________________________________________________________________\n",
      "dec_dense_4_reshape (Dense)  (None, 1600)              35200     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_2 (Dense)      (None, 80, 1, 20)         420       \n",
      "_________________________________________________________________\n",
      "decoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "decoder_relu_2 (ReLU)        (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_1 (Dense)      (None, 80, 1, 60)         1260      \n",
      "_________________________________________________________________\n",
      "decoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "decoder_relu_1 (ReLU)        (None, 80, 1, 60)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_0 (Dense)      (None, 80, 1, 80)         4880      \n",
      "_________________________________________________________________\n",
      "decoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "decoder_relu_0 (ReLU)        (None, 80, 1, 80)         0         \n",
      "_________________________________________________________________\n",
      "decoder_last_layer (Dense)   (None, 80, 1, 1)          81        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 80, 1, 1)          0         \n",
      "=================================================================\n",
      "Total params: 42,481\n",
      "Trainable params: 42,161\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 21)                40501     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          42481     \n",
      "=================================================================\n",
      "Total params: 82,982\n",
      "Trainable params: 82,342\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "730/730 [==============================] - 18s 25ms/step - loss: 0.0077 - mean_squared_error: 0.0077 - accuracy: 0.0067 - val_loss: 2.9480e-04 - val_mean_squared_error: 2.9480e-04 - val_accuracy: 0.0060\n",
      "Epoch 2/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 1.9256e-04 - mean_squared_error: 1.9256e-04 - accuracy: 0.0067 - val_loss: 1.5164e-04 - val_mean_squared_error: 1.5164e-04 - val_accuracy: 0.0060\n",
      "Epoch 3/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 1.2073e-04 - mean_squared_error: 1.2073e-04 - accuracy: 0.0067 - val_loss: 1.0694e-04 - val_mean_squared_error: 1.0694e-04 - val_accuracy: 0.0060\n",
      "Epoch 4/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 9.7740e-05 - mean_squared_error: 9.7739e-05 - accuracy: 0.0067 - val_loss: 8.8341e-05 - val_mean_squared_error: 8.8341e-05 - val_accuracy: 0.0060\n",
      "Epoch 5/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 8.4206e-05 - mean_squared_error: 8.4206e-05 - accuracy: 0.0067 - val_loss: 7.8546e-05 - val_mean_squared_error: 7.8546e-05 - val_accuracy: 0.0060\n",
      "Epoch 6/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 7.7716e-05 - mean_squared_error: 7.7716e-05 - accuracy: 0.0067 - val_loss: 7.5145e-05 - val_mean_squared_error: 7.5145e-05 - val_accuracy: 0.0060\n",
      "Epoch 7/25\n",
      "730/730 [==============================] - 17s 24ms/step - loss: 7.3714e-05 - mean_squared_error: 7.3714e-05 - accuracy: 0.0067 - val_loss: 7.1205e-05 - val_mean_squared_error: 7.1205e-05 - val_accuracy: 0.0060\n",
      "Epoch 8/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 7.2226e-05 - mean_squared_error: 7.2226e-05 - accuracy: 0.0067 - val_loss: 7.1395e-05 - val_mean_squared_error: 7.1395e-05 - val_accuracy: 0.0060\n",
      "Epoch 9/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 7.0006e-05 - mean_squared_error: 7.0006e-05 - accuracy: 0.0067 - val_loss: 6.8941e-05 - val_mean_squared_error: 6.8941e-05 - val_accuracy: 0.0060\n",
      "Epoch 10/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.8973e-05 - mean_squared_error: 6.8973e-05 - accuracy: 0.0067 - val_loss: 6.8355e-05 - val_mean_squared_error: 6.8355e-05 - val_accuracy: 0.0060\n",
      "Epoch 11/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.8475e-05 - mean_squared_error: 6.8475e-05 - accuracy: 0.0067 - val_loss: 6.9452e-05 - val_mean_squared_error: 6.9452e-05 - val_accuracy: 0.0060\n",
      "Epoch 12/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.8377e-05 - mean_squared_error: 6.8377e-05 - accuracy: 0.0067 - val_loss: 6.7321e-05 - val_mean_squared_error: 6.7321e-05 - val_accuracy: 0.0060\n",
      "Epoch 13/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.8212e-05 - mean_squared_error: 6.8212e-05 - accuracy: 0.0067 - val_loss: 6.7084e-05 - val_mean_squared_error: 6.7084e-05 - val_accuracy: 0.0060\n",
      "Epoch 14/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.7413e-05 - mean_squared_error: 6.7413e-05 - accuracy: 0.0067 - val_loss: 6.6661e-05 - val_mean_squared_error: 6.6661e-05 - val_accuracy: 0.0060\n",
      "Epoch 15/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.7392e-05 - mean_squared_error: 6.7392e-05 - accuracy: 0.0067 - val_loss: 6.6654e-05 - val_mean_squared_error: 6.6654e-05 - val_accuracy: 0.0060\n",
      "Epoch 16/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.7152e-05 - mean_squared_error: 6.7152e-05 - accuracy: 0.0067 - val_loss: 6.7829e-05 - val_mean_squared_error: 6.7829e-05 - val_accuracy: 0.0060\n",
      "Epoch 17/25\n",
      "730/730 [==============================] - 17s 24ms/step - loss: 6.7564e-05 - mean_squared_error: 6.7564e-05 - accuracy: 0.0067 - val_loss: 6.6509e-05 - val_mean_squared_error: 6.6509e-05 - val_accuracy: 0.0060\n",
      "Epoch 18/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.6837e-05 - mean_squared_error: 6.6838e-05 - accuracy: 0.0067 - val_loss: 6.6132e-05 - val_mean_squared_error: 6.6132e-05 - val_accuracy: 0.0060\n",
      "Epoch 19/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.6866e-05 - mean_squared_error: 6.6866e-05 - accuracy: 0.0067 - val_loss: 6.6993e-05 - val_mean_squared_error: 6.6993e-05 - val_accuracy: 0.0060\n",
      "Epoch 20/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.6730e-05 - mean_squared_error: 6.6730e-05 - accuracy: 0.0067 - val_loss: 6.6282e-05 - val_mean_squared_error: 6.6282e-05 - val_accuracy: 0.0060\n",
      "Epoch 21/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.6617e-05 - mean_squared_error: 6.6617e-05 - accuracy: 0.0067 - val_loss: 6.6471e-05 - val_mean_squared_error: 6.6471e-05 - val_accuracy: 0.0060\n",
      "Epoch 22/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.6507e-05 - mean_squared_error: 6.6508e-05 - accuracy: 0.0067 - val_loss: 6.7167e-05 - val_mean_squared_error: 6.7167e-05 - val_accuracy: 0.0060\n",
      "Epoch 23/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.6375e-05 - mean_squared_error: 6.6375e-05 - accuracy: 0.0067 - val_loss: 6.6699e-05 - val_mean_squared_error: 6.6699e-05 - val_accuracy: 0.0060\n",
      "Epoch 24/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.6162e-05 - mean_squared_error: 6.6162e-05 - accuracy: 0.0067 - val_loss: 6.5831e-05 - val_mean_squared_error: 6.5831e-05 - val_accuracy: 0.0060\n",
      "Epoch 25/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.6099e-05 - mean_squared_error: 6.6099e-05 - accuracy: 0.0067 - val_loss: 6.5870e-05 - val_mean_squared_error: 6.5870e-05 - val_accuracy: 0.0060\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 21)                40501     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          42481     \n",
      "=================================================================\n",
      "Total params: 82,982\n",
      "Trainable params: 82,342\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 21)                33621     \n",
      "=================================================================\n",
      "Total params: 40,501\n",
      "Trainable params: 40,181\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 6.8257e-05 - mean_squared_error: 6.8257e-05 - accuracy: 0.0060\n",
      "MSE results: 6.825737364124507e-05\n",
      "accuracy results: 0.005996230989694595\n",
      "metrics names ['loss', 'mean_squared_error', 'accuracy']\n",
      "fold iteration # 3  lat dim 21\n",
      "MSE (valid) [6.602079520234838e-05, 6.825737364124507e-05], lat dim 21\n",
      "Train idx = [    0     1     2 ... 29181 29182 29183] test idx = [   14    28    32 ... 29151 29154 29170]\n",
      "training set size=(23347, 80, 1, 1)\n",
      "test set size=(5837, 80, 1, 1)\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 21)                33621     \n",
      "=================================================================\n",
      "Total params: 40,501\n",
      "Trainable params: 40,181\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 21)]              0         \n",
      "_________________________________________________________________\n",
      "dec_dense_4_reshape (Dense)  (None, 1600)              35200     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_2 (Dense)      (None, 80, 1, 20)         420       \n",
      "_________________________________________________________________\n",
      "decoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "decoder_relu_2 (ReLU)        (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_1 (Dense)      (None, 80, 1, 60)         1260      \n",
      "_________________________________________________________________\n",
      "decoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "decoder_relu_1 (ReLU)        (None, 80, 1, 60)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_0 (Dense)      (None, 80, 1, 80)         4880      \n",
      "_________________________________________________________________\n",
      "decoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "decoder_relu_0 (ReLU)        (None, 80, 1, 80)         0         \n",
      "_________________________________________________________________\n",
      "decoder_last_layer (Dense)   (None, 80, 1, 1)          81        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 80, 1, 1)          0         \n",
      "=================================================================\n",
      "Total params: 42,481\n",
      "Trainable params: 42,161\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 21)                40501     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          42481     \n",
      "=================================================================\n",
      "Total params: 82,982\n",
      "Trainable params: 82,342\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - accuracy: 0.0066 - val_loss: 2.8281e-04 - val_mean_squared_error: 2.8281e-04 - val_accuracy: 0.0065\n",
      "Epoch 2/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 1.9387e-04 - mean_squared_error: 1.9387e-04 - accuracy: 0.0066 - val_loss: 1.3567e-04 - val_mean_squared_error: 1.3567e-04 - val_accuracy: 0.0065\n",
      "Epoch 3/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 1.2176e-04 - mean_squared_error: 1.2176e-04 - accuracy: 0.0066 - val_loss: 1.0522e-04 - val_mean_squared_error: 1.0522e-04 - val_accuracy: 0.0065\n",
      "Epoch 4/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 9.7987e-05 - mean_squared_error: 9.7987e-05 - accuracy: 0.0066 - val_loss: 9.0994e-05 - val_mean_squared_error: 9.0994e-05 - val_accuracy: 0.0065\n",
      "Epoch 5/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 8.7000e-05 - mean_squared_error: 8.7000e-05 - accuracy: 0.0066 - val_loss: 8.2319e-05 - val_mean_squared_error: 8.2319e-05 - val_accuracy: 0.0065\n",
      "Epoch 6/25\n",
      "730/730 [==============================] - 16s 23ms/step - loss: 8.0325e-05 - mean_squared_error: 8.0325e-05 - accuracy: 0.0066 - val_loss: 7.6474e-05 - val_mean_squared_error: 7.6474e-05 - val_accuracy: 0.0065\n",
      "Epoch 7/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.5128e-05 - mean_squared_error: 7.5128e-05 - accuracy: 0.0066 - val_loss: 7.3274e-05 - val_mean_squared_error: 7.3274e-05 - val_accuracy: 0.0065\n",
      "Epoch 8/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 7.2864e-05 - mean_squared_error: 7.2864e-05 - accuracy: 0.0066 - val_loss: 7.3159e-05 - val_mean_squared_error: 7.3159e-05 - val_accuracy: 0.0065\n",
      "Epoch 9/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 7.0887e-05 - mean_squared_error: 7.0887e-05 - accuracy: 0.0066 - val_loss: 7.0846e-05 - val_mean_squared_error: 7.0846e-05 - val_accuracy: 0.0065\n",
      "Epoch 10/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.9587e-05 - mean_squared_error: 6.9587e-05 - accuracy: 0.0066 - val_loss: 6.8784e-05 - val_mean_squared_error: 6.8784e-05 - val_accuracy: 0.0065\n",
      "Epoch 11/25\n",
      "730/730 [==============================] - 16s 23ms/step - loss: 6.8411e-05 - mean_squared_error: 6.8411e-05 - accuracy: 0.0066 - val_loss: 6.8519e-05 - val_mean_squared_error: 6.8519e-05 - val_accuracy: 0.0065\n",
      "Epoch 12/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.7954e-05 - mean_squared_error: 6.7954e-05 - accuracy: 0.0066 - val_loss: 6.7536e-05 - val_mean_squared_error: 6.7536e-05 - val_accuracy: 0.0065\n",
      "Epoch 13/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.7699e-05 - mean_squared_error: 6.7699e-05 - accuracy: 0.0066 - val_loss: 6.7490e-05 - val_mean_squared_error: 6.7490e-05 - val_accuracy: 0.0065\n",
      "Epoch 14/25\n",
      "730/730 [==============================] - 21s 28ms/step - loss: 6.7357e-05 - mean_squared_error: 6.7357e-05 - accuracy: 0.0066 - val_loss: 6.7867e-05 - val_mean_squared_error: 6.7867e-05 - val_accuracy: 0.0065\n",
      "Epoch 15/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.7301e-05 - mean_squared_error: 6.7301e-05 - accuracy: 0.0066 - val_loss: 6.7043e-05 - val_mean_squared_error: 6.7043e-05 - val_accuracy: 0.0065\n",
      "Epoch 16/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6806e-05 - mean_squared_error: 6.6806e-05 - accuracy: 0.0066 - val_loss: 6.6644e-05 - val_mean_squared_error: 6.6644e-05 - val_accuracy: 0.0065\n",
      "Epoch 17/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.6744e-05 - mean_squared_error: 6.6744e-05 - accuracy: 0.0066 - val_loss: 6.6770e-05 - val_mean_squared_error: 6.6770e-05 - val_accuracy: 0.0065\n",
      "Epoch 18/25\n",
      "730/730 [==============================] - 19s 26ms/step - loss: 6.6402e-05 - mean_squared_error: 6.6402e-05 - accuracy: 0.0066 - val_loss: 6.7298e-05 - val_mean_squared_error: 6.7298e-05 - val_accuracy: 0.0065\n",
      "Epoch 19/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.6524e-05 - mean_squared_error: 6.6524e-05 - accuracy: 0.0066 - val_loss: 6.7075e-05 - val_mean_squared_error: 6.7075e-05 - val_accuracy: 0.0065\n",
      "Epoch 20/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.6343e-05 - mean_squared_error: 6.6343e-05 - accuracy: 0.0066 - val_loss: 6.7026e-05 - val_mean_squared_error: 6.7026e-05 - val_accuracy: 0.0065\n",
      "Epoch 21/25\n",
      "730/730 [==============================] - 16s 23ms/step - loss: 6.6220e-05 - mean_squared_error: 6.6220e-05 - accuracy: 0.0066 - val_loss: 6.6584e-05 - val_mean_squared_error: 6.6584e-05 - val_accuracy: 0.0065\n",
      "Epoch 22/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.6191e-05 - mean_squared_error: 6.6191e-05 - accuracy: 0.0066 - val_loss: 6.6267e-05 - val_mean_squared_error: 6.6267e-05 - val_accuracy: 0.0065\n",
      "Epoch 23/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.5898e-05 - mean_squared_error: 6.5898e-05 - accuracy: 0.0066 - val_loss: 6.6212e-05 - val_mean_squared_error: 6.6212e-05 - val_accuracy: 0.0065\n",
      "Epoch 24/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.6011e-05 - mean_squared_error: 6.6011e-05 - accuracy: 0.0066 - val_loss: 6.7083e-05 - val_mean_squared_error: 6.7083e-05 - val_accuracy: 0.0065\n",
      "Epoch 25/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.5698e-05 - mean_squared_error: 6.5698e-05 - accuracy: 0.0066 - val_loss: 6.6191e-05 - val_mean_squared_error: 6.6191e-05 - val_accuracy: 0.0065\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 21)                40501     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          42481     \n",
      "=================================================================\n",
      "Total params: 82,982\n",
      "Trainable params: 82,342\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 21)                33621     \n",
      "=================================================================\n",
      "Total params: 40,501\n",
      "Trainable params: 40,181\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 6.8568e-05 - mean_squared_error: 6.8568e-05 - accuracy: 0.0065\n",
      "MSE results: 6.856777326902375e-05\n",
      "accuracy results: 0.006510193459689617\n",
      "metrics names ['loss', 'mean_squared_error', 'accuracy']\n",
      "fold iteration # 4  lat dim 21\n",
      "MSE (valid) [6.602079520234838e-05, 6.825737364124507e-05, 6.856777326902375e-05], lat dim 21\n",
      "Train idx = [    0     1     2 ... 29181 29182 29183] test idx = [    4     5    10 ... 29175 29177 29180]\n",
      "training set size=(23347, 80, 1, 1)\n",
      "test set size=(5837, 80, 1, 1)\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 21)                33621     \n",
      "=================================================================\n",
      "Total params: 40,501\n",
      "Trainable params: 40,181\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 21)]              0         \n",
      "_________________________________________________________________\n",
      "dec_dense_4_reshape (Dense)  (None, 1600)              35200     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_2 (Dense)      (None, 80, 1, 20)         420       \n",
      "_________________________________________________________________\n",
      "decoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "decoder_relu_2 (ReLU)        (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_1 (Dense)      (None, 80, 1, 60)         1260      \n",
      "_________________________________________________________________\n",
      "decoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "decoder_relu_1 (ReLU)        (None, 80, 1, 60)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_0 (Dense)      (None, 80, 1, 80)         4880      \n",
      "_________________________________________________________________\n",
      "decoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "decoder_relu_0 (ReLU)        (None, 80, 1, 80)         0         \n",
      "_________________________________________________________________\n",
      "decoder_last_layer (Dense)   (None, 80, 1, 1)          81        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 80, 1, 1)          0         \n",
      "=================================================================\n",
      "Total params: 42,481\n",
      "Trainable params: 42,161\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 21)                40501     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          42481     \n",
      "=================================================================\n",
      "Total params: 82,982\n",
      "Trainable params: 82,342\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - accuracy: 0.0065 - val_loss: 3.5511e-04 - val_mean_squared_error: 3.5511e-04 - val_accuracy: 0.0069\n",
      "Epoch 2/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 2.1626e-04 - mean_squared_error: 2.1626e-04 - accuracy: 0.0065 - val_loss: 1.4181e-04 - val_mean_squared_error: 1.4181e-04 - val_accuracy: 0.0069\n",
      "Epoch 3/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 1.3506e-04 - mean_squared_error: 1.3506e-04 - accuracy: 0.0065 - val_loss: 1.1314e-04 - val_mean_squared_error: 1.1314e-04 - val_accuracy: 0.0069\n",
      "Epoch 4/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 1.0960e-04 - mean_squared_error: 1.0960e-04 - accuracy: 0.0065 - val_loss: 9.4693e-05 - val_mean_squared_error: 9.4693e-05 - val_accuracy: 0.0069\n",
      "Epoch 5/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 9.4368e-05 - mean_squared_error: 9.4368e-05 - accuracy: 0.0065 - val_loss: 8.6651e-05 - val_mean_squared_error: 8.6651e-05 - val_accuracy: 0.0069\n",
      "Epoch 6/25\n",
      "730/730 [==============================] - 19s 26ms/step - loss: 8.5735e-05 - mean_squared_error: 8.5735e-05 - accuracy: 0.0065 - val_loss: 7.5876e-05 - val_mean_squared_error: 7.5876e-05 - val_accuracy: 0.0069\n",
      "Epoch 7/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 8.1575e-05 - mean_squared_error: 8.1575e-05 - accuracy: 0.0065 - val_loss: 7.1261e-05 - val_mean_squared_error: 7.1261e-05 - val_accuracy: 0.0069\n",
      "Epoch 8/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 7.6406e-05 - mean_squared_error: 7.6406e-05 - accuracy: 0.0065 - val_loss: 7.0648e-05 - val_mean_squared_error: 7.0648e-05 - val_accuracy: 0.0069\n",
      "Epoch 9/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.2976e-05 - mean_squared_error: 7.2976e-05 - accuracy: 0.0065 - val_loss: 6.7266e-05 - val_mean_squared_error: 6.7266e-05 - val_accuracy: 0.0069\n",
      "Epoch 10/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.1427e-05 - mean_squared_error: 7.1427e-05 - accuracy: 0.0065 - val_loss: 6.5775e-05 - val_mean_squared_error: 6.5775e-05 - val_accuracy: 0.0069\n",
      "Epoch 11/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.0362e-05 - mean_squared_error: 7.0362e-05 - accuracy: 0.0065 - val_loss: 6.6139e-05 - val_mean_squared_error: 6.6139e-05 - val_accuracy: 0.0069\n",
      "Epoch 12/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.9350e-05 - mean_squared_error: 6.9350e-05 - accuracy: 0.0065 - val_loss: 6.7257e-05 - val_mean_squared_error: 6.7257e-05 - val_accuracy: 0.0069\n",
      "Epoch 13/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 6.9223e-05 - mean_squared_error: 6.9223e-05 - accuracy: 0.0065 - val_loss: 6.5740e-05 - val_mean_squared_error: 6.5740e-05 - val_accuracy: 0.0069\n",
      "Epoch 14/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 6.8207e-05 - mean_squared_error: 6.8207e-05 - accuracy: 0.0065 - val_loss: 6.4474e-05 - val_mean_squared_error: 6.4474e-05 - val_accuracy: 0.0069\n",
      "Epoch 15/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.8137e-05 - mean_squared_error: 6.8137e-05 - accuracy: 0.0065 - val_loss: 6.9348e-05 - val_mean_squared_error: 6.9348e-05 - val_accuracy: 0.0069\n",
      "Epoch 16/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.7829e-05 - mean_squared_error: 6.7829e-05 - accuracy: 0.0065 - val_loss: 6.5070e-05 - val_mean_squared_error: 6.5070e-05 - val_accuracy: 0.0069\n",
      "Epoch 17/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.7910e-05 - mean_squared_error: 6.7910e-05 - accuracy: 0.0065 - val_loss: 6.4324e-05 - val_mean_squared_error: 6.4324e-05 - val_accuracy: 0.0069\n",
      "Epoch 18/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.7482e-05 - mean_squared_error: 6.7482e-05 - accuracy: 0.0065 - val_loss: 6.4175e-05 - val_mean_squared_error: 6.4175e-05 - val_accuracy: 0.0069\n",
      "Epoch 19/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.7071e-05 - mean_squared_error: 6.7071e-05 - accuracy: 0.0065 - val_loss: 6.5005e-05 - val_mean_squared_error: 6.5005e-05 - val_accuracy: 0.0069\n",
      "Epoch 20/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.6960e-05 - mean_squared_error: 6.6960e-05 - accuracy: 0.0065 - val_loss: 6.3877e-05 - val_mean_squared_error: 6.3877e-05 - val_accuracy: 0.0069\n",
      "Epoch 21/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6824e-05 - mean_squared_error: 6.6824e-05 - accuracy: 0.0065 - val_loss: 6.3694e-05 - val_mean_squared_error: 6.3694e-05 - val_accuracy: 0.0069\n",
      "Epoch 22/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.6932e-05 - mean_squared_error: 6.6932e-05 - accuracy: 0.0065 - val_loss: 6.4123e-05 - val_mean_squared_error: 6.4123e-05 - val_accuracy: 0.0069\n",
      "Epoch 23/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.6630e-05 - mean_squared_error: 6.6630e-05 - accuracy: 0.0065 - val_loss: 6.4066e-05 - val_mean_squared_error: 6.4066e-05 - val_accuracy: 0.0069\n",
      "Epoch 24/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.6527e-05 - mean_squared_error: 6.6527e-05 - accuracy: 0.0065 - val_loss: 6.3777e-05 - val_mean_squared_error: 6.3777e-05 - val_accuracy: 0.0069\n",
      "Epoch 25/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.6416e-05 - mean_squared_error: 6.6416e-05 - accuracy: 0.0065 - val_loss: 6.3582e-05 - val_mean_squared_error: 6.3582e-05 - val_accuracy: 0.0069\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 21)                40501     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          42481     \n",
      "=================================================================\n",
      "Total params: 82,982\n",
      "Trainable params: 82,342\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 21)                33621     \n",
      "=================================================================\n",
      "Total params: 40,501\n",
      "Trainable params: 40,181\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 6.6445e-05 - mean_squared_error: 6.6445e-05 - accuracy: 0.0069\n",
      "MSE results: 6.644536915700883e-05\n",
      "accuracy results: 0.006852835416793823\n",
      "metrics names ['loss', 'mean_squared_error', 'accuracy']\n",
      "fold iteration # 5  lat dim 21\n",
      "MSE (valid) [6.602079520234838e-05, 6.825737364124507e-05, 6.856777326902375e-05, 6.644536915700883e-05], lat dim 21\n",
      "Train idx = [    3     4     5 ... 29179 29180 29182] test idx = [    0     1     2 ... 29167 29181 29183]\n",
      "training set size=(23348, 80, 1, 1)\n",
      "test set size=(5836, 80, 1, 1)\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 21)                33621     \n",
      "=================================================================\n",
      "Total params: 40,501\n",
      "Trainable params: 40,181\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 21)]              0         \n",
      "_________________________________________________________________\n",
      "dec_dense_4_reshape (Dense)  (None, 1600)              35200     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_2 (Dense)      (None, 80, 1, 20)         420       \n",
      "_________________________________________________________________\n",
      "decoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "decoder_relu_2 (ReLU)        (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_1 (Dense)      (None, 80, 1, 60)         1260      \n",
      "_________________________________________________________________\n",
      "decoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "decoder_relu_1 (ReLU)        (None, 80, 1, 60)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_0 (Dense)      (None, 80, 1, 80)         4880      \n",
      "_________________________________________________________________\n",
      "decoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "decoder_relu_0 (ReLU)        (None, 80, 1, 80)         0         \n",
      "_________________________________________________________________\n",
      "decoder_last_layer (Dense)   (None, 80, 1, 1)          81        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 80, 1, 1)          0         \n",
      "=================================================================\n",
      "Total params: 42,481\n",
      "Trainable params: 42,161\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 21)                40501     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          42481     \n",
      "=================================================================\n",
      "Total params: 82,982\n",
      "Trainable params: 82,342\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - accuracy: 0.0068 - val_loss: 3.0763e-04 - val_mean_squared_error: 3.0763e-04 - val_accuracy: 0.0057\n",
      "Epoch 2/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 2.0611e-04 - mean_squared_error: 2.0611e-04 - accuracy: 0.0068 - val_loss: 1.4692e-04 - val_mean_squared_error: 1.4692e-04 - val_accuracy: 0.0057\n",
      "Epoch 3/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 1.2690e-04 - mean_squared_error: 1.2690e-04 - accuracy: 0.0068 - val_loss: 1.1124e-04 - val_mean_squared_error: 1.1124e-04 - val_accuracy: 0.0057\n",
      "Epoch 4/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 1.0004e-04 - mean_squared_error: 1.0004e-04 - accuracy: 0.0068 - val_loss: 9.4927e-05 - val_mean_squared_error: 9.4927e-05 - val_accuracy: 0.0057\n",
      "Epoch 5/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 8.6656e-05 - mean_squared_error: 8.6656e-05 - accuracy: 0.0068 - val_loss: 8.4003e-05 - val_mean_squared_error: 8.4003e-05 - val_accuracy: 0.0057\n",
      "Epoch 6/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 8.0359e-05 - mean_squared_error: 8.0359e-05 - accuracy: 0.0068 - val_loss: 8.0020e-05 - val_mean_squared_error: 8.0020e-05 - val_accuracy: 0.0057\n",
      "Epoch 7/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.5613e-05 - mean_squared_error: 7.5613e-05 - accuracy: 0.0068 - val_loss: 7.6557e-05 - val_mean_squared_error: 7.6557e-05 - val_accuracy: 0.0057\n",
      "Epoch 8/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.3186e-05 - mean_squared_error: 7.3186e-05 - accuracy: 0.0068 - val_loss: 7.4074e-05 - val_mean_squared_error: 7.4074e-05 - val_accuracy: 0.0057\n",
      "Epoch 9/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.0832e-05 - mean_squared_error: 7.0832e-05 - accuracy: 0.0068 - val_loss: 7.3354e-05 - val_mean_squared_error: 7.3354e-05 - val_accuracy: 0.0057\n",
      "Epoch 10/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.9957e-05 - mean_squared_error: 6.9957e-05 - accuracy: 0.0068 - val_loss: 7.2267e-05 - val_mean_squared_error: 7.2267e-05 - val_accuracy: 0.0057\n",
      "Epoch 11/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.8698e-05 - mean_squared_error: 6.8698e-05 - accuracy: 0.0068 - val_loss: 7.1355e-05 - val_mean_squared_error: 7.1355e-05 - val_accuracy: 0.0057\n",
      "Epoch 12/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.8108e-05 - mean_squared_error: 6.8108e-05 - accuracy: 0.0068 - val_loss: 7.0131e-05 - val_mean_squared_error: 7.0131e-05 - val_accuracy: 0.0057\n",
      "Epoch 13/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.7704e-05 - mean_squared_error: 6.7704e-05 - accuracy: 0.0068 - val_loss: 6.9738e-05 - val_mean_squared_error: 6.9738e-05 - val_accuracy: 0.0057\n",
      "Epoch 14/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.8539e-05 - mean_squared_error: 6.8539e-05 - accuracy: 0.0068 - val_loss: 7.3306e-05 - val_mean_squared_error: 7.3306e-05 - val_accuracy: 0.0057\n",
      "Epoch 15/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.7127e-05 - mean_squared_error: 6.7127e-05 - accuracy: 0.0068 - val_loss: 7.0326e-05 - val_mean_squared_error: 7.0326e-05 - val_accuracy: 0.0057\n",
      "Epoch 16/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6523e-05 - mean_squared_error: 6.6523e-05 - accuracy: 0.0068 - val_loss: 6.9568e-05 - val_mean_squared_error: 6.9568e-05 - val_accuracy: 0.0057\n",
      "Epoch 17/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6678e-05 - mean_squared_error: 6.6678e-05 - accuracy: 0.0068 - val_loss: 6.9564e-05 - val_mean_squared_error: 6.9564e-05 - val_accuracy: 0.0057\n",
      "Epoch 18/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6243e-05 - mean_squared_error: 6.6243e-05 - accuracy: 0.0068 - val_loss: 6.9260e-05 - val_mean_squared_error: 6.9260e-05 - val_accuracy: 0.0057\n",
      "Epoch 19/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.5956e-05 - mean_squared_error: 6.5956e-05 - accuracy: 0.0068 - val_loss: 6.9048e-05 - val_mean_squared_error: 6.9048e-05 - val_accuracy: 0.0057\n",
      "Epoch 20/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6109e-05 - mean_squared_error: 6.6109e-05 - accuracy: 0.0068 - val_loss: 6.9392e-05 - val_mean_squared_error: 6.9393e-05 - val_accuracy: 0.0057\n",
      "Epoch 21/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.5907e-05 - mean_squared_error: 6.5907e-05 - accuracy: 0.0068 - val_loss: 6.8710e-05 - val_mean_squared_error: 6.8710e-05 - val_accuracy: 0.0057\n",
      "Epoch 22/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.5524e-05 - mean_squared_error: 6.5524e-05 - accuracy: 0.0068 - val_loss: 6.8576e-05 - val_mean_squared_error: 6.8576e-05 - val_accuracy: 0.0057\n",
      "Epoch 23/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.5686e-05 - mean_squared_error: 6.5686e-05 - accuracy: 0.0068 - val_loss: 6.8631e-05 - val_mean_squared_error: 6.8631e-05 - val_accuracy: 0.0057\n",
      "Epoch 24/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.5656e-05 - mean_squared_error: 6.5656e-05 - accuracy: 0.0068 - val_loss: 6.9027e-05 - val_mean_squared_error: 6.9027e-05 - val_accuracy: 0.0057\n",
      "Epoch 25/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.5435e-05 - mean_squared_error: 6.5435e-05 - accuracy: 0.0068 - val_loss: 6.8662e-05 - val_mean_squared_error: 6.8662e-05 - val_accuracy: 0.0057\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 21)                40501     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          42481     \n",
      "=================================================================\n",
      "Total params: 82,982\n",
      "Trainable params: 82,342\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 21)                33621     \n",
      "=================================================================\n",
      "Total params: 40,501\n",
      "Trainable params: 40,181\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 7.0963e-05 - mean_squared_error: 7.0963e-05 - accuracy: 0.0057\n",
      "MSE results: 7.096293120412156e-05\n",
      "accuracy results: 0.005654558073729277\n",
      "metrics names ['loss', 'mean_squared_error', 'accuracy']\n",
      "fold iteration # 6  lat dim 21\n",
      "MSE (valid) [6.602079520234838e-05, 6.825737364124507e-05, 6.856777326902375e-05, 6.644536915700883e-05, 7.096293120412156e-05], lat dim 21\n",
      "Train idx = [    0     1     2 ... 29181 29182 29183] test idx = [    5    13    14 ... 29175 29178 29179]\n",
      "training set size=(23347, 80, 1, 1)\n",
      "test set size=(5837, 80, 1, 1)\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 22)                35222     \n",
      "=================================================================\n",
      "Total params: 42,102\n",
      "Trainable params: 41,782\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 22)]              0         \n",
      "_________________________________________________________________\n",
      "dec_dense_4_reshape (Dense)  (None, 1600)              36800     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_2 (Dense)      (None, 80, 1, 20)         420       \n",
      "_________________________________________________________________\n",
      "decoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "decoder_relu_2 (ReLU)        (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_1 (Dense)      (None, 80, 1, 60)         1260      \n",
      "_________________________________________________________________\n",
      "decoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "decoder_relu_1 (ReLU)        (None, 80, 1, 60)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_0 (Dense)      (None, 80, 1, 80)         4880      \n",
      "_________________________________________________________________\n",
      "decoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "decoder_relu_0 (ReLU)        (None, 80, 1, 80)         0         \n",
      "_________________________________________________________________\n",
      "decoder_last_layer (Dense)   (None, 80, 1, 1)          81        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 80, 1, 1)          0         \n",
      "=================================================================\n",
      "Total params: 44,081\n",
      "Trainable params: 43,761\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 22)                42102     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          44081     \n",
      "=================================================================\n",
      "Total params: 86,183\n",
      "Trainable params: 85,543\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - accuracy: 0.0067 - val_loss: 2.6690e-04 - val_mean_squared_error: 2.6690e-04 - val_accuracy: 0.0058\n",
      "Epoch 2/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 1.9535e-04 - mean_squared_error: 1.9535e-04 - accuracy: 0.0068 - val_loss: 1.3900e-04 - val_mean_squared_error: 1.3900e-04 - val_accuracy: 0.0058\n",
      "Epoch 3/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 1.2491e-04 - mean_squared_error: 1.2491e-04 - accuracy: 0.0068 - val_loss: 1.0571e-04 - val_mean_squared_error: 1.0571e-04 - val_accuracy: 0.0058\n",
      "Epoch 4/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 1.0095e-04 - mean_squared_error: 1.0095e-04 - accuracy: 0.0068 - val_loss: 8.9824e-05 - val_mean_squared_error: 8.9824e-05 - val_accuracy: 0.0058\n",
      "Epoch 5/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 8.7913e-05 - mean_squared_error: 8.7913e-05 - accuracy: 0.0068 - val_loss: 8.3195e-05 - val_mean_squared_error: 8.3195e-05 - val_accuracy: 0.0058\n",
      "Epoch 6/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 8.0609e-05 - mean_squared_error: 8.0609e-05 - accuracy: 0.0068 - val_loss: 7.6285e-05 - val_mean_squared_error: 7.6285e-05 - val_accuracy: 0.0058\n",
      "Epoch 7/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.5687e-05 - mean_squared_error: 7.5687e-05 - accuracy: 0.0068 - val_loss: 7.1287e-05 - val_mean_squared_error: 7.1287e-05 - val_accuracy: 0.0058\n",
      "Epoch 8/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 7.3032e-05 - mean_squared_error: 7.3032e-05 - accuracy: 0.0068 - val_loss: 7.0877e-05 - val_mean_squared_error: 7.0877e-05 - val_accuracy: 0.0058\n",
      "Epoch 9/25\n",
      "730/730 [==============================] - 16s 23ms/step - loss: 7.0870e-05 - mean_squared_error: 7.0870e-05 - accuracy: 0.0068 - val_loss: 6.8036e-05 - val_mean_squared_error: 6.8036e-05 - val_accuracy: 0.0058\n",
      "Epoch 10/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.9617e-05 - mean_squared_error: 6.9617e-05 - accuracy: 0.0068 - val_loss: 6.6949e-05 - val_mean_squared_error: 6.6949e-05 - val_accuracy: 0.0058\n",
      "Epoch 11/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.8900e-05 - mean_squared_error: 6.8900e-05 - accuracy: 0.0068 - val_loss: 6.7040e-05 - val_mean_squared_error: 6.7040e-05 - val_accuracy: 0.0058\n",
      "Epoch 12/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.8508e-05 - mean_squared_error: 6.8508e-05 - accuracy: 0.0068 - val_loss: 6.9457e-05 - val_mean_squared_error: 6.9457e-05 - val_accuracy: 0.0058\n",
      "Epoch 13/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.7730e-05 - mean_squared_error: 6.7730e-05 - accuracy: 0.0068 - val_loss: 6.7604e-05 - val_mean_squared_error: 6.7604e-05 - val_accuracy: 0.0058\n",
      "Epoch 14/25\n",
      "730/730 [==============================] - 16s 23ms/step - loss: 6.7201e-05 - mean_squared_error: 6.7201e-05 - accuracy: 0.0068 - val_loss: 6.5794e-05 - val_mean_squared_error: 6.5794e-05 - val_accuracy: 0.0058\n",
      "Epoch 15/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.6996e-05 - mean_squared_error: 6.6996e-05 - accuracy: 0.0068 - val_loss: 6.5676e-05 - val_mean_squared_error: 6.5676e-05 - val_accuracy: 0.0058\n",
      "Epoch 16/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.6938e-05 - mean_squared_error: 6.6938e-05 - accuracy: 0.0068 - val_loss: 6.5351e-05 - val_mean_squared_error: 6.5352e-05 - val_accuracy: 0.0058\n",
      "Epoch 17/25\n",
      "730/730 [==============================] - 17s 24ms/step - loss: 6.6779e-05 - mean_squared_error: 6.6779e-05 - accuracy: 0.0068 - val_loss: 6.5321e-05 - val_mean_squared_error: 6.5321e-05 - val_accuracy: 0.0058\n",
      "Epoch 18/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6661e-05 - mean_squared_error: 6.6661e-05 - accuracy: 0.0068 - val_loss: 6.5125e-05 - val_mean_squared_error: 6.5125e-05 - val_accuracy: 0.0058\n",
      "Epoch 19/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6295e-05 - mean_squared_error: 6.6295e-05 - accuracy: 0.0068 - val_loss: 6.4969e-05 - val_mean_squared_error: 6.4969e-05 - val_accuracy: 0.0058\n",
      "Epoch 20/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.6364e-05 - mean_squared_error: 6.6364e-05 - accuracy: 0.0068 - val_loss: 6.5158e-05 - val_mean_squared_error: 6.5158e-05 - val_accuracy: 0.0058\n",
      "Epoch 21/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6219e-05 - mean_squared_error: 6.6219e-05 - accuracy: 0.0068 - val_loss: 6.6483e-05 - val_mean_squared_error: 6.6483e-05 - val_accuracy: 0.0058\n",
      "Epoch 22/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6199e-05 - mean_squared_error: 6.6199e-05 - accuracy: 0.0068 - val_loss: 6.5557e-05 - val_mean_squared_error: 6.5557e-05 - val_accuracy: 0.0058\n",
      "Epoch 23/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.5958e-05 - mean_squared_error: 6.5958e-05 - accuracy: 0.0068 - val_loss: 6.5190e-05 - val_mean_squared_error: 6.5190e-05 - val_accuracy: 0.0058\n",
      "Epoch 24/25\n",
      "730/730 [==============================] - 16s 23ms/step - loss: 6.5980e-05 - mean_squared_error: 6.5980e-05 - accuracy: 0.0068 - val_loss: 6.4940e-05 - val_mean_squared_error: 6.4940e-05 - val_accuracy: 0.0058\n",
      "Epoch 25/25\n",
      "730/730 [==============================] - 16s 23ms/step - loss: 6.5845e-05 - mean_squared_error: 6.5845e-05 - accuracy: 0.0068 - val_loss: 6.4839e-05 - val_mean_squared_error: 6.4839e-05 - val_accuracy: 0.0058\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 22)                42102     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          44081     \n",
      "=================================================================\n",
      "Total params: 86,183\n",
      "Trainable params: 85,543\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 22)                35222     \n",
      "=================================================================\n",
      "Total params: 42,102\n",
      "Trainable params: 41,782\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 6.7898e-05 - mean_squared_error: 6.7898e-05 - accuracy: 0.0058\n",
      "MSE results: 6.789761391701177e-05\n",
      "accuracy results: 0.005824910011142492\n",
      "metrics names ['loss', 'mean_squared_error', 'accuracy']\n",
      "fold iteration # 2  lat dim 22\n",
      "MSE (valid) [6.789761391701177e-05], lat dim 22\n",
      "Train idx = [    0     1     2 ... 29180 29181 29182] test idx = [    4     7     8 ... 29135 29144 29183]\n",
      "training set size=(23347, 80, 1, 1)\n",
      "test set size=(5837, 80, 1, 1)\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 22)                35222     \n",
      "=================================================================\n",
      "Total params: 42,102\n",
      "Trainable params: 41,782\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 22)]              0         \n",
      "_________________________________________________________________\n",
      "dec_dense_4_reshape (Dense)  (None, 1600)              36800     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_2 (Dense)      (None, 80, 1, 20)         420       \n",
      "_________________________________________________________________\n",
      "decoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "decoder_relu_2 (ReLU)        (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_1 (Dense)      (None, 80, 1, 60)         1260      \n",
      "_________________________________________________________________\n",
      "decoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "decoder_relu_1 (ReLU)        (None, 80, 1, 60)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_0 (Dense)      (None, 80, 1, 80)         4880      \n",
      "_________________________________________________________________\n",
      "decoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "decoder_relu_0 (ReLU)        (None, 80, 1, 80)         0         \n",
      "_________________________________________________________________\n",
      "decoder_last_layer (Dense)   (None, 80, 1, 1)          81        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 80, 1, 1)          0         \n",
      "=================================================================\n",
      "Total params: 44,081\n",
      "Trainable params: 43,761\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 22)                42102     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          44081     \n",
      "=================================================================\n",
      "Total params: 86,183\n",
      "Trainable params: 85,543\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - accuracy: 0.0064 - val_loss: 2.6268e-04 - val_mean_squared_error: 2.6268e-04 - val_accuracy: 0.0072\n",
      "Epoch 2/25\n",
      "730/730 [==============================] - 15s 20ms/step - loss: 1.8475e-04 - mean_squared_error: 1.8475e-04 - accuracy: 0.0064 - val_loss: 1.2616e-04 - val_mean_squared_error: 1.2616e-04 - val_accuracy: 0.0072\n",
      "Epoch 3/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 1.1319e-04 - mean_squared_error: 1.1319e-04 - accuracy: 0.0064 - val_loss: 1.0047e-04 - val_mean_squared_error: 1.0047e-04 - val_accuracy: 0.0072\n",
      "Epoch 4/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 9.0189e-05 - mean_squared_error: 9.0189e-05 - accuracy: 0.0064 - val_loss: 8.4867e-05 - val_mean_squared_error: 8.4867e-05 - val_accuracy: 0.0072\n",
      "Epoch 5/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 8.0188e-05 - mean_squared_error: 8.0188e-05 - accuracy: 0.0064 - val_loss: 7.7858e-05 - val_mean_squared_error: 7.7858e-05 - val_accuracy: 0.0072\n",
      "Epoch 6/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 7.5367e-05 - mean_squared_error: 7.5367e-05 - accuracy: 0.0064 - val_loss: 7.4824e-05 - val_mean_squared_error: 7.4824e-05 - val_accuracy: 0.0072\n",
      "Epoch 7/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 7.2210e-05 - mean_squared_error: 7.2210e-05 - accuracy: 0.0064 - val_loss: 7.2044e-05 - val_mean_squared_error: 7.2044e-05 - val_accuracy: 0.0072\n",
      "Epoch 8/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 7.0087e-05 - mean_squared_error: 7.0087e-05 - accuracy: 0.0064 - val_loss: 7.0943e-05 - val_mean_squared_error: 7.0943e-05 - val_accuracy: 0.0072\n",
      "Epoch 9/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 6.9615e-05 - mean_squared_error: 6.9615e-05 - accuracy: 0.0064 - val_loss: 6.9978e-05 - val_mean_squared_error: 6.9978e-05 - val_accuracy: 0.0072\n",
      "Epoch 10/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.8374e-05 - mean_squared_error: 6.8374e-05 - accuracy: 0.0064 - val_loss: 6.9252e-05 - val_mean_squared_error: 6.9252e-05 - val_accuracy: 0.0072\n",
      "Epoch 11/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.8261e-05 - mean_squared_error: 6.8261e-05 - accuracy: 0.0064 - val_loss: 6.9074e-05 - val_mean_squared_error: 6.9074e-05 - val_accuracy: 0.0072\n",
      "Epoch 12/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.7651e-05 - mean_squared_error: 6.7651e-05 - accuracy: 0.0064 - val_loss: 6.8673e-05 - val_mean_squared_error: 6.8673e-05 - val_accuracy: 0.0072\n",
      "Epoch 13/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.7536e-05 - mean_squared_error: 6.7536e-05 - accuracy: 0.0064 - val_loss: 6.8661e-05 - val_mean_squared_error: 6.8661e-05 - val_accuracy: 0.0072\n",
      "Epoch 14/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.6833e-05 - mean_squared_error: 6.6833e-05 - accuracy: 0.0064 - val_loss: 6.7989e-05 - val_mean_squared_error: 6.7989e-05 - val_accuracy: 0.0072\n",
      "Epoch 15/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6823e-05 - mean_squared_error: 6.6823e-05 - accuracy: 0.0064 - val_loss: 6.8093e-05 - val_mean_squared_error: 6.8093e-05 - val_accuracy: 0.0072\n",
      "Epoch 16/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.6502e-05 - mean_squared_error: 6.6502e-05 - accuracy: 0.0064 - val_loss: 6.8856e-05 - val_mean_squared_error: 6.8856e-05 - val_accuracy: 0.0072\n",
      "Epoch 17/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.6404e-05 - mean_squared_error: 6.6404e-05 - accuracy: 0.0064 - val_loss: 6.7637e-05 - val_mean_squared_error: 6.7637e-05 - val_accuracy: 0.0072\n",
      "Epoch 18/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 6.6238e-05 - mean_squared_error: 6.6238e-05 - accuracy: 0.0064 - val_loss: 7.6252e-05 - val_mean_squared_error: 7.6252e-05 - val_accuracy: 0.0072\n",
      "Epoch 19/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 6.6064e-05 - mean_squared_error: 6.6064e-05 - accuracy: 0.0064 - val_loss: 6.7946e-05 - val_mean_squared_error: 6.7946e-05 - val_accuracy: 0.0072\n",
      "Epoch 20/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.6452e-05 - mean_squared_error: 6.6452e-05 - accuracy: 0.0064 - val_loss: 6.7427e-05 - val_mean_squared_error: 6.7427e-05 - val_accuracy: 0.0072\n",
      "Epoch 21/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.5882e-05 - mean_squared_error: 6.5882e-05 - accuracy: 0.0064 - val_loss: 6.7881e-05 - val_mean_squared_error: 6.7881e-05 - val_accuracy: 0.0072\n",
      "Epoch 22/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.5610e-05 - mean_squared_error: 6.5610e-05 - accuracy: 0.0064 - val_loss: 6.7772e-05 - val_mean_squared_error: 6.7772e-05 - val_accuracy: 0.0072\n",
      "Epoch 23/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.5531e-05 - mean_squared_error: 6.5531e-05 - accuracy: 0.0064 - val_loss: 6.7848e-05 - val_mean_squared_error: 6.7848e-05 - val_accuracy: 0.0072\n",
      "Epoch 24/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 6.5530e-05 - mean_squared_error: 6.5530e-05 - accuracy: 0.0064 - val_loss: 6.8178e-05 - val_mean_squared_error: 6.8178e-05 - val_accuracy: 0.0072\n",
      "Epoch 25/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.5755e-05 - mean_squared_error: 6.5755e-05 - accuracy: 0.0064 - val_loss: 6.7660e-05 - val_mean_squared_error: 6.7660e-05 - val_accuracy: 0.0072\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 22)                42102     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          44081     \n",
      "=================================================================\n",
      "Total params: 86,183\n",
      "Trainable params: 85,543\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 22)                35222     \n",
      "=================================================================\n",
      "Total params: 42,102\n",
      "Trainable params: 41,782\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 7.1002e-05 - mean_squared_error: 7.1002e-05 - accuracy: 0.0072\n",
      "MSE results: 7.10024032741785e-05\n",
      "accuracy results: 0.007195476908236742\n",
      "metrics names ['loss', 'mean_squared_error', 'accuracy']\n",
      "fold iteration # 3  lat dim 22\n",
      "MSE (valid) [6.789761391701177e-05, 7.10024032741785e-05], lat dim 22\n",
      "Train idx = [    0     1     2 ... 29181 29182 29183] test idx = [    3     9    18 ... 29172 29177 29180]\n",
      "training set size=(23347, 80, 1, 1)\n",
      "test set size=(5837, 80, 1, 1)\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 22)                35222     \n",
      "=================================================================\n",
      "Total params: 42,102\n",
      "Trainable params: 41,782\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 22)]              0         \n",
      "_________________________________________________________________\n",
      "dec_dense_4_reshape (Dense)  (None, 1600)              36800     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_2 (Dense)      (None, 80, 1, 20)         420       \n",
      "_________________________________________________________________\n",
      "decoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "decoder_relu_2 (ReLU)        (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_1 (Dense)      (None, 80, 1, 60)         1260      \n",
      "_________________________________________________________________\n",
      "decoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "decoder_relu_1 (ReLU)        (None, 80, 1, 60)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_0 (Dense)      (None, 80, 1, 80)         4880      \n",
      "_________________________________________________________________\n",
      "decoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "decoder_relu_0 (ReLU)        (None, 80, 1, 80)         0         \n",
      "_________________________________________________________________\n",
      "decoder_last_layer (Dense)   (None, 80, 1, 1)          81        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 80, 1, 1)          0         \n",
      "=================================================================\n",
      "Total params: 44,081\n",
      "Trainable params: 43,761\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 22)                42102     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          44081     \n",
      "=================================================================\n",
      "Total params: 86,183\n",
      "Trainable params: 85,543\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 0.0129 - mean_squared_error: 0.0129 - accuracy: 0.0068 - val_loss: 3.1762e-04 - val_mean_squared_error: 3.1762e-04 - val_accuracy: 0.0058\n",
      "Epoch 2/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 2.2201e-04 - mean_squared_error: 2.2201e-04 - accuracy: 0.0068 - val_loss: 1.4627e-04 - val_mean_squared_error: 1.4627e-04 - val_accuracy: 0.0058\n",
      "Epoch 3/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 1.3279e-04 - mean_squared_error: 1.3279e-04 - accuracy: 0.0068 - val_loss: 1.0774e-04 - val_mean_squared_error: 1.0774e-04 - val_accuracy: 0.0058\n",
      "Epoch 4/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 1.0528e-04 - mean_squared_error: 1.0528e-04 - accuracy: 0.0068 - val_loss: 8.9075e-05 - val_mean_squared_error: 8.9075e-05 - val_accuracy: 0.0058\n",
      "Epoch 5/25\n",
      "730/730 [==============================] - 16s 23ms/step - loss: 9.2793e-05 - mean_squared_error: 9.2793e-05 - accuracy: 0.0068 - val_loss: 8.2543e-05 - val_mean_squared_error: 8.2543e-05 - val_accuracy: 0.0058\n",
      "Epoch 6/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 8.4408e-05 - mean_squared_error: 8.4408e-05 - accuracy: 0.0068 - val_loss: 7.6116e-05 - val_mean_squared_error: 7.6116e-05 - val_accuracy: 0.0058\n",
      "Epoch 7/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.9482e-05 - mean_squared_error: 7.9482e-05 - accuracy: 0.0068 - val_loss: 7.0482e-05 - val_mean_squared_error: 7.0482e-05 - val_accuracy: 0.0058\n",
      "Epoch 8/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.5752e-05 - mean_squared_error: 7.5752e-05 - accuracy: 0.0068 - val_loss: 6.9250e-05 - val_mean_squared_error: 6.9250e-05 - val_accuracy: 0.0058\n",
      "Epoch 9/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.3859e-05 - mean_squared_error: 7.3859e-05 - accuracy: 0.0068 - val_loss: 6.5559e-05 - val_mean_squared_error: 6.5559e-05 - val_accuracy: 0.0058\n",
      "Epoch 10/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 7.2143e-05 - mean_squared_error: 7.2143e-05 - accuracy: 0.0068 - val_loss: 6.5118e-05 - val_mean_squared_error: 6.5118e-05 - val_accuracy: 0.0058\n",
      "Epoch 11/25\n",
      "730/730 [==============================] - 18s 24ms/step - loss: 7.0525e-05 - mean_squared_error: 7.0525e-05 - accuracy: 0.0068 - val_loss: 6.3682e-05 - val_mean_squared_error: 6.3682e-05 - val_accuracy: 0.0058\n",
      "Epoch 12/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 7.1440e-05 - mean_squared_error: 7.1440e-05 - accuracy: 0.0068 - val_loss: 6.8218e-05 - val_mean_squared_error: 6.8218e-05 - val_accuracy: 0.0058\n",
      "Epoch 13/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.0906e-05 - mean_squared_error: 7.0906e-05 - accuracy: 0.0068 - val_loss: 6.2815e-05 - val_mean_squared_error: 6.2815e-05 - val_accuracy: 0.0058\n",
      "Epoch 14/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.8994e-05 - mean_squared_error: 6.8994e-05 - accuracy: 0.0068 - val_loss: 6.3227e-05 - val_mean_squared_error: 6.3227e-05 - val_accuracy: 0.0058\n",
      "Epoch 15/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.8529e-05 - mean_squared_error: 6.8529e-05 - accuracy: 0.0068 - val_loss: 6.2078e-05 - val_mean_squared_error: 6.2078e-05 - val_accuracy: 0.0058\n",
      "Epoch 16/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.7979e-05 - mean_squared_error: 6.7979e-05 - accuracy: 0.0068 - val_loss: 6.2183e-05 - val_mean_squared_error: 6.2183e-05 - val_accuracy: 0.0058\n",
      "Epoch 17/25\n",
      "730/730 [==============================] - 16s 23ms/step - loss: 6.7945e-05 - mean_squared_error: 6.7945e-05 - accuracy: 0.0068 - val_loss: 6.1479e-05 - val_mean_squared_error: 6.1479e-05 - val_accuracy: 0.0058\n",
      "Epoch 18/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.7616e-05 - mean_squared_error: 6.7616e-05 - accuracy: 0.0068 - val_loss: 6.1577e-05 - val_mean_squared_error: 6.1577e-05 - val_accuracy: 0.0058\n",
      "Epoch 19/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.7685e-05 - mean_squared_error: 6.7685e-05 - accuracy: 0.0068 - val_loss: 6.1438e-05 - val_mean_squared_error: 6.1438e-05 - val_accuracy: 0.0058\n",
      "Epoch 20/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.7367e-05 - mean_squared_error: 6.7367e-05 - accuracy: 0.0068 - val_loss: 6.2026e-05 - val_mean_squared_error: 6.2026e-05 - val_accuracy: 0.0058\n",
      "Epoch 21/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.7290e-05 - mean_squared_error: 6.7290e-05 - accuracy: 0.0068 - val_loss: 6.1110e-05 - val_mean_squared_error: 6.1110e-05 - val_accuracy: 0.0058\n",
      "Epoch 22/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.7135e-05 - mean_squared_error: 6.7135e-05 - accuracy: 0.0068 - val_loss: 6.1236e-05 - val_mean_squared_error: 6.1236e-05 - val_accuracy: 0.0058\n",
      "Epoch 23/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.7056e-05 - mean_squared_error: 6.7056e-05 - accuracy: 0.0068 - val_loss: 6.2226e-05 - val_mean_squared_error: 6.2226e-05 - val_accuracy: 0.0058\n",
      "Epoch 24/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.7105e-05 - mean_squared_error: 6.7105e-05 - accuracy: 0.0068 - val_loss: 6.2314e-05 - val_mean_squared_error: 6.2314e-05 - val_accuracy: 0.0058\n",
      "Epoch 25/25\n",
      "730/730 [==============================] - 16s 23ms/step - loss: 6.6994e-05 - mean_squared_error: 6.6994e-05 - accuracy: 0.0068 - val_loss: 6.1131e-05 - val_mean_squared_error: 6.1131e-05 - val_accuracy: 0.0058\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 22)                42102     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          44081     \n",
      "=================================================================\n",
      "Total params: 86,183\n",
      "Trainable params: 85,543\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 22)                35222     \n",
      "=================================================================\n",
      "Total params: 42,102\n",
      "Trainable params: 41,782\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 6.3910e-05 - mean_squared_error: 6.3910e-05 - accuracy: 0.0058\n",
      "MSE results: 6.391012720996514e-05\n",
      "accuracy results: 0.005824910011142492\n",
      "metrics names ['loss', 'mean_squared_error', 'accuracy']\n",
      "fold iteration # 4  lat dim 22\n",
      "MSE (valid) [6.789761391701177e-05, 7.10024032741785e-05, 6.391012720996514e-05], lat dim 22\n",
      "Train idx = [    0     2     3 ... 29180 29181 29183] test idx = [    1     6    12 ... 29174 29176 29182]\n",
      "training set size=(23347, 80, 1, 1)\n",
      "test set size=(5837, 80, 1, 1)\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 22)                35222     \n",
      "=================================================================\n",
      "Total params: 42,102\n",
      "Trainable params: 41,782\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 22)]              0         \n",
      "_________________________________________________________________\n",
      "dec_dense_4_reshape (Dense)  (None, 1600)              36800     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_2 (Dense)      (None, 80, 1, 20)         420       \n",
      "_________________________________________________________________\n",
      "decoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "decoder_relu_2 (ReLU)        (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_1 (Dense)      (None, 80, 1, 60)         1260      \n",
      "_________________________________________________________________\n",
      "decoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "decoder_relu_1 (ReLU)        (None, 80, 1, 60)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_0 (Dense)      (None, 80, 1, 80)         4880      \n",
      "_________________________________________________________________\n",
      "decoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "decoder_relu_0 (ReLU)        (None, 80, 1, 80)         0         \n",
      "_________________________________________________________________\n",
      "decoder_last_layer (Dense)   (None, 80, 1, 1)          81        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 80, 1, 1)          0         \n",
      "=================================================================\n",
      "Total params: 44,081\n",
      "Trainable params: 43,761\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 22)                42102     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          44081     \n",
      "=================================================================\n",
      "Total params: 86,183\n",
      "Trainable params: 85,543\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 0.0077 - mean_squared_error: 0.0077 - accuracy: 0.0066 - val_loss: 2.8433e-04 - val_mean_squared_error: 2.8433e-04 - val_accuracy: 0.0065\n",
      "Epoch 2/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 1.9251e-04 - mean_squared_error: 1.9251e-04 - accuracy: 0.0066 - val_loss: 1.3964e-04 - val_mean_squared_error: 1.3964e-04 - val_accuracy: 0.0065\n",
      "Epoch 3/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 1.1674e-04 - mean_squared_error: 1.1674e-04 - accuracy: 0.0066 - val_loss: 1.0154e-04 - val_mean_squared_error: 1.0154e-04 - val_accuracy: 0.0065\n",
      "Epoch 4/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 9.2675e-05 - mean_squared_error: 9.2675e-05 - accuracy: 0.0066 - val_loss: 8.5741e-05 - val_mean_squared_error: 8.5741e-05 - val_accuracy: 0.0065\n",
      "Epoch 5/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 8.1705e-05 - mean_squared_error: 8.1705e-05 - accuracy: 0.0066 - val_loss: 7.8704e-05 - val_mean_squared_error: 7.8704e-05 - val_accuracy: 0.0065\n",
      "Epoch 6/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.6004e-05 - mean_squared_error: 7.6004e-05 - accuracy: 0.0066 - val_loss: 7.4833e-05 - val_mean_squared_error: 7.4833e-05 - val_accuracy: 0.0065\n",
      "Epoch 7/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.2667e-05 - mean_squared_error: 7.2667e-05 - accuracy: 0.0066 - val_loss: 7.5591e-05 - val_mean_squared_error: 7.5591e-05 - val_accuracy: 0.0065\n",
      "Epoch 8/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.0766e-05 - mean_squared_error: 7.0766e-05 - accuracy: 0.0066 - val_loss: 7.0894e-05 - val_mean_squared_error: 7.0894e-05 - val_accuracy: 0.0065\n",
      "Epoch 9/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.0503e-05 - mean_squared_error: 7.0503e-05 - accuracy: 0.0066 - val_loss: 7.5672e-05 - val_mean_squared_error: 7.5672e-05 - val_accuracy: 0.0065\n",
      "Epoch 10/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.9202e-05 - mean_squared_error: 6.9202e-05 - accuracy: 0.0066 - val_loss: 6.9190e-05 - val_mean_squared_error: 6.9190e-05 - val_accuracy: 0.0065\n",
      "Epoch 11/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.7638e-05 - mean_squared_error: 6.7638e-05 - accuracy: 0.0066 - val_loss: 6.8484e-05 - val_mean_squared_error: 6.8484e-05 - val_accuracy: 0.0065\n",
      "Epoch 12/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.7766e-05 - mean_squared_error: 6.7766e-05 - accuracy: 0.0066 - val_loss: 6.8278e-05 - val_mean_squared_error: 6.8278e-05 - val_accuracy: 0.0065\n",
      "Epoch 13/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.7086e-05 - mean_squared_error: 6.7086e-05 - accuracy: 0.0066 - val_loss: 6.7887e-05 - val_mean_squared_error: 6.7887e-05 - val_accuracy: 0.0065\n",
      "Epoch 14/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6953e-05 - mean_squared_error: 6.6953e-05 - accuracy: 0.0066 - val_loss: 6.8413e-05 - val_mean_squared_error: 6.8413e-05 - val_accuracy: 0.0065\n",
      "Epoch 15/25\n",
      "730/730 [==============================] - 18s 25ms/step - loss: 6.6414e-05 - mean_squared_error: 6.6414e-05 - accuracy: 0.0066 - val_loss: 6.7946e-05 - val_mean_squared_error: 6.7946e-05 - val_accuracy: 0.0065\n",
      "Epoch 16/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6655e-05 - mean_squared_error: 6.6655e-05 - accuracy: 0.0066 - val_loss: 6.7925e-05 - val_mean_squared_error: 6.7925e-05 - val_accuracy: 0.0065\n",
      "Epoch 17/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6329e-05 - mean_squared_error: 6.6329e-05 - accuracy: 0.0066 - val_loss: 6.7976e-05 - val_mean_squared_error: 6.7976e-05 - val_accuracy: 0.0065\n",
      "Epoch 18/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6385e-05 - mean_squared_error: 6.6385e-05 - accuracy: 0.0066 - val_loss: 6.7425e-05 - val_mean_squared_error: 6.7425e-05 - val_accuracy: 0.0065\n",
      "Epoch 19/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6148e-05 - mean_squared_error: 6.6148e-05 - accuracy: 0.0066 - val_loss: 6.7243e-05 - val_mean_squared_error: 6.7243e-05 - val_accuracy: 0.0065\n",
      "Epoch 20/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.5983e-05 - mean_squared_error: 6.5983e-05 - accuracy: 0.0066 - val_loss: 6.7440e-05 - val_mean_squared_error: 6.7440e-05 - val_accuracy: 0.0065\n",
      "Epoch 21/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.5982e-05 - mean_squared_error: 6.5982e-05 - accuracy: 0.0066 - val_loss: 6.7322e-05 - val_mean_squared_error: 6.7322e-05 - val_accuracy: 0.0065\n",
      "Epoch 22/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.5818e-05 - mean_squared_error: 6.5818e-05 - accuracy: 0.0066 - val_loss: 6.8235e-05 - val_mean_squared_error: 6.8235e-05 - val_accuracy: 0.0065\n",
      "Epoch 23/25\n",
      "730/730 [==============================] - 16s 23ms/step - loss: 6.5520e-05 - mean_squared_error: 6.5520e-05 - accuracy: 0.0066 - val_loss: 6.7949e-05 - val_mean_squared_error: 6.7949e-05 - val_accuracy: 0.0065\n",
      "Epoch 24/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.5826e-05 - mean_squared_error: 6.5826e-05 - accuracy: 0.0066 - val_loss: 6.7233e-05 - val_mean_squared_error: 6.7233e-05 - val_accuracy: 0.0065\n",
      "Epoch 25/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.5549e-05 - mean_squared_error: 6.5549e-05 - accuracy: 0.0066 - val_loss: 6.7152e-05 - val_mean_squared_error: 6.7152e-05 - val_accuracy: 0.0065\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 22)                42102     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          44081     \n",
      "=================================================================\n",
      "Total params: 86,183\n",
      "Trainable params: 85,543\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 22)                35222     \n",
      "=================================================================\n",
      "Total params: 42,102\n",
      "Trainable params: 41,782\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 6.9809e-05 - mean_squared_error: 6.9810e-05 - accuracy: 0.0065\n",
      "MSE results: 6.980951002333313e-05\n",
      "accuracy results: 0.006510193459689617\n",
      "metrics names ['loss', 'mean_squared_error', 'accuracy']\n",
      "fold iteration # 5  lat dim 22\n",
      "MSE (valid) [6.789761391701177e-05, 7.10024032741785e-05, 6.391012720996514e-05, 6.980951002333313e-05], lat dim 22\n",
      "Train idx = [    1     3     4 ... 29180 29182 29183] test idx = [    0     2    10 ... 29171 29173 29181]\n",
      "training set size=(23348, 80, 1, 1)\n",
      "test set size=(5836, 80, 1, 1)\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 22)                35222     \n",
      "=================================================================\n",
      "Total params: 42,102\n",
      "Trainable params: 41,782\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 22)]              0         \n",
      "_________________________________________________________________\n",
      "dec_dense_4_reshape (Dense)  (None, 1600)              36800     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_2 (Dense)      (None, 80, 1, 20)         420       \n",
      "_________________________________________________________________\n",
      "decoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "decoder_relu_2 (ReLU)        (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_1 (Dense)      (None, 80, 1, 60)         1260      \n",
      "_________________________________________________________________\n",
      "decoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "decoder_relu_1 (ReLU)        (None, 80, 1, 60)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_0 (Dense)      (None, 80, 1, 80)         4880      \n",
      "_________________________________________________________________\n",
      "decoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "decoder_relu_0 (ReLU)        (None, 80, 1, 80)         0         \n",
      "_________________________________________________________________\n",
      "decoder_last_layer (Dense)   (None, 80, 1, 1)          81        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 80, 1, 1)          0         \n",
      "=================================================================\n",
      "Total params: 44,081\n",
      "Trainable params: 43,761\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 22)                42102     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          44081     \n",
      "=================================================================\n",
      "Total params: 86,183\n",
      "Trainable params: 85,543\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - accuracy: 0.0063 - val_loss: 2.1043e-04 - val_mean_squared_error: 2.1043e-04 - val_accuracy: 0.0075\n",
      "Epoch 2/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 1.6652e-04 - mean_squared_error: 1.6652e-04 - accuracy: 0.0063 - val_loss: 1.2039e-04 - val_mean_squared_error: 1.2039e-04 - val_accuracy: 0.0075\n",
      "Epoch 3/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 1.0856e-04 - mean_squared_error: 1.0856e-04 - accuracy: 0.0063 - val_loss: 1.0369e-04 - val_mean_squared_error: 1.0369e-04 - val_accuracy: 0.0075\n",
      "Epoch 4/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 8.8739e-05 - mean_squared_error: 8.8739e-05 - accuracy: 0.0063 - val_loss: 8.0633e-05 - val_mean_squared_error: 8.0633e-05 - val_accuracy: 0.0075\n",
      "Epoch 5/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 7.9627e-05 - mean_squared_error: 7.9627e-05 - accuracy: 0.0063 - val_loss: 7.3880e-05 - val_mean_squared_error: 7.3880e-05 - val_accuracy: 0.0075\n",
      "Epoch 6/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 7.4820e-05 - mean_squared_error: 7.4820e-05 - accuracy: 0.0063 - val_loss: 7.5590e-05 - val_mean_squared_error: 7.5590e-05 - val_accuracy: 0.0075\n",
      "Epoch 7/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 7.2238e-05 - mean_squared_error: 7.2238e-05 - accuracy: 0.0063 - val_loss: 7.1545e-05 - val_mean_squared_error: 7.1545e-05 - val_accuracy: 0.0075\n",
      "Epoch 8/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.0985e-05 - mean_squared_error: 7.0985e-05 - accuracy: 0.0063 - val_loss: 6.9103e-05 - val_mean_squared_error: 6.9103e-05 - val_accuracy: 0.0075\n",
      "Epoch 9/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.9370e-05 - mean_squared_error: 6.9370e-05 - accuracy: 0.0063 - val_loss: 6.7562e-05 - val_mean_squared_error: 6.7562e-05 - val_accuracy: 0.0075\n",
      "Epoch 10/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.8691e-05 - mean_squared_error: 6.8691e-05 - accuracy: 0.0063 - val_loss: 6.6823e-05 - val_mean_squared_error: 6.6823e-05 - val_accuracy: 0.0075\n",
      "Epoch 11/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 6.8473e-05 - mean_squared_error: 6.8473e-05 - accuracy: 0.0063 - val_loss: 6.6250e-05 - val_mean_squared_error: 6.6250e-05 - val_accuracy: 0.0075\n",
      "Epoch 12/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.7836e-05 - mean_squared_error: 6.7836e-05 - accuracy: 0.0063 - val_loss: 6.5878e-05 - val_mean_squared_error: 6.5877e-05 - val_accuracy: 0.0075\n",
      "Epoch 13/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.8129e-05 - mean_squared_error: 6.8129e-05 - accuracy: 0.0063 - val_loss: 6.7044e-05 - val_mean_squared_error: 6.7044e-05 - val_accuracy: 0.0075\n",
      "Epoch 14/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 6.7702e-05 - mean_squared_error: 6.7702e-05 - accuracy: 0.0063 - val_loss: 6.6204e-05 - val_mean_squared_error: 6.6204e-05 - val_accuracy: 0.0075\n",
      "Epoch 15/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 6.7571e-05 - mean_squared_error: 6.7571e-05 - accuracy: 0.0063 - val_loss: 6.5451e-05 - val_mean_squared_error: 6.5451e-05 - val_accuracy: 0.0075\n",
      "Epoch 16/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.7044e-05 - mean_squared_error: 6.7044e-05 - accuracy: 0.0063 - val_loss: 6.5740e-05 - val_mean_squared_error: 6.5740e-05 - val_accuracy: 0.0075\n",
      "Epoch 17/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.6813e-05 - mean_squared_error: 6.6813e-05 - accuracy: 0.0063 - val_loss: 6.5225e-05 - val_mean_squared_error: 6.5225e-05 - val_accuracy: 0.0075\n",
      "Epoch 18/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.7256e-05 - mean_squared_error: 6.7256e-05 - accuracy: 0.0063 - val_loss: 6.5120e-05 - val_mean_squared_error: 6.5120e-05 - val_accuracy: 0.0075\n",
      "Epoch 19/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.6656e-05 - mean_squared_error: 6.6656e-05 - accuracy: 0.0063 - val_loss: 6.5150e-05 - val_mean_squared_error: 6.5150e-05 - val_accuracy: 0.0075\n",
      "Epoch 20/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.6544e-05 - mean_squared_error: 6.6544e-05 - accuracy: 0.0063 - val_loss: 6.5312e-05 - val_mean_squared_error: 6.5312e-05 - val_accuracy: 0.0075\n",
      "Epoch 21/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 6.6660e-05 - mean_squared_error: 6.6660e-05 - accuracy: 0.0063 - val_loss: 6.5692e-05 - val_mean_squared_error: 6.5692e-05 - val_accuracy: 0.0075\n",
      "Epoch 22/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 6.6298e-05 - mean_squared_error: 6.6298e-05 - accuracy: 0.0063 - val_loss: 6.4825e-05 - val_mean_squared_error: 6.4825e-05 - val_accuracy: 0.0075\n",
      "Epoch 23/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.6187e-05 - mean_squared_error: 6.6187e-05 - accuracy: 0.0063 - val_loss: 6.4983e-05 - val_mean_squared_error: 6.4983e-05 - val_accuracy: 0.0075\n",
      "Epoch 24/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.6320e-05 - mean_squared_error: 6.6320e-05 - accuracy: 0.0063 - val_loss: 6.9581e-05 - val_mean_squared_error: 6.9581e-05 - val_accuracy: 0.0075\n",
      "Epoch 25/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.5933e-05 - mean_squared_error: 6.5933e-05 - accuracy: 0.0063 - val_loss: 6.4931e-05 - val_mean_squared_error: 6.4931e-05 - val_accuracy: 0.0075\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 22)                42102     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          44081     \n",
      "=================================================================\n",
      "Total params: 86,183\n",
      "Trainable params: 85,543\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 22)                35222     \n",
      "=================================================================\n",
      "Total params: 42,102\n",
      "Trainable params: 41,782\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 6.7963e-05 - mean_squared_error: 6.7963e-05 - accuracy: 0.0075\n",
      "MSE results: 6.79628283251077e-05\n",
      "accuracy results: 0.00753941060975194\n",
      "metrics names ['loss', 'mean_squared_error', 'accuracy']\n",
      "fold iteration # 6  lat dim 22\n",
      "MSE (valid) [6.789761391701177e-05, 7.10024032741785e-05, 6.391012720996514e-05, 6.980951002333313e-05, 6.79628283251077e-05], lat dim 22\n",
      "Train idx = [    0     1     2 ... 29180 29181 29183] test idx = [    5    16    33 ... 29172 29179 29182]\n",
      "training set size=(23347, 80, 1, 1)\n",
      "test set size=(5837, 80, 1, 1)\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 23)                36823     \n",
      "=================================================================\n",
      "Total params: 43,703\n",
      "Trainable params: 43,383\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 23)]              0         \n",
      "_________________________________________________________________\n",
      "dec_dense_4_reshape (Dense)  (None, 1600)              38400     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_2 (Dense)      (None, 80, 1, 20)         420       \n",
      "_________________________________________________________________\n",
      "decoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "decoder_relu_2 (ReLU)        (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_1 (Dense)      (None, 80, 1, 60)         1260      \n",
      "_________________________________________________________________\n",
      "decoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "decoder_relu_1 (ReLU)        (None, 80, 1, 60)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_0 (Dense)      (None, 80, 1, 80)         4880      \n",
      "_________________________________________________________________\n",
      "decoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "decoder_relu_0 (ReLU)        (None, 80, 1, 80)         0         \n",
      "_________________________________________________________________\n",
      "decoder_last_layer (Dense)   (None, 80, 1, 1)          81        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 80, 1, 1)          0         \n",
      "=================================================================\n",
      "Total params: 45,681\n",
      "Trainable params: 45,361\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 23)                43703     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          45681     \n",
      "=================================================================\n",
      "Total params: 89,384\n",
      "Trainable params: 88,744\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "730/730 [==============================] - 17s 24ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - accuracy: 0.0064 - val_loss: 2.9523e-04 - val_mean_squared_error: 2.9523e-04 - val_accuracy: 0.0072\n",
      "Epoch 2/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 2.0925e-04 - mean_squared_error: 2.0925e-04 - accuracy: 0.0064 - val_loss: 1.3722e-04 - val_mean_squared_error: 1.3722e-04 - val_accuracy: 0.0072\n",
      "Epoch 3/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 1.2738e-04 - mean_squared_error: 1.2738e-04 - accuracy: 0.0064 - val_loss: 1.0057e-04 - val_mean_squared_error: 1.0057e-04 - val_accuracy: 0.0072\n",
      "Epoch 4/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 1.0025e-04 - mean_squared_error: 1.0025e-04 - accuracy: 0.0064 - val_loss: 8.4741e-05 - val_mean_squared_error: 8.4741e-05 - val_accuracy: 0.0072\n",
      "Epoch 5/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 8.6755e-05 - mean_squared_error: 8.6755e-05 - accuracy: 0.0064 - val_loss: 7.8781e-05 - val_mean_squared_error: 7.8781e-05 - val_accuracy: 0.0072\n",
      "Epoch 6/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 7.9512e-05 - mean_squared_error: 7.9512e-05 - accuracy: 0.0064 - val_loss: 7.0959e-05 - val_mean_squared_error: 7.0959e-05 - val_accuracy: 0.0072\n",
      "Epoch 7/25\n",
      "730/730 [==============================] - 17s 24ms/step - loss: 7.5007e-05 - mean_squared_error: 7.5007e-05 - accuracy: 0.0064 - val_loss: 6.7471e-05 - val_mean_squared_error: 6.7471e-05 - val_accuracy: 0.0072\n",
      "Epoch 8/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 7.2162e-05 - mean_squared_error: 7.2162e-05 - accuracy: 0.0064 - val_loss: 6.5635e-05 - val_mean_squared_error: 6.5635e-05 - val_accuracy: 0.0072\n",
      "Epoch 9/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 7.0424e-05 - mean_squared_error: 7.0424e-05 - accuracy: 0.0064 - val_loss: 6.4232e-05 - val_mean_squared_error: 6.4232e-05 - val_accuracy: 0.0072\n",
      "Epoch 10/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.9979e-05 - mean_squared_error: 6.9979e-05 - accuracy: 0.0064 - val_loss: 6.3995e-05 - val_mean_squared_error: 6.3995e-05 - val_accuracy: 0.0072\n",
      "Epoch 11/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.9475e-05 - mean_squared_error: 6.9475e-05 - accuracy: 0.0064 - val_loss: 6.2787e-05 - val_mean_squared_error: 6.2787e-05 - val_accuracy: 0.0072\n",
      "Epoch 12/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.8856e-05 - mean_squared_error: 6.8856e-05 - accuracy: 0.0064 - val_loss: 6.2335e-05 - val_mean_squared_error: 6.2335e-05 - val_accuracy: 0.0072\n",
      "Epoch 13/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.8534e-05 - mean_squared_error: 6.8534e-05 - accuracy: 0.0064 - val_loss: 6.2125e-05 - val_mean_squared_error: 6.2125e-05 - val_accuracy: 0.0072\n",
      "Epoch 14/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.8281e-05 - mean_squared_error: 6.8281e-05 - accuracy: 0.0064 - val_loss: 6.1673e-05 - val_mean_squared_error: 6.1673e-05 - val_accuracy: 0.0072\n",
      "Epoch 15/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.7469e-05 - mean_squared_error: 6.7469e-05 - accuracy: 0.0064 - val_loss: 6.1728e-05 - val_mean_squared_error: 6.1728e-05 - val_accuracy: 0.0072\n",
      "Epoch 16/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.7825e-05 - mean_squared_error: 6.7825e-05 - accuracy: 0.0064 - val_loss: 6.5148e-05 - val_mean_squared_error: 6.5148e-05 - val_accuracy: 0.0072\n",
      "Epoch 17/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.7459e-05 - mean_squared_error: 6.7459e-05 - accuracy: 0.0064 - val_loss: 6.2436e-05 - val_mean_squared_error: 6.2436e-05 - val_accuracy: 0.0072\n",
      "Epoch 18/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.7427e-05 - mean_squared_error: 6.7427e-05 - accuracy: 0.0064 - val_loss: 6.2388e-05 - val_mean_squared_error: 6.2388e-05 - val_accuracy: 0.0072\n",
      "Epoch 19/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.7065e-05 - mean_squared_error: 6.7065e-05 - accuracy: 0.0064 - val_loss: 6.1288e-05 - val_mean_squared_error: 6.1288e-05 - val_accuracy: 0.0072\n",
      "Epoch 20/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.7198e-05 - mean_squared_error: 6.7198e-05 - accuracy: 0.0064 - val_loss: 6.1175e-05 - val_mean_squared_error: 6.1175e-05 - val_accuracy: 0.0072\n",
      "Epoch 21/25\n",
      "730/730 [==============================] - 17s 24ms/step - loss: 6.6785e-05 - mean_squared_error: 6.6785e-05 - accuracy: 0.0064 - val_loss: 6.1849e-05 - val_mean_squared_error: 6.1849e-05 - val_accuracy: 0.0072\n",
      "Epoch 22/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.7015e-05 - mean_squared_error: 6.7015e-05 - accuracy: 0.0064 - val_loss: 6.1371e-05 - val_mean_squared_error: 6.1371e-05 - val_accuracy: 0.0072\n",
      "Epoch 23/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.6600e-05 - mean_squared_error: 6.6600e-05 - accuracy: 0.0064 - val_loss: 6.1199e-05 - val_mean_squared_error: 6.1199e-05 - val_accuracy: 0.0072\n",
      "Epoch 24/25\n",
      "730/730 [==============================] - 17s 24ms/step - loss: 6.6765e-05 - mean_squared_error: 6.6765e-05 - accuracy: 0.0064 - val_loss: 6.1210e-05 - val_mean_squared_error: 6.1210e-05 - val_accuracy: 0.0072\n",
      "Epoch 25/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.6475e-05 - mean_squared_error: 6.6475e-05 - accuracy: 0.0064 - val_loss: 6.1092e-05 - val_mean_squared_error: 6.1092e-05 - val_accuracy: 0.0072\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 23)                43703     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          45681     \n",
      "=================================================================\n",
      "Total params: 89,384\n",
      "Trainable params: 88,744\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 23)                36823     \n",
      "=================================================================\n",
      "Total params: 43,703\n",
      "Trainable params: 43,383\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 6.3597e-05 - mean_squared_error: 6.3597e-05 - accuracy: 0.0072\n",
      "MSE results: 6.359726830851287e-05\n",
      "accuracy results: 0.007195476908236742\n",
      "metrics names ['loss', 'mean_squared_error', 'accuracy']\n",
      "fold iteration # 2  lat dim 23\n",
      "MSE (valid) [6.359726830851287e-05], lat dim 23\n",
      "Train idx = [    0     1     2 ... 29181 29182 29183] test idx = [    7    13    15 ... 29170 29173 29176]\n",
      "training set size=(23347, 80, 1, 1)\n",
      "test set size=(5837, 80, 1, 1)\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 23)                36823     \n",
      "=================================================================\n",
      "Total params: 43,703\n",
      "Trainable params: 43,383\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 23)]              0         \n",
      "_________________________________________________________________\n",
      "dec_dense_4_reshape (Dense)  (None, 1600)              38400     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_2 (Dense)      (None, 80, 1, 20)         420       \n",
      "_________________________________________________________________\n",
      "decoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "decoder_relu_2 (ReLU)        (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_1 (Dense)      (None, 80, 1, 60)         1260      \n",
      "_________________________________________________________________\n",
      "decoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "decoder_relu_1 (ReLU)        (None, 80, 1, 60)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_0 (Dense)      (None, 80, 1, 80)         4880      \n",
      "_________________________________________________________________\n",
      "decoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "decoder_relu_0 (ReLU)        (None, 80, 1, 80)         0         \n",
      "_________________________________________________________________\n",
      "decoder_last_layer (Dense)   (None, 80, 1, 1)          81        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 80, 1, 1)          0         \n",
      "=================================================================\n",
      "Total params: 45,681\n",
      "Trainable params: 45,361\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 23)                43703     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          45681     \n",
      "=================================================================\n",
      "Total params: 89,384\n",
      "Trainable params: 88,744\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "730/730 [==============================] - 17s 24ms/step - loss: 0.0081 - mean_squared_error: 0.0081 - accuracy: 0.0064 - val_loss: 2.8870e-04 - val_mean_squared_error: 2.8870e-04 - val_accuracy: 0.0074\n",
      "Epoch 2/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 1.9536e-04 - mean_squared_error: 1.9536e-04 - accuracy: 0.0064 - val_loss: 1.3517e-04 - val_mean_squared_error: 1.3517e-04 - val_accuracy: 0.0074\n",
      "Epoch 3/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 1.2438e-04 - mean_squared_error: 1.2438e-04 - accuracy: 0.0064 - val_loss: 1.0422e-04 - val_mean_squared_error: 1.0422e-04 - val_accuracy: 0.0074\n",
      "Epoch 4/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 1.0119e-04 - mean_squared_error: 1.0119e-04 - accuracy: 0.0064 - val_loss: 9.1504e-05 - val_mean_squared_error: 9.1504e-05 - val_accuracy: 0.0074\n",
      "Epoch 5/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 9.0502e-05 - mean_squared_error: 9.0502e-05 - accuracy: 0.0064 - val_loss: 8.2998e-05 - val_mean_squared_error: 8.2998e-05 - val_accuracy: 0.0074\n",
      "Epoch 6/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 8.2282e-05 - mean_squared_error: 8.2283e-05 - accuracy: 0.0064 - val_loss: 7.5192e-05 - val_mean_squared_error: 7.5192e-05 - val_accuracy: 0.0074\n",
      "Epoch 7/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 7.6589e-05 - mean_squared_error: 7.6589e-05 - accuracy: 0.0064 - val_loss: 7.2319e-05 - val_mean_squared_error: 7.2319e-05 - val_accuracy: 0.0074\n",
      "Epoch 8/25\n",
      "730/730 [==============================] - 20s 27ms/step - loss: 7.3047e-05 - mean_squared_error: 7.3047e-05 - accuracy: 0.0064 - val_loss: 6.8764e-05 - val_mean_squared_error: 6.8764e-05 - val_accuracy: 0.0074\n",
      "Epoch 9/25\n",
      "730/730 [==============================] - 18s 25ms/step - loss: 7.0989e-05 - mean_squared_error: 7.0989e-05 - accuracy: 0.0064 - val_loss: 6.8024e-05 - val_mean_squared_error: 6.8024e-05 - val_accuracy: 0.0074\n",
      "Epoch 10/25\n",
      "730/730 [==============================] - 17s 24ms/step - loss: 6.9826e-05 - mean_squared_error: 6.9826e-05 - accuracy: 0.0064 - val_loss: 6.5952e-05 - val_mean_squared_error: 6.5952e-05 - val_accuracy: 0.0074\n",
      "Epoch 11/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.8850e-05 - mean_squared_error: 6.8850e-05 - accuracy: 0.0064 - val_loss: 6.7704e-05 - val_mean_squared_error: 6.7704e-05 - val_accuracy: 0.0074\n",
      "Epoch 12/25\n",
      "730/730 [==============================] - 20s 28ms/step - loss: 6.8603e-05 - mean_squared_error: 6.8603e-05 - accuracy: 0.0064 - val_loss: 6.5343e-05 - val_mean_squared_error: 6.5343e-05 - val_accuracy: 0.0074\n",
      "Epoch 13/25\n",
      "730/730 [==============================] - 17s 24ms/step - loss: 6.8918e-05 - mean_squared_error: 6.8918e-05 - accuracy: 0.0064 - val_loss: 6.5087e-05 - val_mean_squared_error: 6.5087e-05 - val_accuracy: 0.0074\n",
      "Epoch 14/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.7728e-05 - mean_squared_error: 6.7728e-05 - accuracy: 0.0064 - val_loss: 6.4801e-05 - val_mean_squared_error: 6.4801e-05 - val_accuracy: 0.0074\n",
      "Epoch 15/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.7461e-05 - mean_squared_error: 6.7461e-05 - accuracy: 0.0064 - val_loss: 6.4780e-05 - val_mean_squared_error: 6.4780e-05 - val_accuracy: 0.0074\n",
      "Epoch 16/25\n",
      "730/730 [==============================] - 17s 24ms/step - loss: 6.6965e-05 - mean_squared_error: 6.6965e-05 - accuracy: 0.0064 - val_loss: 6.4402e-05 - val_mean_squared_error: 6.4402e-05 - val_accuracy: 0.0074\n",
      "Epoch 17/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.6635e-05 - mean_squared_error: 6.6635e-05 - accuracy: 0.0064 - val_loss: 6.4601e-05 - val_mean_squared_error: 6.4601e-05 - val_accuracy: 0.0074\n",
      "Epoch 18/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.6463e-05 - mean_squared_error: 6.6462e-05 - accuracy: 0.0064 - val_loss: 6.3899e-05 - val_mean_squared_error: 6.3899e-05 - val_accuracy: 0.0074\n",
      "Epoch 19/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.6379e-05 - mean_squared_error: 6.6378e-05 - accuracy: 0.0064 - val_loss: 6.4429e-05 - val_mean_squared_error: 6.4429e-05 - val_accuracy: 0.0074\n",
      "Epoch 20/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.6506e-05 - mean_squared_error: 6.6506e-05 - accuracy: 0.0064 - val_loss: 6.3774e-05 - val_mean_squared_error: 6.3774e-05 - val_accuracy: 0.0074\n",
      "Epoch 21/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.6398e-05 - mean_squared_error: 6.6398e-05 - accuracy: 0.0064 - val_loss: 6.4253e-05 - val_mean_squared_error: 6.4253e-05 - val_accuracy: 0.0074\n",
      "Epoch 22/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.6249e-05 - mean_squared_error: 6.6249e-05 - accuracy: 0.0064 - val_loss: 6.3747e-05 - val_mean_squared_error: 6.3747e-05 - val_accuracy: 0.0074\n",
      "Epoch 23/25\n",
      "730/730 [==============================] - 18s 25ms/step - loss: 6.6072e-05 - mean_squared_error: 6.6072e-05 - accuracy: 0.0064 - val_loss: 6.5249e-05 - val_mean_squared_error: 6.5249e-05 - val_accuracy: 0.0074\n",
      "Epoch 24/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.6065e-05 - mean_squared_error: 6.6065e-05 - accuracy: 0.0064 - val_loss: 6.3764e-05 - val_mean_squared_error: 6.3764e-05 - val_accuracy: 0.0074\n",
      "Epoch 25/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.5884e-05 - mean_squared_error: 6.5884e-05 - accuracy: 0.0064 - val_loss: 6.3603e-05 - val_mean_squared_error: 6.3603e-05 - val_accuracy: 0.0074\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 23)                43703     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          45681     \n",
      "=================================================================\n",
      "Total params: 89,384\n",
      "Trainable params: 88,744\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 23)                36823     \n",
      "=================================================================\n",
      "Total params: 43,703\n",
      "Trainable params: 43,383\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 6.6268e-05 - mean_squared_error: 6.6268e-05 - accuracy: 0.0074\n",
      "MSE results: 6.626826507272199e-05\n",
      "accuracy results: 0.007366797886788845\n",
      "metrics names ['loss', 'mean_squared_error', 'accuracy']\n",
      "fold iteration # 3  lat dim 23\n",
      "MSE (valid) [6.359726830851287e-05, 6.626826507272199e-05], lat dim 23\n",
      "Train idx = [    1     2     5 ... 29181 29182 29183] test idx = [    0     3     4 ... 29167 29175 29177]\n",
      "training set size=(23347, 80, 1, 1)\n",
      "test set size=(5837, 80, 1, 1)\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 23)                36823     \n",
      "=================================================================\n",
      "Total params: 43,703\n",
      "Trainable params: 43,383\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 23)]              0         \n",
      "_________________________________________________________________\n",
      "dec_dense_4_reshape (Dense)  (None, 1600)              38400     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_2 (Dense)      (None, 80, 1, 20)         420       \n",
      "_________________________________________________________________\n",
      "decoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "decoder_relu_2 (ReLU)        (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_1 (Dense)      (None, 80, 1, 60)         1260      \n",
      "_________________________________________________________________\n",
      "decoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "decoder_relu_1 (ReLU)        (None, 80, 1, 60)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_0 (Dense)      (None, 80, 1, 80)         4880      \n",
      "_________________________________________________________________\n",
      "decoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "decoder_relu_0 (ReLU)        (None, 80, 1, 80)         0         \n",
      "_________________________________________________________________\n",
      "decoder_last_layer (Dense)   (None, 80, 1, 1)          81        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 80, 1, 1)          0         \n",
      "=================================================================\n",
      "Total params: 45,681\n",
      "Trainable params: 45,361\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 23)                43703     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          45681     \n",
      "=================================================================\n",
      "Total params: 89,384\n",
      "Trainable params: 88,744\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "730/730 [==============================] - 18s 25ms/step - loss: 0.0093 - mean_squared_error: 0.0093 - accuracy: 0.0069 - val_loss: 2.9861e-04 - val_mean_squared_error: 2.9861e-04 - val_accuracy: 0.0055\n",
      "Epoch 2/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 2.0453e-04 - mean_squared_error: 2.0453e-04 - accuracy: 0.0069 - val_loss: 1.4864e-04 - val_mean_squared_error: 1.4864e-04 - val_accuracy: 0.0055\n",
      "Epoch 3/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 1.2766e-04 - mean_squared_error: 1.2766e-04 - accuracy: 0.0069 - val_loss: 1.1476e-04 - val_mean_squared_error: 1.1476e-04 - val_accuracy: 0.0055\n",
      "Epoch 4/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 1.0398e-04 - mean_squared_error: 1.0398e-04 - accuracy: 0.0069 - val_loss: 1.0176e-04 - val_mean_squared_error: 1.0176e-04 - val_accuracy: 0.0055\n",
      "Epoch 5/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 8.8514e-05 - mean_squared_error: 8.8514e-05 - accuracy: 0.0069 - val_loss: 8.3036e-05 - val_mean_squared_error: 8.3036e-05 - val_accuracy: 0.0055\n",
      "Epoch 6/25\n",
      "730/730 [==============================] - 16s 23ms/step - loss: 8.0987e-05 - mean_squared_error: 8.0987e-05 - accuracy: 0.0069 - val_loss: 7.5953e-05 - val_mean_squared_error: 7.5953e-05 - val_accuracy: 0.0055\n",
      "Epoch 7/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 7.6267e-05 - mean_squared_error: 7.6267e-05 - accuracy: 0.0069 - val_loss: 8.2763e-05 - val_mean_squared_error: 8.2763e-05 - val_accuracy: 0.0055\n",
      "Epoch 8/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 7.2272e-05 - mean_squared_error: 7.2272e-05 - accuracy: 0.0069 - val_loss: 7.0886e-05 - val_mean_squared_error: 7.0886e-05 - val_accuracy: 0.0055\n",
      "Epoch 9/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.0552e-05 - mean_squared_error: 7.0553e-05 - accuracy: 0.0069 - val_loss: 7.0196e-05 - val_mean_squared_error: 7.0196e-05 - val_accuracy: 0.0055\n",
      "Epoch 10/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.9390e-05 - mean_squared_error: 6.9390e-05 - accuracy: 0.0069 - val_loss: 6.8705e-05 - val_mean_squared_error: 6.8705e-05 - val_accuracy: 0.0055\n",
      "Epoch 11/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.8396e-05 - mean_squared_error: 6.8396e-05 - accuracy: 0.0069 - val_loss: 6.7415e-05 - val_mean_squared_error: 6.7415e-05 - val_accuracy: 0.0055\n",
      "Epoch 12/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 6.8230e-05 - mean_squared_error: 6.8230e-05 - accuracy: 0.0069 - val_loss: 6.7081e-05 - val_mean_squared_error: 6.7081e-05 - val_accuracy: 0.0055\n",
      "Epoch 13/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.7407e-05 - mean_squared_error: 6.7407e-05 - accuracy: 0.0069 - val_loss: 7.0198e-05 - val_mean_squared_error: 7.0198e-05 - val_accuracy: 0.0055\n",
      "Epoch 14/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.7213e-05 - mean_squared_error: 6.7213e-05 - accuracy: 0.0069 - val_loss: 6.6516e-05 - val_mean_squared_error: 6.6516e-05 - val_accuracy: 0.0055\n",
      "Epoch 15/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.6980e-05 - mean_squared_error: 6.6980e-05 - accuracy: 0.0069 - val_loss: 6.6920e-05 - val_mean_squared_error: 6.6920e-05 - val_accuracy: 0.0055\n",
      "Epoch 16/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.6533e-05 - mean_squared_error: 6.6533e-05 - accuracy: 0.0069 - val_loss: 6.6083e-05 - val_mean_squared_error: 6.6083e-05 - val_accuracy: 0.0055\n",
      "Epoch 17/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.6424e-05 - mean_squared_error: 6.6424e-05 - accuracy: 0.0069 - val_loss: 6.5774e-05 - val_mean_squared_error: 6.5774e-05 - val_accuracy: 0.0055\n",
      "Epoch 18/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.6401e-05 - mean_squared_error: 6.6401e-05 - accuracy: 0.0069 - val_loss: 6.6491e-05 - val_mean_squared_error: 6.6491e-05 - val_accuracy: 0.0055\n",
      "Epoch 19/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.6307e-05 - mean_squared_error: 6.6307e-05 - accuracy: 0.0069 - val_loss: 6.5973e-05 - val_mean_squared_error: 6.5973e-05 - val_accuracy: 0.0055\n",
      "Epoch 20/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.6152e-05 - mean_squared_error: 6.6152e-05 - accuracy: 0.0069 - val_loss: 6.5848e-05 - val_mean_squared_error: 6.5848e-05 - val_accuracy: 0.0055\n",
      "Epoch 21/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.5966e-05 - mean_squared_error: 6.5966e-05 - accuracy: 0.0069 - val_loss: 6.6771e-05 - val_mean_squared_error: 6.6771e-05 - val_accuracy: 0.0055\n",
      "Epoch 22/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.5697e-05 - mean_squared_error: 6.5697e-05 - accuracy: 0.0069 - val_loss: 6.5552e-05 - val_mean_squared_error: 6.5552e-05 - val_accuracy: 0.0055\n",
      "Epoch 23/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.5772e-05 - mean_squared_error: 6.5772e-05 - accuracy: 0.0069 - val_loss: 6.5922e-05 - val_mean_squared_error: 6.5922e-05 - val_accuracy: 0.0055\n",
      "Epoch 24/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.5671e-05 - mean_squared_error: 6.5671e-05 - accuracy: 0.0069 - val_loss: 6.5537e-05 - val_mean_squared_error: 6.5537e-05 - val_accuracy: 0.0055\n",
      "Epoch 25/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.5516e-05 - mean_squared_error: 6.5516e-05 - accuracy: 0.0069 - val_loss: 6.6196e-05 - val_mean_squared_error: 6.6196e-05 - val_accuracy: 0.0055\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 23)                43703     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          45681     \n",
      "=================================================================\n",
      "Total params: 89,384\n",
      "Trainable params: 88,744\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 23)                36823     \n",
      "=================================================================\n",
      "Total params: 43,703\n",
      "Trainable params: 43,383\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 7.0191e-05 - mean_squared_error: 7.0191e-05 - accuracy: 0.0055\n",
      "MSE results: 7.019135955488309e-05\n",
      "accuracy results: 0.0054822685196995735\n",
      "metrics names ['loss', 'mean_squared_error', 'accuracy']\n",
      "fold iteration # 4  lat dim 23\n",
      "MSE (valid) [6.359726830851287e-05, 6.626826507272199e-05, 7.019135955488309e-05], lat dim 23\n",
      "Train idx = [    0     3     4 ... 29179 29182 29183] test idx = [    1     2     8 ... 29178 29180 29181]\n",
      "training set size=(23347, 80, 1, 1)\n",
      "test set size=(5837, 80, 1, 1)\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 23)                36823     \n",
      "=================================================================\n",
      "Total params: 43,703\n",
      "Trainable params: 43,383\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 23)]              0         \n",
      "_________________________________________________________________\n",
      "dec_dense_4_reshape (Dense)  (None, 1600)              38400     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_2 (Dense)      (None, 80, 1, 20)         420       \n",
      "_________________________________________________________________\n",
      "decoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "decoder_relu_2 (ReLU)        (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_1 (Dense)      (None, 80, 1, 60)         1260      \n",
      "_________________________________________________________________\n",
      "decoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "decoder_relu_1 (ReLU)        (None, 80, 1, 60)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_0 (Dense)      (None, 80, 1, 80)         4880      \n",
      "_________________________________________________________________\n",
      "decoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "decoder_relu_0 (ReLU)        (None, 80, 1, 80)         0         \n",
      "_________________________________________________________________\n",
      "decoder_last_layer (Dense)   (None, 80, 1, 1)          81        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 80, 1, 1)          0         \n",
      "=================================================================\n",
      "Total params: 45,681\n",
      "Trainable params: 45,361\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 23)                43703     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          45681     \n",
      "=================================================================\n",
      "Total params: 89,384\n",
      "Trainable params: 88,744\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 0.0096 - mean_squared_error: 0.0096 - accuracy: 0.0069 - val_loss: 2.6968e-04 - val_mean_squared_error: 2.6968e-04 - val_accuracy: 0.0051\n",
      "Epoch 2/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 1.9708e-04 - mean_squared_error: 1.9708e-04 - accuracy: 0.0069 - val_loss: 1.4130e-04 - val_mean_squared_error: 1.4130e-04 - val_accuracy: 0.0051\n",
      "Epoch 3/25\n",
      "730/730 [==============================] - 16s 23ms/step - loss: 1.2459e-04 - mean_squared_error: 1.2459e-04 - accuracy: 0.0069 - val_loss: 1.1003e-04 - val_mean_squared_error: 1.1003e-04 - val_accuracy: 0.0051\n",
      "Epoch 4/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 1.0100e-04 - mean_squared_error: 1.0100e-04 - accuracy: 0.0069 - val_loss: 9.5017e-05 - val_mean_squared_error: 9.5017e-05 - val_accuracy: 0.0051\n",
      "Epoch 5/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 8.7929e-05 - mean_squared_error: 8.7929e-05 - accuracy: 0.0069 - val_loss: 8.3136e-05 - val_mean_squared_error: 8.3136e-05 - val_accuracy: 0.0051\n",
      "Epoch 6/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 8.0288e-05 - mean_squared_error: 8.0289e-05 - accuracy: 0.0069 - val_loss: 7.8301e-05 - val_mean_squared_error: 7.8301e-05 - val_accuracy: 0.0051\n",
      "Epoch 7/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.4712e-05 - mean_squared_error: 7.4712e-05 - accuracy: 0.0069 - val_loss: 7.2266e-05 - val_mean_squared_error: 7.2266e-05 - val_accuracy: 0.0051\n",
      "Epoch 8/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.1905e-05 - mean_squared_error: 7.1905e-05 - accuracy: 0.0069 - val_loss: 7.3312e-05 - val_mean_squared_error: 7.3312e-05 - val_accuracy: 0.0051\n",
      "Epoch 9/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.0195e-05 - mean_squared_error: 7.0195e-05 - accuracy: 0.0069 - val_loss: 7.0534e-05 - val_mean_squared_error: 7.0534e-05 - val_accuracy: 0.0051\n",
      "Epoch 10/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.9024e-05 - mean_squared_error: 6.9024e-05 - accuracy: 0.0069 - val_loss: 6.8709e-05 - val_mean_squared_error: 6.8709e-05 - val_accuracy: 0.0051\n",
      "Epoch 11/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.8233e-05 - mean_squared_error: 6.8233e-05 - accuracy: 0.0069 - val_loss: 6.8497e-05 - val_mean_squared_error: 6.8497e-05 - val_accuracy: 0.0051\n",
      "Epoch 12/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.7497e-05 - mean_squared_error: 6.7497e-05 - accuracy: 0.0069 - val_loss: 6.8117e-05 - val_mean_squared_error: 6.8117e-05 - val_accuracy: 0.0051\n",
      "Epoch 13/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.7112e-05 - mean_squared_error: 6.7112e-05 - accuracy: 0.0069 - val_loss: 6.7818e-05 - val_mean_squared_error: 6.7818e-05 - val_accuracy: 0.0051\n",
      "Epoch 14/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6653e-05 - mean_squared_error: 6.6653e-05 - accuracy: 0.0069 - val_loss: 7.2081e-05 - val_mean_squared_error: 7.2081e-05 - val_accuracy: 0.0051\n",
      "Epoch 15/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.7447e-05 - mean_squared_error: 6.7447e-05 - accuracy: 0.0069 - val_loss: 6.7711e-05 - val_mean_squared_error: 6.7711e-05 - val_accuracy: 0.0051\n",
      "Epoch 16/25\n",
      "730/730 [==============================] - 16s 23ms/step - loss: 6.6212e-05 - mean_squared_error: 6.6212e-05 - accuracy: 0.0069 - val_loss: 6.7126e-05 - val_mean_squared_error: 6.7126e-05 - val_accuracy: 0.0051\n",
      "Epoch 17/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.5961e-05 - mean_squared_error: 6.5961e-05 - accuracy: 0.0069 - val_loss: 6.7557e-05 - val_mean_squared_error: 6.7557e-05 - val_accuracy: 0.0051\n",
      "Epoch 18/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.5860e-05 - mean_squared_error: 6.5860e-05 - accuracy: 0.0069 - val_loss: 6.7506e-05 - val_mean_squared_error: 6.7506e-05 - val_accuracy: 0.0051\n",
      "Epoch 19/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.5415e-05 - mean_squared_error: 6.5415e-05 - accuracy: 0.0069 - val_loss: 6.7323e-05 - val_mean_squared_error: 6.7323e-05 - val_accuracy: 0.0051\n",
      "Epoch 20/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.5414e-05 - mean_squared_error: 6.5414e-05 - accuracy: 0.0069 - val_loss: 6.6968e-05 - val_mean_squared_error: 6.6968e-05 - val_accuracy: 0.0051\n",
      "Epoch 21/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 6.5430e-05 - mean_squared_error: 6.5430e-05 - accuracy: 0.0069 - val_loss: 6.6947e-05 - val_mean_squared_error: 6.6947e-05 - val_accuracy: 0.0051\n",
      "Epoch 22/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.5333e-05 - mean_squared_error: 6.5333e-05 - accuracy: 0.0069 - val_loss: 6.7441e-05 - val_mean_squared_error: 6.7441e-05 - val_accuracy: 0.0051\n",
      "Epoch 23/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.5133e-05 - mean_squared_error: 6.5133e-05 - accuracy: 0.0069 - val_loss: 6.6906e-05 - val_mean_squared_error: 6.6906e-05 - val_accuracy: 0.0051\n",
      "Epoch 24/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.5112e-05 - mean_squared_error: 6.5112e-05 - accuracy: 0.0069 - val_loss: 6.6612e-05 - val_mean_squared_error: 6.6612e-05 - val_accuracy: 0.0051\n",
      "Epoch 25/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.5001e-05 - mean_squared_error: 6.5001e-05 - accuracy: 0.0069 - val_loss: 6.6851e-05 - val_mean_squared_error: 6.6851e-05 - val_accuracy: 0.0051\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 23)                43703     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          45681     \n",
      "=================================================================\n",
      "Total params: 89,384\n",
      "Trainable params: 88,744\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 23)                36823     \n",
      "=================================================================\n",
      "Total params: 43,703\n",
      "Trainable params: 43,383\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 6.9673e-05 - mean_squared_error: 6.9673e-05 - accuracy: 0.0051\n",
      "MSE results: 6.967259832890704e-05\n",
      "accuracy results: 0.005139626562595367\n",
      "metrics names ['loss', 'mean_squared_error', 'accuracy']\n",
      "fold iteration # 5  lat dim 23\n",
      "MSE (valid) [6.359726830851287e-05, 6.626826507272199e-05, 7.019135955488309e-05, 6.967259832890704e-05], lat dim 23\n",
      "Train idx = [    0     1     2 ... 29180 29181 29182] test idx = [    6     9    12 ... 29168 29174 29183]\n",
      "training set size=(23348, 80, 1, 1)\n",
      "test set size=(5836, 80, 1, 1)\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 23)                36823     \n",
      "=================================================================\n",
      "Total params: 43,703\n",
      "Trainable params: 43,383\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 23)]              0         \n",
      "_________________________________________________________________\n",
      "dec_dense_4_reshape (Dense)  (None, 1600)              38400     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_2 (Dense)      (None, 80, 1, 20)         420       \n",
      "_________________________________________________________________\n",
      "decoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "decoder_relu_2 (ReLU)        (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_1 (Dense)      (None, 80, 1, 60)         1260      \n",
      "_________________________________________________________________\n",
      "decoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "decoder_relu_1 (ReLU)        (None, 80, 1, 60)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_0 (Dense)      (None, 80, 1, 80)         4880      \n",
      "_________________________________________________________________\n",
      "decoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "decoder_relu_0 (ReLU)        (None, 80, 1, 80)         0         \n",
      "_________________________________________________________________\n",
      "decoder_last_layer (Dense)   (None, 80, 1, 1)          81        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 80, 1, 1)          0         \n",
      "=================================================================\n",
      "Total params: 45,681\n",
      "Trainable params: 45,361\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 23)                43703     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          45681     \n",
      "=================================================================\n",
      "Total params: 89,384\n",
      "Trainable params: 88,744\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - accuracy: 0.0063 - val_loss: 2.8826e-04 - val_mean_squared_error: 2.8826e-04 - val_accuracy: 0.0077\n",
      "Epoch 2/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 2.0701e-04 - mean_squared_error: 2.0701e-04 - accuracy: 0.0063 - val_loss: 1.4922e-04 - val_mean_squared_error: 1.4922e-04 - val_accuracy: 0.0077\n",
      "Epoch 3/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 1.2847e-04 - mean_squared_error: 1.2847e-04 - accuracy: 0.0063 - val_loss: 1.0940e-04 - val_mean_squared_error: 1.0940e-04 - val_accuracy: 0.0077\n",
      "Epoch 4/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 1.0481e-04 - mean_squared_error: 1.0481e-04 - accuracy: 0.0063 - val_loss: 9.6654e-05 - val_mean_squared_error: 9.6654e-05 - val_accuracy: 0.0077\n",
      "Epoch 5/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 9.0234e-05 - mean_squared_error: 9.0234e-05 - accuracy: 0.0063 - val_loss: 8.5917e-05 - val_mean_squared_error: 8.5917e-05 - val_accuracy: 0.0077\n",
      "Epoch 6/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 8.2651e-05 - mean_squared_error: 8.2651e-05 - accuracy: 0.0063 - val_loss: 8.6308e-05 - val_mean_squared_error: 8.6308e-05 - val_accuracy: 0.0077\n",
      "Epoch 7/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.7283e-05 - mean_squared_error: 7.7283e-05 - accuracy: 0.0063 - val_loss: 7.4549e-05 - val_mean_squared_error: 7.4549e-05 - val_accuracy: 0.0077\n",
      "Epoch 8/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.3350e-05 - mean_squared_error: 7.3350e-05 - accuracy: 0.0063 - val_loss: 7.1624e-05 - val_mean_squared_error: 7.1624e-05 - val_accuracy: 0.0077\n",
      "Epoch 9/25\n",
      "730/730 [==============================] - 18s 24ms/step - loss: 7.1811e-05 - mean_squared_error: 7.1811e-05 - accuracy: 0.0063 - val_loss: 7.3543e-05 - val_mean_squared_error: 7.3543e-05 - val_accuracy: 0.0077\n",
      "Epoch 10/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.9594e-05 - mean_squared_error: 6.9594e-05 - accuracy: 0.0063 - val_loss: 7.0160e-05 - val_mean_squared_error: 7.0160e-05 - val_accuracy: 0.0077\n",
      "Epoch 11/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.8602e-05 - mean_squared_error: 6.8602e-05 - accuracy: 0.0063 - val_loss: 6.8607e-05 - val_mean_squared_error: 6.8607e-05 - val_accuracy: 0.0077\n",
      "Epoch 12/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.7931e-05 - mean_squared_error: 6.7931e-05 - accuracy: 0.0063 - val_loss: 6.9637e-05 - val_mean_squared_error: 6.9637e-05 - val_accuracy: 0.0077\n",
      "Epoch 13/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.7613e-05 - mean_squared_error: 6.7613e-05 - accuracy: 0.0063 - val_loss: 6.8054e-05 - val_mean_squared_error: 6.8054e-05 - val_accuracy: 0.0077\n",
      "Epoch 14/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6726e-05 - mean_squared_error: 6.6726e-05 - accuracy: 0.0063 - val_loss: 6.7491e-05 - val_mean_squared_error: 6.7491e-05 - val_accuracy: 0.0077\n",
      "Epoch 15/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6776e-05 - mean_squared_error: 6.6776e-05 - accuracy: 0.0063 - val_loss: 7.9921e-05 - val_mean_squared_error: 7.9921e-05 - val_accuracy: 0.0077\n",
      "Epoch 16/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6382e-05 - mean_squared_error: 6.6382e-05 - accuracy: 0.0063 - val_loss: 6.7284e-05 - val_mean_squared_error: 6.7284e-05 - val_accuracy: 0.0077\n",
      "Epoch 17/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6079e-05 - mean_squared_error: 6.6079e-05 - accuracy: 0.0063 - val_loss: 6.9569e-05 - val_mean_squared_error: 6.9569e-05 - val_accuracy: 0.0077\n",
      "Epoch 18/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.5948e-05 - mean_squared_error: 6.5948e-05 - accuracy: 0.0063 - val_loss: 6.7024e-05 - val_mean_squared_error: 6.7024e-05 - val_accuracy: 0.0077\n",
      "Epoch 19/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.5703e-05 - mean_squared_error: 6.5703e-05 - accuracy: 0.0063 - val_loss: 6.6962e-05 - val_mean_squared_error: 6.6962e-05 - val_accuracy: 0.0077\n",
      "Epoch 20/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.5563e-05 - mean_squared_error: 6.5563e-05 - accuracy: 0.0063 - val_loss: 6.7000e-05 - val_mean_squared_error: 6.7000e-05 - val_accuracy: 0.0077\n",
      "Epoch 21/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.5326e-05 - mean_squared_error: 6.5326e-05 - accuracy: 0.0063 - val_loss: 6.7842e-05 - val_mean_squared_error: 6.7842e-05 - val_accuracy: 0.0077\n",
      "Epoch 22/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.5395e-05 - mean_squared_error: 6.5395e-05 - accuracy: 0.0063 - val_loss: 6.6861e-05 - val_mean_squared_error: 6.6861e-05 - val_accuracy: 0.0077\n",
      "Epoch 23/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.5241e-05 - mean_squared_error: 6.5241e-05 - accuracy: 0.0063 - val_loss: 6.6523e-05 - val_mean_squared_error: 6.6523e-05 - val_accuracy: 0.0077\n",
      "Epoch 24/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.5158e-05 - mean_squared_error: 6.5158e-05 - accuracy: 0.0063 - val_loss: 6.6533e-05 - val_mean_squared_error: 6.6533e-05 - val_accuracy: 0.0077\n",
      "Epoch 25/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.4934e-05 - mean_squared_error: 6.4934e-05 - accuracy: 0.0063 - val_loss: 6.7437e-05 - val_mean_squared_error: 6.7437e-05 - val_accuracy: 0.0077\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 23)                43703     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          45681     \n",
      "=================================================================\n",
      "Total params: 89,384\n",
      "Trainable params: 88,744\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 23)                36823     \n",
      "=================================================================\n",
      "Total params: 43,703\n",
      "Trainable params: 43,383\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 7.4043e-05 - mean_squared_error: 7.4043e-05 - accuracy: 0.0077\n",
      "MSE results: 7.404282951029018e-05\n",
      "accuracy results: 0.007710760924965143\n",
      "metrics names ['loss', 'mean_squared_error', 'accuracy']\n",
      "fold iteration # 6  lat dim 23\n",
      "MSE (valid) [6.359726830851287e-05, 6.626826507272199e-05, 7.019135955488309e-05, 6.967259832890704e-05, 7.404282951029018e-05], lat dim 23\n",
      "Train idx = [    0     1     2 ... 29181 29182 29183] test idx = [    9    15    19 ... 29164 29167 29173]\n",
      "training set size=(23347, 80, 1, 1)\n",
      "test set size=(5837, 80, 1, 1)\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 24)                38424     \n",
      "=================================================================\n",
      "Total params: 45,304\n",
      "Trainable params: 44,984\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 24)]              0         \n",
      "_________________________________________________________________\n",
      "dec_dense_4_reshape (Dense)  (None, 1600)              40000     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_2 (Dense)      (None, 80, 1, 20)         420       \n",
      "_________________________________________________________________\n",
      "decoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "decoder_relu_2 (ReLU)        (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_1 (Dense)      (None, 80, 1, 60)         1260      \n",
      "_________________________________________________________________\n",
      "decoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "decoder_relu_1 (ReLU)        (None, 80, 1, 60)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_0 (Dense)      (None, 80, 1, 80)         4880      \n",
      "_________________________________________________________________\n",
      "decoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "decoder_relu_0 (ReLU)        (None, 80, 1, 80)         0         \n",
      "_________________________________________________________________\n",
      "decoder_last_layer (Dense)   (None, 80, 1, 1)          81        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 80, 1, 1)          0         \n",
      "=================================================================\n",
      "Total params: 47,281\n",
      "Trainable params: 46,961\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 24)                45304     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          47281     \n",
      "=================================================================\n",
      "Total params: 92,585\n",
      "Trainable params: 91,945\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 0.0091 - mean_squared_error: 0.0091 - accuracy: 0.0066 - val_loss: 2.8648e-04 - val_mean_squared_error: 2.8648e-04 - val_accuracy: 0.0065\n",
      "Epoch 2/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 2.0141e-04 - mean_squared_error: 2.0141e-04 - accuracy: 0.0066 - val_loss: 1.3848e-04 - val_mean_squared_error: 1.3848e-04 - val_accuracy: 0.0065\n",
      "Epoch 3/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 1.2476e-04 - mean_squared_error: 1.2476e-04 - accuracy: 0.0066 - val_loss: 1.0174e-04 - val_mean_squared_error: 1.0174e-04 - val_accuracy: 0.0065\n",
      "Epoch 4/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 9.9688e-05 - mean_squared_error: 9.9688e-05 - accuracy: 0.0066 - val_loss: 8.8427e-05 - val_mean_squared_error: 8.8427e-05 - val_accuracy: 0.0065\n",
      "Epoch 5/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 8.7437e-05 - mean_squared_error: 8.7437e-05 - accuracy: 0.0066 - val_loss: 7.9914e-05 - val_mean_squared_error: 7.9914e-05 - val_accuracy: 0.0065\n",
      "Epoch 6/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 7.9253e-05 - mean_squared_error: 7.9253e-05 - accuracy: 0.0066 - val_loss: 7.2635e-05 - val_mean_squared_error: 7.2635e-05 - val_accuracy: 0.0065\n",
      "Epoch 7/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 7.5526e-05 - mean_squared_error: 7.5526e-05 - accuracy: 0.0066 - val_loss: 6.9954e-05 - val_mean_squared_error: 6.9954e-05 - val_accuracy: 0.0065\n",
      "Epoch 8/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.2317e-05 - mean_squared_error: 7.2317e-05 - accuracy: 0.0066 - val_loss: 6.7447e-05 - val_mean_squared_error: 6.7447e-05 - val_accuracy: 0.0065\n",
      "Epoch 9/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.0405e-05 - mean_squared_error: 7.0405e-05 - accuracy: 0.0066 - val_loss: 6.6277e-05 - val_mean_squared_error: 6.6277e-05 - val_accuracy: 0.0065\n",
      "Epoch 10/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 6.9596e-05 - mean_squared_error: 6.9596e-05 - accuracy: 0.0066 - val_loss: 6.5098e-05 - val_mean_squared_error: 6.5098e-05 - val_accuracy: 0.0065\n",
      "Epoch 11/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.9080e-05 - mean_squared_error: 6.9080e-05 - accuracy: 0.0066 - val_loss: 6.6381e-05 - val_mean_squared_error: 6.6381e-05 - val_accuracy: 0.0065\n",
      "Epoch 12/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.8548e-05 - mean_squared_error: 6.8548e-05 - accuracy: 0.0066 - val_loss: 6.4906e-05 - val_mean_squared_error: 6.4906e-05 - val_accuracy: 0.0065\n",
      "Epoch 13/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.8748e-05 - mean_squared_error: 6.8748e-05 - accuracy: 0.0066 - val_loss: 6.5388e-05 - val_mean_squared_error: 6.5388e-05 - val_accuracy: 0.0065\n",
      "Epoch 14/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.7309e-05 - mean_squared_error: 6.7309e-05 - accuracy: 0.0066 - val_loss: 6.3617e-05 - val_mean_squared_error: 6.3617e-05 - val_accuracy: 0.0065\n",
      "Epoch 15/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 6.6920e-05 - mean_squared_error: 6.6920e-05 - accuracy: 0.0066 - val_loss: 6.3926e-05 - val_mean_squared_error: 6.3926e-05 - val_accuracy: 0.0065\n",
      "Epoch 16/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 6.7034e-05 - mean_squared_error: 6.7034e-05 - accuracy: 0.0066 - val_loss: 6.3929e-05 - val_mean_squared_error: 6.3929e-05 - val_accuracy: 0.0065\n",
      "Epoch 17/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.6874e-05 - mean_squared_error: 6.6874e-05 - accuracy: 0.0066 - val_loss: 6.3850e-05 - val_mean_squared_error: 6.3850e-05 - val_accuracy: 0.0065\n",
      "Epoch 18/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.6668e-05 - mean_squared_error: 6.6668e-05 - accuracy: 0.0066 - val_loss: 6.4161e-05 - val_mean_squared_error: 6.4161e-05 - val_accuracy: 0.0065\n",
      "Epoch 19/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.6661e-05 - mean_squared_error: 6.6661e-05 - accuracy: 0.0066 - val_loss: 6.3460e-05 - val_mean_squared_error: 6.3460e-05 - val_accuracy: 0.0065\n",
      "Epoch 20/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.6219e-05 - mean_squared_error: 6.6219e-05 - accuracy: 0.0066 - val_loss: 6.3213e-05 - val_mean_squared_error: 6.3213e-05 - val_accuracy: 0.0065\n",
      "Epoch 21/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 6.6103e-05 - mean_squared_error: 6.6103e-05 - accuracy: 0.0066 - val_loss: 6.3579e-05 - val_mean_squared_error: 6.3579e-05 - val_accuracy: 0.0065\n",
      "Epoch 22/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.6773e-05 - mean_squared_error: 6.6773e-05 - accuracy: 0.0066 - val_loss: 6.3594e-05 - val_mean_squared_error: 6.3594e-05 - val_accuracy: 0.0065\n",
      "Epoch 23/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.6017e-05 - mean_squared_error: 6.6017e-05 - accuracy: 0.0066 - val_loss: 6.4260e-05 - val_mean_squared_error: 6.4260e-05 - val_accuracy: 0.0065\n",
      "Epoch 24/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.6226e-05 - mean_squared_error: 6.6226e-05 - accuracy: 0.0066 - val_loss: 6.3484e-05 - val_mean_squared_error: 6.3484e-05 - val_accuracy: 0.0065\n",
      "Epoch 25/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.5854e-05 - mean_squared_error: 6.5854e-05 - accuracy: 0.0066 - val_loss: 6.3527e-05 - val_mean_squared_error: 6.3527e-05 - val_accuracy: 0.0065\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 24)                45304     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          47281     \n",
      "=================================================================\n",
      "Total params: 92,585\n",
      "Trainable params: 91,945\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 24)                38424     \n",
      "=================================================================\n",
      "Total params: 45,304\n",
      "Trainable params: 44,984\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 6.7585e-05 - mean_squared_error: 6.7585e-05 - accuracy: 0.0065\n",
      "MSE results: 6.758503150194883e-05\n",
      "accuracy results: 0.006510193459689617\n",
      "metrics names ['loss', 'mean_squared_error', 'accuracy']\n",
      "fold iteration # 2  lat dim 24\n",
      "MSE (valid) [6.758503150194883e-05], lat dim 24\n",
      "Train idx = [    1     2     3 ... 29179 29180 29182] test idx = [    0     5    10 ... 29169 29181 29183]\n",
      "training set size=(23347, 80, 1, 1)\n",
      "test set size=(5837, 80, 1, 1)\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 24)                38424     \n",
      "=================================================================\n",
      "Total params: 45,304\n",
      "Trainable params: 44,984\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 24)]              0         \n",
      "_________________________________________________________________\n",
      "dec_dense_4_reshape (Dense)  (None, 1600)              40000     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_2 (Dense)      (None, 80, 1, 20)         420       \n",
      "_________________________________________________________________\n",
      "decoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "decoder_relu_2 (ReLU)        (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_1 (Dense)      (None, 80, 1, 60)         1260      \n",
      "_________________________________________________________________\n",
      "decoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "decoder_relu_1 (ReLU)        (None, 80, 1, 60)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_0 (Dense)      (None, 80, 1, 80)         4880      \n",
      "_________________________________________________________________\n",
      "decoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "decoder_relu_0 (ReLU)        (None, 80, 1, 80)         0         \n",
      "_________________________________________________________________\n",
      "decoder_last_layer (Dense)   (None, 80, 1, 1)          81        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 80, 1, 1)          0         \n",
      "=================================================================\n",
      "Total params: 47,281\n",
      "Trainable params: 46,961\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 24)                45304     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          47281     \n",
      "=================================================================\n",
      "Total params: 92,585\n",
      "Trainable params: 91,945\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "730/730 [==============================] - 17s 24ms/step - loss: 0.0113 - mean_squared_error: 0.0113 - accuracy: 0.0066 - val_loss: 3.1611e-04 - val_mean_squared_error: 3.1611e-04 - val_accuracy: 0.0065\n",
      "Epoch 2/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 2.1401e-04 - mean_squared_error: 2.1401e-04 - accuracy: 0.0066 - val_loss: 1.4578e-04 - val_mean_squared_error: 1.4578e-04 - val_accuracy: 0.0065\n",
      "Epoch 3/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 1.3119e-04 - mean_squared_error: 1.3119e-04 - accuracy: 0.0066 - val_loss: 1.1079e-04 - val_mean_squared_error: 1.1079e-04 - val_accuracy: 0.0065\n",
      "Epoch 4/25\n",
      "730/730 [==============================] - 18s 24ms/step - loss: 1.0424e-04 - mean_squared_error: 1.0424e-04 - accuracy: 0.0066 - val_loss: 9.5812e-05 - val_mean_squared_error: 9.5812e-05 - val_accuracy: 0.0065\n",
      "Epoch 5/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 8.9724e-05 - mean_squared_error: 8.9724e-05 - accuracy: 0.0066 - val_loss: 8.6134e-05 - val_mean_squared_error: 8.6134e-05 - val_accuracy: 0.0065\n",
      "Epoch 6/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 8.1600e-05 - mean_squared_error: 8.1600e-05 - accuracy: 0.0066 - val_loss: 7.9098e-05 - val_mean_squared_error: 7.9098e-05 - val_accuracy: 0.0065\n",
      "Epoch 7/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.6964e-05 - mean_squared_error: 7.6964e-05 - accuracy: 0.0066 - val_loss: 7.6163e-05 - val_mean_squared_error: 7.6163e-05 - val_accuracy: 0.0065\n",
      "Epoch 8/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.2958e-05 - mean_squared_error: 7.2958e-05 - accuracy: 0.0066 - val_loss: 7.1823e-05 - val_mean_squared_error: 7.1823e-05 - val_accuracy: 0.0065\n",
      "Epoch 9/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.0847e-05 - mean_squared_error: 7.0847e-05 - accuracy: 0.0066 - val_loss: 6.9975e-05 - val_mean_squared_error: 6.9975e-05 - val_accuracy: 0.0065\n",
      "Epoch 10/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.9551e-05 - mean_squared_error: 6.9551e-05 - accuracy: 0.0066 - val_loss: 6.8734e-05 - val_mean_squared_error: 6.8734e-05 - val_accuracy: 0.0065\n",
      "Epoch 11/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.8410e-05 - mean_squared_error: 6.8410e-05 - accuracy: 0.0066 - val_loss: 7.0474e-05 - val_mean_squared_error: 7.0474e-05 - val_accuracy: 0.0065\n",
      "Epoch 12/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.7971e-05 - mean_squared_error: 6.7971e-05 - accuracy: 0.0066 - val_loss: 6.9819e-05 - val_mean_squared_error: 6.9819e-05 - val_accuracy: 0.0065\n",
      "Epoch 13/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6738e-05 - mean_squared_error: 6.6738e-05 - accuracy: 0.0066 - val_loss: 6.8869e-05 - val_mean_squared_error: 6.8869e-05 - val_accuracy: 0.0065\n",
      "Epoch 14/25\n",
      "730/730 [==============================] - 16s 23ms/step - loss: 6.6494e-05 - mean_squared_error: 6.6494e-05 - accuracy: 0.0066 - val_loss: 6.7310e-05 - val_mean_squared_error: 6.7310e-05 - val_accuracy: 0.0065\n",
      "Epoch 15/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6091e-05 - mean_squared_error: 6.6091e-05 - accuracy: 0.0066 - val_loss: 6.7324e-05 - val_mean_squared_error: 6.7324e-05 - val_accuracy: 0.0065\n",
      "Epoch 16/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.5785e-05 - mean_squared_error: 6.5785e-05 - accuracy: 0.0066 - val_loss: 6.7269e-05 - val_mean_squared_error: 6.7269e-05 - val_accuracy: 0.0065\n",
      "Epoch 17/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.5553e-05 - mean_squared_error: 6.5553e-05 - accuracy: 0.0066 - val_loss: 6.7016e-05 - val_mean_squared_error: 6.7016e-05 - val_accuracy: 0.0065\n",
      "Epoch 18/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.5453e-05 - mean_squared_error: 6.5453e-05 - accuracy: 0.0066 - val_loss: 6.7935e-05 - val_mean_squared_error: 6.7935e-05 - val_accuracy: 0.0065\n",
      "Epoch 19/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.5568e-05 - mean_squared_error: 6.5568e-05 - accuracy: 0.0066 - val_loss: 6.8788e-05 - val_mean_squared_error: 6.8788e-05 - val_accuracy: 0.0065\n",
      "Epoch 20/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.5395e-05 - mean_squared_error: 6.5395e-05 - accuracy: 0.0066 - val_loss: 6.8279e-05 - val_mean_squared_error: 6.8279e-05 - val_accuracy: 0.0065\n",
      "Epoch 21/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.5154e-05 - mean_squared_error: 6.5154e-05 - accuracy: 0.0066 - val_loss: 6.6278e-05 - val_mean_squared_error: 6.6278e-05 - val_accuracy: 0.0065\n",
      "Epoch 22/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.4886e-05 - mean_squared_error: 6.4886e-05 - accuracy: 0.0066 - val_loss: 6.6257e-05 - val_mean_squared_error: 6.6257e-05 - val_accuracy: 0.0065\n",
      "Epoch 23/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.4958e-05 - mean_squared_error: 6.4958e-05 - accuracy: 0.0066 - val_loss: 6.7845e-05 - val_mean_squared_error: 6.7845e-05 - val_accuracy: 0.0065\n",
      "Epoch 24/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.5018e-05 - mean_squared_error: 6.5018e-05 - accuracy: 0.0066 - val_loss: 6.6034e-05 - val_mean_squared_error: 6.6034e-05 - val_accuracy: 0.0065\n",
      "Epoch 25/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.4702e-05 - mean_squared_error: 6.4703e-05 - accuracy: 0.0066 - val_loss: 6.7021e-05 - val_mean_squared_error: 6.7021e-05 - val_accuracy: 0.0065\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 24)                45304     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          47281     \n",
      "=================================================================\n",
      "Total params: 92,585\n",
      "Trainable params: 91,945\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 24)                38424     \n",
      "=================================================================\n",
      "Total params: 45,304\n",
      "Trainable params: 44,984\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 7.2933e-05 - mean_squared_error: 7.2933e-05 - accuracy: 0.0065\n",
      "MSE results: 7.293307862710208e-05\n",
      "accuracy results: 0.006510193459689617\n",
      "metrics names ['loss', 'mean_squared_error', 'accuracy']\n",
      "fold iteration # 3  lat dim 24\n",
      "MSE (valid) [6.758503150194883e-05, 7.293307862710208e-05], lat dim 24\n",
      "Train idx = [    0     2     4 ... 29180 29181 29183] test idx = [    1     3     6 ... 29174 29176 29182]\n",
      "training set size=(23347, 80, 1, 1)\n",
      "test set size=(5837, 80, 1, 1)\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 24)                38424     \n",
      "=================================================================\n",
      "Total params: 45,304\n",
      "Trainable params: 44,984\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 24)]              0         \n",
      "_________________________________________________________________\n",
      "dec_dense_4_reshape (Dense)  (None, 1600)              40000     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_2 (Dense)      (None, 80, 1, 20)         420       \n",
      "_________________________________________________________________\n",
      "decoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "decoder_relu_2 (ReLU)        (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_1 (Dense)      (None, 80, 1, 60)         1260      \n",
      "_________________________________________________________________\n",
      "decoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "decoder_relu_1 (ReLU)        (None, 80, 1, 60)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_0 (Dense)      (None, 80, 1, 80)         4880      \n",
      "_________________________________________________________________\n",
      "decoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "decoder_relu_0 (ReLU)        (None, 80, 1, 80)         0         \n",
      "_________________________________________________________________\n",
      "decoder_last_layer (Dense)   (None, 80, 1, 1)          81        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 80, 1, 1)          0         \n",
      "=================================================================\n",
      "Total params: 47,281\n",
      "Trainable params: 46,961\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 24)                45304     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          47281     \n",
      "=================================================================\n",
      "Total params: 92,585\n",
      "Trainable params: 91,945\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "730/730 [==============================] - 16s 23ms/step - loss: 0.0129 - mean_squared_error: 0.0129 - accuracy: 0.0066 - val_loss: 3.3033e-04 - val_mean_squared_error: 3.3033e-04 - val_accuracy: 0.0062\n",
      "Epoch 2/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 2.2003e-04 - mean_squared_error: 2.2003e-04 - accuracy: 0.0067 - val_loss: 1.4209e-04 - val_mean_squared_error: 1.4209e-04 - val_accuracy: 0.0062\n",
      "Epoch 3/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 1.3120e-04 - mean_squared_error: 1.3120e-04 - accuracy: 0.0067 - val_loss: 1.1117e-04 - val_mean_squared_error: 1.1117e-04 - val_accuracy: 0.0062\n",
      "Epoch 4/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 1.0500e-04 - mean_squared_error: 1.0500e-04 - accuracy: 0.0067 - val_loss: 9.1364e-05 - val_mean_squared_error: 9.1364e-05 - val_accuracy: 0.0062\n",
      "Epoch 5/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 9.1732e-05 - mean_squared_error: 9.1732e-05 - accuracy: 0.0067 - val_loss: 8.2031e-05 - val_mean_squared_error: 8.2031e-05 - val_accuracy: 0.0062\n",
      "Epoch 6/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 8.3957e-05 - mean_squared_error: 8.3957e-05 - accuracy: 0.0067 - val_loss: 7.6327e-05 - val_mean_squared_error: 7.6327e-05 - val_accuracy: 0.0062\n",
      "Epoch 7/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.9884e-05 - mean_squared_error: 7.9884e-05 - accuracy: 0.0067 - val_loss: 7.6051e-05 - val_mean_squared_error: 7.6051e-05 - val_accuracy: 0.0062\n",
      "Epoch 8/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 7.6660e-05 - mean_squared_error: 7.6660e-05 - accuracy: 0.0067 - val_loss: 7.3851e-05 - val_mean_squared_error: 7.3851e-05 - val_accuracy: 0.0062\n",
      "Epoch 9/25\n",
      "730/730 [==============================] - 19s 26ms/step - loss: 7.2584e-05 - mean_squared_error: 7.2584e-05 - accuracy: 0.0067 - val_loss: 6.7200e-05 - val_mean_squared_error: 6.7200e-05 - val_accuracy: 0.0062\n",
      "Epoch 10/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.1231e-05 - mean_squared_error: 7.1231e-05 - accuracy: 0.0067 - val_loss: 6.5769e-05 - val_mean_squared_error: 6.5769e-05 - val_accuracy: 0.0062\n",
      "Epoch 11/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.0519e-05 - mean_squared_error: 7.0519e-05 - accuracy: 0.0067 - val_loss: 6.4886e-05 - val_mean_squared_error: 6.4886e-05 - val_accuracy: 0.0062\n",
      "Epoch 12/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.9796e-05 - mean_squared_error: 6.9796e-05 - accuracy: 0.0067 - val_loss: 6.3846e-05 - val_mean_squared_error: 6.3846e-05 - val_accuracy: 0.0062\n",
      "Epoch 13/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.8547e-05 - mean_squared_error: 6.8547e-05 - accuracy: 0.0067 - val_loss: 6.3820e-05 - val_mean_squared_error: 6.3820e-05 - val_accuracy: 0.0062\n",
      "Epoch 14/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.8535e-05 - mean_squared_error: 6.8535e-05 - accuracy: 0.0067 - val_loss: 6.5098e-05 - val_mean_squared_error: 6.5098e-05 - val_accuracy: 0.0062\n",
      "Epoch 15/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.7622e-05 - mean_squared_error: 6.7622e-05 - accuracy: 0.0067 - val_loss: 6.3520e-05 - val_mean_squared_error: 6.3520e-05 - val_accuracy: 0.0062\n",
      "Epoch 16/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.7264e-05 - mean_squared_error: 6.7264e-05 - accuracy: 0.0067 - val_loss: 6.3000e-05 - val_mean_squared_error: 6.3000e-05 - val_accuracy: 0.0062\n",
      "Epoch 17/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6725e-05 - mean_squared_error: 6.6725e-05 - accuracy: 0.0067 - val_loss: 6.2570e-05 - val_mean_squared_error: 6.2570e-05 - val_accuracy: 0.0062\n",
      "Epoch 18/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6659e-05 - mean_squared_error: 6.6659e-05 - accuracy: 0.0067 - val_loss: 6.2815e-05 - val_mean_squared_error: 6.2815e-05 - val_accuracy: 0.0062\n",
      "Epoch 19/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6364e-05 - mean_squared_error: 6.6364e-05 - accuracy: 0.0067 - val_loss: 6.2629e-05 - val_mean_squared_error: 6.2629e-05 - val_accuracy: 0.0062\n",
      "Epoch 20/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6579e-05 - mean_squared_error: 6.6579e-05 - accuracy: 0.0067 - val_loss: 6.2690e-05 - val_mean_squared_error: 6.2690e-05 - val_accuracy: 0.0062\n",
      "Epoch 21/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6330e-05 - mean_squared_error: 6.6330e-05 - accuracy: 0.0067 - val_loss: 6.4009e-05 - val_mean_squared_error: 6.4009e-05 - val_accuracy: 0.0062\n",
      "Epoch 22/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6108e-05 - mean_squared_error: 6.6108e-05 - accuracy: 0.0067 - val_loss: 6.2825e-05 - val_mean_squared_error: 6.2825e-05 - val_accuracy: 0.0062\n",
      "Epoch 23/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.6148e-05 - mean_squared_error: 6.6148e-05 - accuracy: 0.0067 - val_loss: 6.2470e-05 - val_mean_squared_error: 6.2470e-05 - val_accuracy: 0.0062\n",
      "Epoch 24/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 6.6136e-05 - mean_squared_error: 6.6136e-05 - accuracy: 0.0067 - val_loss: 6.2297e-05 - val_mean_squared_error: 6.2297e-05 - val_accuracy: 0.0062\n",
      "Epoch 25/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.5767e-05 - mean_squared_error: 6.5767e-05 - accuracy: 0.0067 - val_loss: 6.5375e-05 - val_mean_squared_error: 6.5375e-05 - val_accuracy: 0.0062\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 24)                45304     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          47281     \n",
      "=================================================================\n",
      "Total params: 92,585\n",
      "Trainable params: 91,945\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 24)                38424     \n",
      "=================================================================\n",
      "Total params: 45,304\n",
      "Trainable params: 44,984\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 7.4203e-05 - mean_squared_error: 7.4203e-05 - accuracy: 0.0062\n",
      "MSE results: 7.42026386433281e-05\n",
      "accuracy results: 0.006167551968246698\n",
      "metrics names ['loss', 'mean_squared_error', 'accuracy']\n",
      "fold iteration # 4  lat dim 24\n",
      "MSE (valid) [6.758503150194883e-05, 7.293307862710208e-05, 7.42026386433281e-05], lat dim 24\n",
      "Train idx = [    0     1     3 ... 29181 29182 29183] test idx = [    2     8    17 ... 29170 29171 29180]\n",
      "training set size=(23347, 80, 1, 1)\n",
      "test set size=(5837, 80, 1, 1)\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 24)                38424     \n",
      "=================================================================\n",
      "Total params: 45,304\n",
      "Trainable params: 44,984\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 24)]              0         \n",
      "_________________________________________________________________\n",
      "dec_dense_4_reshape (Dense)  (None, 1600)              40000     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_2 (Dense)      (None, 80, 1, 20)         420       \n",
      "_________________________________________________________________\n",
      "decoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "decoder_relu_2 (ReLU)        (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_1 (Dense)      (None, 80, 1, 60)         1260      \n",
      "_________________________________________________________________\n",
      "decoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "decoder_relu_1 (ReLU)        (None, 80, 1, 60)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_0 (Dense)      (None, 80, 1, 80)         4880      \n",
      "_________________________________________________________________\n",
      "decoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "decoder_relu_0 (ReLU)        (None, 80, 1, 80)         0         \n",
      "_________________________________________________________________\n",
      "decoder_last_layer (Dense)   (None, 80, 1, 1)          81        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 80, 1, 1)          0         \n",
      "=================================================================\n",
      "Total params: 47,281\n",
      "Trainable params: 46,961\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 24)                45304     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          47281     \n",
      "=================================================================\n",
      "Total params: 92,585\n",
      "Trainable params: 91,945\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 0.0086 - mean_squared_error: 0.0086 - accuracy: 0.0067 - val_loss: 2.8256e-04 - val_mean_squared_error: 2.8256e-04 - val_accuracy: 0.0060\n",
      "Epoch 2/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 1.9154e-04 - mean_squared_error: 1.9154e-04 - accuracy: 0.0067 - val_loss: 1.3812e-04 - val_mean_squared_error: 1.3812e-04 - val_accuracy: 0.0060\n",
      "Epoch 3/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 1.2308e-04 - mean_squared_error: 1.2308e-04 - accuracy: 0.0067 - val_loss: 1.0670e-04 - val_mean_squared_error: 1.0670e-04 - val_accuracy: 0.0060\n",
      "Epoch 4/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 1.0023e-04 - mean_squared_error: 1.0023e-04 - accuracy: 0.0067 - val_loss: 9.4501e-05 - val_mean_squared_error: 9.4501e-05 - val_accuracy: 0.0060\n",
      "Epoch 5/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 8.8400e-05 - mean_squared_error: 8.8400e-05 - accuracy: 0.0067 - val_loss: 8.6124e-05 - val_mean_squared_error: 8.6124e-05 - val_accuracy: 0.0060\n",
      "Epoch 6/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 8.1439e-05 - mean_squared_error: 8.1438e-05 - accuracy: 0.0067 - val_loss: 8.2061e-05 - val_mean_squared_error: 8.2061e-05 - val_accuracy: 0.0060\n",
      "Epoch 7/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 7.5838e-05 - mean_squared_error: 7.5838e-05 - accuracy: 0.0067 - val_loss: 7.3306e-05 - val_mean_squared_error: 7.3306e-05 - val_accuracy: 0.0060\n",
      "Epoch 8/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 7.2857e-05 - mean_squared_error: 7.2857e-05 - accuracy: 0.0067 - val_loss: 7.2862e-05 - val_mean_squared_error: 7.2862e-05 - val_accuracy: 0.0060\n",
      "Epoch 9/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 7.0525e-05 - mean_squared_error: 7.0525e-05 - accuracy: 0.0067 - val_loss: 7.0191e-05 - val_mean_squared_error: 7.0191e-05 - val_accuracy: 0.0060\n",
      "Epoch 10/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.8911e-05 - mean_squared_error: 6.8911e-05 - accuracy: 0.0067 - val_loss: 6.9016e-05 - val_mean_squared_error: 6.9016e-05 - val_accuracy: 0.0060\n",
      "Epoch 11/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.7872e-05 - mean_squared_error: 6.7872e-05 - accuracy: 0.0067 - val_loss: 6.8810e-05 - val_mean_squared_error: 6.8810e-05 - val_accuracy: 0.0060\n",
      "Epoch 12/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.6995e-05 - mean_squared_error: 6.6995e-05 - accuracy: 0.0067 - val_loss: 6.7954e-05 - val_mean_squared_error: 6.7954e-05 - val_accuracy: 0.0060\n",
      "Epoch 13/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.6442e-05 - mean_squared_error: 6.6442e-05 - accuracy: 0.0067 - val_loss: 6.8109e-05 - val_mean_squared_error: 6.8109e-05 - val_accuracy: 0.0060\n",
      "Epoch 14/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 6.6446e-05 - mean_squared_error: 6.6446e-05 - accuracy: 0.0067 - val_loss: 6.7723e-05 - val_mean_squared_error: 6.7723e-05 - val_accuracy: 0.0060\n",
      "Epoch 15/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.5989e-05 - mean_squared_error: 6.5989e-05 - accuracy: 0.0067 - val_loss: 6.7310e-05 - val_mean_squared_error: 6.7310e-05 - val_accuracy: 0.0060\n",
      "Epoch 16/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.5913e-05 - mean_squared_error: 6.5913e-05 - accuracy: 0.0067 - val_loss: 6.8309e-05 - val_mean_squared_error: 6.8309e-05 - val_accuracy: 0.0060\n",
      "Epoch 17/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.5704e-05 - mean_squared_error: 6.5704e-05 - accuracy: 0.0067 - val_loss: 6.7130e-05 - val_mean_squared_error: 6.7130e-05 - val_accuracy: 0.0060\n",
      "Epoch 18/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.5559e-05 - mean_squared_error: 6.5559e-05 - accuracy: 0.0067 - val_loss: 6.7323e-05 - val_mean_squared_error: 6.7323e-05 - val_accuracy: 0.0060\n",
      "Epoch 19/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.5355e-05 - mean_squared_error: 6.5355e-05 - accuracy: 0.0067 - val_loss: 6.7050e-05 - val_mean_squared_error: 6.7050e-05 - val_accuracy: 0.0060\n",
      "Epoch 20/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.5325e-05 - mean_squared_error: 6.5325e-05 - accuracy: 0.0067 - val_loss: 6.8471e-05 - val_mean_squared_error: 6.8471e-05 - val_accuracy: 0.0060\n",
      "Epoch 21/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.5025e-05 - mean_squared_error: 6.5025e-05 - accuracy: 0.0067 - val_loss: 6.7034e-05 - val_mean_squared_error: 6.7034e-05 - val_accuracy: 0.0060\n",
      "Epoch 22/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 6.5137e-05 - mean_squared_error: 6.5137e-05 - accuracy: 0.0067 - val_loss: 6.7147e-05 - val_mean_squared_error: 6.7147e-05 - val_accuracy: 0.0060\n",
      "Epoch 23/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.4989e-05 - mean_squared_error: 6.4989e-05 - accuracy: 0.0067 - val_loss: 6.6945e-05 - val_mean_squared_error: 6.6945e-05 - val_accuracy: 0.0060\n",
      "Epoch 24/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.5003e-05 - mean_squared_error: 6.5003e-05 - accuracy: 0.0067 - val_loss: 6.6995e-05 - val_mean_squared_error: 6.6995e-05 - val_accuracy: 0.0060\n",
      "Epoch 25/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.4749e-05 - mean_squared_error: 6.4749e-05 - accuracy: 0.0067 - val_loss: 6.6803e-05 - val_mean_squared_error: 6.6803e-05 - val_accuracy: 0.0060\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 24)                45304     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          47281     \n",
      "=================================================================\n",
      "Total params: 92,585\n",
      "Trainable params: 91,945\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 24)                38424     \n",
      "=================================================================\n",
      "Total params: 45,304\n",
      "Trainable params: 44,984\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 6.9200e-05 - mean_squared_error: 6.9200e-05 - accuracy: 0.0060\n",
      "MSE results: 6.920043961144984e-05\n",
      "accuracy results: 0.005996230989694595\n",
      "metrics names ['loss', 'mean_squared_error', 'accuracy']\n",
      "fold iteration # 5  lat dim 24\n",
      "MSE (valid) [6.758503150194883e-05, 7.293307862710208e-05, 7.42026386433281e-05, 6.920043961144984e-05], lat dim 24\n",
      "Train idx = [    0     1     2 ... 29181 29182 29183] test idx = [    4     7    13 ... 29177 29178 29179]\n",
      "training set size=(23348, 80, 1, 1)\n",
      "test set size=(5836, 80, 1, 1)\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 24)                38424     \n",
      "=================================================================\n",
      "Total params: 45,304\n",
      "Trainable params: 44,984\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 24)]              0         \n",
      "_________________________________________________________________\n",
      "dec_dense_4_reshape (Dense)  (None, 1600)              40000     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_2 (Dense)      (None, 80, 1, 20)         420       \n",
      "_________________________________________________________________\n",
      "decoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "decoder_relu_2 (ReLU)        (None, 80, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_1 (Dense)      (None, 80, 1, 60)         1260      \n",
      "_________________________________________________________________\n",
      "decoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "decoder_relu_1 (ReLU)        (None, 80, 1, 60)         0         \n",
      "_________________________________________________________________\n",
      "decoder_layer_0 (Dense)      (None, 80, 1, 80)         4880      \n",
      "_________________________________________________________________\n",
      "decoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "decoder_relu_0 (ReLU)        (None, 80, 1, 80)         0         \n",
      "_________________________________________________________________\n",
      "decoder_last_layer (Dense)   (None, 80, 1, 1)          81        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 80, 1, 1)          0         \n",
      "=================================================================\n",
      "Total params: 47,281\n",
      "Trainable params: 46,961\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 24)                45304     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          47281     \n",
      "=================================================================\n",
      "Total params: 92,585\n",
      "Trainable params: 91,945\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "730/730 [==============================] - 17s 23ms/step - loss: 0.0093 - mean_squared_error: 0.0093 - accuracy: 0.0063 - val_loss: 2.7498e-04 - val_mean_squared_error: 2.7498e-04 - val_accuracy: 0.0077\n",
      "Epoch 2/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 2.0118e-04 - mean_squared_error: 2.0118e-04 - accuracy: 0.0063 - val_loss: 1.4320e-04 - val_mean_squared_error: 1.4320e-04 - val_accuracy: 0.0077\n",
      "Epoch 3/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 1.2452e-04 - mean_squared_error: 1.2452e-04 - accuracy: 0.0063 - val_loss: 1.0737e-04 - val_mean_squared_error: 1.0737e-04 - val_accuracy: 0.0077\n",
      "Epoch 4/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 9.9677e-05 - mean_squared_error: 9.9676e-05 - accuracy: 0.0063 - val_loss: 9.0773e-05 - val_mean_squared_error: 9.0773e-05 - val_accuracy: 0.0077\n",
      "Epoch 5/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 8.7821e-05 - mean_squared_error: 8.7821e-05 - accuracy: 0.0063 - val_loss: 8.1735e-05 - val_mean_squared_error: 8.1735e-05 - val_accuracy: 0.0077\n",
      "Epoch 6/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 8.1328e-05 - mean_squared_error: 8.1328e-05 - accuracy: 0.0063 - val_loss: 7.5045e-05 - val_mean_squared_error: 7.5045e-05 - val_accuracy: 0.0077\n",
      "Epoch 7/25\n",
      "730/730 [==============================] - 19s 26ms/step - loss: 7.6319e-05 - mean_squared_error: 7.6319e-05 - accuracy: 0.0063 - val_loss: 7.1488e-05 - val_mean_squared_error: 7.1488e-05 - val_accuracy: 0.0077\n",
      "Epoch 8/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 7.3195e-05 - mean_squared_error: 7.3195e-05 - accuracy: 0.0063 - val_loss: 8.1970e-05 - val_mean_squared_error: 8.1970e-05 - val_accuracy: 0.0077\n",
      "Epoch 9/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 7.1264e-05 - mean_squared_error: 7.1264e-05 - accuracy: 0.0063 - val_loss: 6.7465e-05 - val_mean_squared_error: 6.7465e-05 - val_accuracy: 0.0077\n",
      "Epoch 10/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.9829e-05 - mean_squared_error: 6.9829e-05 - accuracy: 0.0063 - val_loss: 6.8458e-05 - val_mean_squared_error: 6.8458e-05 - val_accuracy: 0.0077\n",
      "Epoch 11/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.8489e-05 - mean_squared_error: 6.8489e-05 - accuracy: 0.0063 - val_loss: 6.6346e-05 - val_mean_squared_error: 6.6346e-05 - val_accuracy: 0.0077\n",
      "Epoch 12/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 6.9168e-05 - mean_squared_error: 6.9168e-05 - accuracy: 0.0063 - val_loss: 6.6641e-05 - val_mean_squared_error: 6.6641e-05 - val_accuracy: 0.0077\n",
      "Epoch 13/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.7099e-05 - mean_squared_error: 6.7099e-05 - accuracy: 0.0063 - val_loss: 6.5326e-05 - val_mean_squared_error: 6.5326e-05 - val_accuracy: 0.0077\n",
      "Epoch 14/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 6.7212e-05 - mean_squared_error: 6.7212e-05 - accuracy: 0.0063 - val_loss: 6.5197e-05 - val_mean_squared_error: 6.5197e-05 - val_accuracy: 0.0077\n",
      "Epoch 15/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 6.6679e-05 - mean_squared_error: 6.6679e-05 - accuracy: 0.0063 - val_loss: 6.5348e-05 - val_mean_squared_error: 6.5348e-05 - val_accuracy: 0.0077\n",
      "Epoch 16/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.6564e-05 - mean_squared_error: 6.6564e-05 - accuracy: 0.0063 - val_loss: 6.4937e-05 - val_mean_squared_error: 6.4937e-05 - val_accuracy: 0.0077\n",
      "Epoch 17/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.6319e-05 - mean_squared_error: 6.6319e-05 - accuracy: 0.0063 - val_loss: 6.4770e-05 - val_mean_squared_error: 6.4770e-05 - val_accuracy: 0.0077\n",
      "Epoch 18/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.6297e-05 - mean_squared_error: 6.6297e-05 - accuracy: 0.0063 - val_loss: 6.4724e-05 - val_mean_squared_error: 6.4724e-05 - val_accuracy: 0.0077\n",
      "Epoch 19/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 6.6016e-05 - mean_squared_error: 6.6016e-05 - accuracy: 0.0063 - val_loss: 6.4471e-05 - val_mean_squared_error: 6.4471e-05 - val_accuracy: 0.0077\n",
      "Epoch 20/25\n",
      "730/730 [==============================] - 16s 22ms/step - loss: 6.5736e-05 - mean_squared_error: 6.5736e-05 - accuracy: 0.0063 - val_loss: 6.4967e-05 - val_mean_squared_error: 6.4967e-05 - val_accuracy: 0.0077\n",
      "Epoch 21/25\n",
      "730/730 [==============================] - 16s 21ms/step - loss: 6.5832e-05 - mean_squared_error: 6.5832e-05 - accuracy: 0.0063 - val_loss: 6.4494e-05 - val_mean_squared_error: 6.4494e-05 - val_accuracy: 0.0077\n",
      "Epoch 22/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.5684e-05 - mean_squared_error: 6.5684e-05 - accuracy: 0.0063 - val_loss: 6.5544e-05 - val_mean_squared_error: 6.5544e-05 - val_accuracy: 0.0077\n",
      "Epoch 23/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.5605e-05 - mean_squared_error: 6.5605e-05 - accuracy: 0.0063 - val_loss: 6.5642e-05 - val_mean_squared_error: 6.5642e-05 - val_accuracy: 0.0077\n",
      "Epoch 24/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.5528e-05 - mean_squared_error: 6.5528e-05 - accuracy: 0.0063 - val_loss: 6.4312e-05 - val_mean_squared_error: 6.4312e-05 - val_accuracy: 0.0077\n",
      "Epoch 25/25\n",
      "730/730 [==============================] - 15s 21ms/step - loss: 6.5308e-05 - mean_squared_error: 6.5308e-05 - accuracy: 0.0063 - val_loss: 6.4217e-05 - val_mean_squared_error: 6.4217e-05 - val_accuracy: 0.0077\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 24)                45304     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 80, 1, 1)          47281     \n",
      "=================================================================\n",
      "Total params: 92,585\n",
      "Trainable params: 91,945\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 80, 1, 1)]        0         \n",
      "_________________________________________________________________\n",
      "encoder_layer_0 (Dense)      (None, 80, 1, 80)         160       \n",
      "_________________________________________________________________\n",
      "encoder_bn_0 (BatchNormaliza (None, 80, 1, 80)         320       \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (Dense)      (None, 80, 1, 60)         4860      \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 80, 1, 60)         240       \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (Dense)      (None, 80, 1, 20)         1220      \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 80, 1, 20)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "latent_space_layer (Dense)   (None, 24)                38424     \n",
      "=================================================================\n",
      "Total params: 45,304\n",
      "Trainable params: 44,984\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 6.6702e-05 - mean_squared_error: 6.6702e-05 - accuracy: 0.0077\n",
      "MSE results: 6.670240691164508e-05\n",
      "accuracy results: 0.007710760924965143\n",
      "metrics names ['loss', 'mean_squared_error', 'accuracy']\n",
      "fold iteration # 6  lat dim 24\n",
      "MSE (valid) [6.758503150194883e-05, 7.293307862710208e-05, 7.42026386433281e-05, 6.920043961144984e-05, 6.670240691164508e-05], lat dim 24\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define constant parameter values for training\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 25\n",
    "\n",
    "# Load your data, dimensions are:\n",
    "# *Datasets sizes* sz[0] = num_subjects / sz[1] = num_ROIs / sz[2] = num_timepoints\n",
    "# Dataset is called all_data here\n",
    "# Timestep\n",
    "dt = 2  # in seconds\n",
    "\n",
    "sz_all = all_data_normalized.shape\n",
    "\n",
    "\n",
    "# This is how I built the data sets for test and training, \"dataset\" is your data, \"chunk_siz\" is the time window we\n",
    "# talked about (~0.8-1sec for you --> you have to put it in number of frames),\n",
    "# \"train_prop\" is the training vs test ratio\n",
    "\n",
    "def build_training_test_sets(dataset, chunk_siz=1, train_prop=0.9):\n",
    "    dataset = dataset.reshape(dataset.shape + (1,))\n",
    "    sz_dat = dataset.shape\n",
    "    print(sz_dat)\n",
    "    tot_patients = sz_dat[0]\n",
    "    num_chunks = int(np.floor(sz_dat[2]/chunk_siz))\n",
    "    num_train_patients = int(np.floor(tot_patients*train_prop))\n",
    "    x_train = np.empty([num_train_patients*num_chunks, sz_dat[1], chunk_siz, 1])\n",
    "    x_test = np.empty([(tot_patients-num_train_patients)*num_chunks, sz_dat[1], chunk_siz, 1])\n",
    "    for chunk_idx in range(0, num_chunks-1):\n",
    "        # Take num_train_patients patients randomly in time chunk chunk_idx and add them to the training\n",
    "        patients_to_add = np.random.choice(tot_patients, size=num_train_patients, replace=False)\n",
    "        other_patients = np.delete(range(0, tot_patients), patients_to_add, axis=0)\n",
    "        x_train[chunk_idx*num_train_patients:(chunk_idx+1)*num_train_patients, :, :] = \\\n",
    "            dataset[patients_to_add, :, chunk_idx*chunk_siz:(chunk_idx+1)*chunk_siz, :]\n",
    "        x_test[chunk_idx*(tot_patients-num_train_patients):(chunk_idx+1)*(tot_patients-num_train_patients), :, :] = \\\n",
    "            dataset[other_patients, :, chunk_idx*chunk_siz:(chunk_idx+1)*chunk_siz, :]\n",
    "    return x_train, x_test\n",
    "\n",
    "# This is to train the AE\n",
    "def train(x_train, x_valid, learning_rate, batch_size, epochs, latent_dim=10, chunk_siz=60):\n",
    "    autoenc = AutoEncoderDense(\n",
    "        input_size=[80, chunk_siz, 1],\n",
    "        layers_dim=[80, 60, 20],\n",
    "        latent_space_dim=latent_dim\n",
    "    )\n",
    "    autoenc.summary()\n",
    "    autoenc.train(x_train, x_valid, learning_rate, batch_size, epochs)\n",
    "    return autoenc\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define data set\n",
    "    dataset, x_test = build_training_test_sets(all_data_normalized, 1, 1)\n",
    "    sz_dat = dataset.shape\n",
    "    print(f\"dataset shape {sz_dat}\")\n",
    "\n",
    "    mean_val_mse = []\n",
    "    mean_val_acc = []\n",
    "\n",
    "    latdim_range = range(19, 25, 1) #change\n",
    "    for lat_dim in latdim_range:\n",
    "        VALIDATION_ACC = []\n",
    "        VALIDATION_MSE = []\n",
    "\n",
    "        # K-fold validation datasets\n",
    "        k = 5\n",
    "        kf = KFold(n_splits=k, shuffle=True, random_state=None)\n",
    "        fold_iteration = 1\n",
    "        for train_idx, test_idx in kf.split(dataset):\n",
    "            print(f\"Train idx = {train_idx} test idx = {test_idx}\")\n",
    "            x_train = dataset[train_idx, :, :, :]\n",
    "            x_valid = dataset[test_idx, :, :, :]\n",
    "            print(f\"training set size={x_train.shape}\")\n",
    "            print(f\"test set size={x_valid.shape}\")\n",
    "\n",
    "            # Training step # fold_iteration/k\n",
    "            save_dir = \"KFOLD_validation\"\n",
    "\n",
    "            autoencoder = train(x_train, x_valid, LEARNING_RATE, BATCH_SIZE, EPOCHS, lat_dim, 1)\n",
    "            autoencoder.save(save_dir, f\"model_{fold_iteration}_{lat_dim}\")\n",
    "            autoencoder.save_encoder(save_dir, f\"encoder_{fold_iteration}_{lat_dim}\")\n",
    "\n",
    "            autoencoder_trained = AutoEncoderDense.load(save_dir, f\"model_{fold_iteration}_{lat_dim}\")\n",
    "            autoencoder_trained.summary()\n",
    "            weights = autoencoder_trained.get_weights()\n",
    "\n",
    "            encoder_trained = AutoEncoderDense.load_encoder(save_dir, f\"encoder_{fold_iteration}_{lat_dim}\")\n",
    "            encoder_trained.summary()\n",
    "            encoder_weights = encoder_trained.get_weights()\n",
    "\n",
    "            # Evaluate the performance of the model - VALIDATION SET\n",
    "            x_predict = autoencoder_trained.predict(x_valid)\n",
    "            results = autoencoder_trained.evaluate(x_predict, x_valid)\n",
    "\n",
    "            print(f\"MSE results: {results[1]}\")\n",
    "            print(f\"accuracy results: {results[2]}\")\n",
    "            print(f\"metrics names {autoencoder_trained.metrics_names}\")\n",
    "\n",
    "            VALIDATION_MSE.append(results[1])\n",
    "            VALIDATION_ACC.append(results[2])\n",
    "\n",
    "            backend.clear_session()\n",
    "\n",
    "            fold_iteration += 1\n",
    "            print(f\"fold iteration # {fold_iteration}  lat dim {lat_dim}\")\n",
    "            print(f\"MSE (valid) {VALIDATION_MSE}, lat dim {lat_dim}\")\n",
    "\n",
    "        mean_val_mse.append(np.mean(VALIDATION_MSE))\n",
    "        mean_val_acc.append(np.mean(VALIDATION_ACC))\n",
    "\n",
    "    # Save results evaluation for matlab\n",
    "    sio.savemat(save_dir + f\"/validation_mse_{lat_dim}.mat\", mdict={'validation_MSE': mean_val_mse})\n",
    "    sio.savemat(save_dir + f\"/validation_acc_{lat_dim}.mat\", mdict={'validation_acc': mean_val_acc})\n",
    "\n",
    "    colors_data_points = plt.cm.gist_rainbow(np.linspace(0, 1, 103))\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "    ax.plot(latdim_range, mean_val_mse, color=colors_data_points[36])\n",
    "    ax.set_xlabel(\"Latent dimension\")\n",
    "    ax.set_xlabel(f\"Mean squared error ({k}-fold validation)\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
